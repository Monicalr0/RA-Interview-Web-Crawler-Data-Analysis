Title,URL,Subreddit,Body,Comments
ScrapeStack trouble getting HTML for search results page for Best Buy.,https://www.reddit.com/r/webscraping/comments/10fjmre/scrapestack_trouble_getting_html_for_search/,webscraping,"Trying to get the HTML for the Best Buy search results page:

> curl --location --request GET ""https://api.scrapestack.com/scrape?access_key=MY_KEY&proxy_location=us&render_js=1&url=https://www.bestbuy.com/site/searchpage.jsp?id=pcat17071&qp=format_facet%3DFormat~Physical&st=elden+ring"" 

This is returning improper HTML:

    *snip*
    <title>Best Buy: Page Not Found</title>
    *snip*

This same URL works fine using other services but I would rather use ScrapeStack since I'm using it elsewhere on our site.

Would appreciate any tips. Thanks!",[]
"Facebook graph API: ""please reduce the amount of data you're asking for error""",https://www.reddit.com/r/webscraping/comments/10f9tu4/facebook_graph_api_please_reduce_the_amount_of/,webscraping,"I know, if you're asking nicely to an API then it's not *real* scraping -- but official developer channels gave zero shits about this (figures) so mayyyybe it's worth a shot here? 

I'm working on a custom solution that gets *owned* page posts and comments for a client, for analytics reasons. Client manages some 25+ pages, of which all but one are localised versions, and one is a global page in English, which is the default to where FB users not included in all the different locales get redirected to. 

Everything is working OK (it's mostly `<page_id>/feed` and `<post_id>/comments` requests) *except for the global page*. 

When trying to access that via the /feed endpoint all I get is the **""please reduce the amount of data you're asking for""** error, regardless of *limit* set on the request or the number of fields requested. I can set that limit to *one* and still get the error, regardless of the amount of fields I'm requesting. 

Any ideas?",[]
Best platform to host my webscraping backend?,https://www.reddit.com/r/webscraping/comments/10f2j1m/best_platform_to_host_my_webscraping_backend/,webscraping,"I am currently building a web scraping application and am in the process of deciding on a platform to host my backend. I am looking for a platform that can handle the resource-intensive nature of web scraping and can support the programming languages and frameworks that I am using (Selenium, BS, requests).

I have been researching various options such as Heroku and Vercel, but webscraping violates their terms of use.

I would like to know what others have found to be the best platform for hosting web scraping backends and why. Additionally, if you have any experience with a specific platform and its ability to handle web scraping, I would appreciate any insights you could provide.

Thank you in advance for your help!","['You can use VPS from Google Cloud or AWS', 'Digital Ocean', 'I am running mine on Azure', 'Zyte']"
Need help completing this project.,https://www.reddit.com/r/webscraping/comments/10f8rjk/need_help_completing_this_project/,webscraping,"I am a newbie with web scrapping and I need help in completing this project.

I am trying to get the number form the span class that has the last ""star fill"" This is my desired output  seatcomfort  = 3 cabinstaffservice = 5 inflight = 5 FoodBeverages = 5 GroundService = 4 Valueformoney = 4 wifi = 5 

    seatcomfort = Ratings.select_one('tr:has(td:first-child:-soup-contains(""Seat Comfort"")) td.review-rating-stars.stars, span.star fill')    
    
    cabinstaffservice = Ratings.select_one('tr:has(td:first-child:-soup-contains(""Cabin Staff Service"")) td.review-rating-stars.stars, span.star fill')
    
    inflight = Ratings.select_one('tr:has(td:first-child:-soup-contains(""Inflight Entertainment"")) td.review-rating-stars.stars, span.star fill')
    
    FoodBeverages = Ratings.select_one('tr:has(td:first-child:-soup-contains(""Food & Beverages"")) td.review-rating-stars.stars, span.star fill')
    
    GroundService = Ratings.select_one('tr:has(td:first-child:-soup-contains(""Ground Service"")) td.review-rating-stars.stars, span.star fill')
    
    Valueformoney  = Ratings.select_one('tr:has(td:first-child:-soup-contains(""Value For Money"")) td.review-rating-stars.stars, span.star fill')
    
    wifi  = Ratings.select_one('tr:has(td:first-child:-soup-contains(""Wifi & Connectivity"")) td.review-rating-stars.stars, span.star fill')
    --------------------------------------------------------------------------------
    #output 
    
    seatcomfort= <td class=""review-rating-stars stars""><span class=""star fill"">1</span><span class=""star fill"">2</span><span class=""star fill"">3</span><span class=""star"">4</span><span class=""star"">5</span></td>
    
    Cabinservice= <td class=""review-rating-stars stars""><span class=""star fill"">1</span><span class=""star fill"">2</span><span class=""star fill"">3</span><span class=""star fill"">4</span><span class=""star fill"">5</span></td>
    
    inflight= <td class=""review-rating-stars stars""><span class=""star fill"">1</span><span class=""star fill"">2</span><span class=""star fill"">3</span><span class=""star fill"">4</span><span class=""star fill"">5</span></td>
    
    foodbeverages= <td class=""review-rating-stars stars""><span class=""star fill"">1</span><span class=""star fill"">2</span><span class=""star fill"">3</span><span class=""star fill"">4</span><span class=""star fill"">5</span></td>
    
    Groundservice= <td class=""review-rating-stars stars""><span class=""star fill"">1</span><span class=""star fill"">2</span><span class=""star fill"">3</span><span class=""star fill"">4</span><span class=""star"">5</span></td>
    
    Valueformoney= <td class=""review-rating-stars stars""><span class=""star fill"">1</span><span class=""star fill"">2</span><span class=""star fill"">3</span><span class=""star fill"">4</span><span class=""star"">5</span></td>
    
    wifi= <td class=""review-rating-stars stars""><span class=""star fill"">1</span><span class=""star fill"">2</span><span class=""star fill"">3</span><span class=""star fill"">4</span><span class=""star fill"">5</span></td>","['If your tool supports xpath you could use that to find the last star fill, or you could change select_one to select_all and get the last element from the array. Changing your selector from span.star fill to span.star.fill should return only the filled star spans']"
data completeness checks for dynamically loading page,https://www.reddit.com/r/webscraping/comments/10f4g5k/data_completeness_checks_for_dynamically_loading/,webscraping,"Hi, using Selenium to crawl and complete web scraping. The url loads dynamically and hence playing around with waiting time to fully load. I am not able to get the content-length meta data form the source to check teh data completeness. Is there any other way to check whether downloaded data is complete. As the page is loading dynamically, some long pages are incompletely downloaded. How do we get around this issue? Thanks.","[""Pretty good explanation of why it's difficult here: https://stackoverflow.com/questions/47832693/is-there-a-way-with-python-selenium-to-wait-until-all-elements-of-a-page-has-loa \n\nThat being said, you can use ExpectedConditions to wait until a certain html element has loaded or is clickable. Is there any element that fits that use case, something that only appears once the data has loaded?\n\nAlso, is Selenium/browser automation the only option here? Could you recreate the network requests without a browser at all? Or maybe use the browser just to get the required cookies/authentication details and the make the back end requests without the browser?""]"
"Web scraping Etsy for best sellers of an Etsy search term, then their top items?",https://www.reddit.com/r/webscraping/comments/10f3jx9/web_scraping_etsy_for_best_sellers_of_an_etsy/,webscraping,"Is this plausible using JavaScript and how legal is doing so? I‚Äôve been learning web dev for a year now and thought this could be a good idea for a portfolio piece but maybe employers would frown upon this?

I wanna make it for me personally as I do hand tool woodwork and thought it would be useful to have this data and then I thought surely I could program that?",[]
Which course is better for web parsing?,https://www.reddit.com/r/webscraping/comments/10el6kb/which_course_is_better_for_web_parsing/,webscraping,"Hello! I am a complete beginner, who would love to learn about web scraping. Currently, I am deciding between these two courses:
1. https://www.udemy.com/course/web-scraping-in-python-with-beautifulsoup-and-selenium/
2. https://www.udemy.com/course/web-scraping-course-in-python-bs4-selenium-and-scrapy/
I am sort of leaning towards second one, because it has just been updated and it also covers scrapy.
I'd love to hear your opinions or if you can reccommend me a better course.
Have a nice day!","['Obviously the second one because it has a higher rating, plus you say you are leaning towards that one?', 'Neither.  Choose a website and try to parse it one step at a time.']"
How to launch a scrapy spider from a script in a Thread(),https://www.reddit.com/r/webscraping/comments/10enkwt/how_to_launch_a_scrapy_spider_from_a_script_in_a/,webscraping,"Hi evryone,

I am using scrapy and I would like to start my spider from a script without blocking the process while scraping. Basically I have a little GUI with a start button, I don't want the window to be frozen when I press the start button, because I also want a Stop button to be able to interrupt a scrap if needed without terminating the process manually with Ctrl-C .

I tried to thread like this:

    def launch_spider(self, key_word_list, number_of_page):
            spider = SpiderWallpaper()
            process = CrawlerProcess(get_project_settings())
            process.crawl('SpiderWallpaper', keywords = key_word_list, pages = number_of_page)
    // if i use process.start() directly the main process is frozen waiting for the
    // scraping to complete so :
            mythread = Thread(target = process.start)
            mythread.start()
    output:
        Traceback (most recent call last):
      File ""/usr/lib/python3.10/threading.py"", line 1016, in _bootstrap_inner
        self.run()
      File ""/usr/lib/python3.10/threading.py"", line 953, in run
        self._target(*self._args, **self._kwargs)
      File ""/home/***/.local/lib/python3.10/site-packages/scrapy/crawler.py"", line 356, in start
        install_shutdown_handlers(self._signal_shutdown)
      File ""/home/***/.local/lib/python3.10/site-packages/scrapy/utils/ossignal.py"", line 19, in install_shutdown_handlers
        reactor._handleSignals()
      File ""/usr/lib/python3.10/site-packages/twisted/internet/posixbase.py"", line 142, in _handleSignals
        _SignalReactorMixin._handleSignals(self)
      File ""/usr/lib/python3.10/site-packages/twisted/internet/base.py"", line 1282, in _handleSignals
        signal.signal(signal.SIGTERM, reactorBaseSelf.sigTerm)
      File ""/usr/lib/python3.10/signal.py"", line 56, in signal
        handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))
    
    ValueError: signal only works in main thread of the main interpreter
    

I saw this [snippet](https://snipplr.com/snippet/67015/revisions) which seems interesting but the import doesn't work with the latest version of scrapy.

Any ideas on how to manage the signal to be used in a subThread ?",[]
need software to scrap some select data from a website and remplace them in my text file,https://www.reddit.com/r/webscraping/comments/10ec8cc/need_software_to_scrap_some_select_data_from_a/,webscraping,"Hey guys, i hope you are doing well, like in title, need software to scrap some select data from a website and remplace them in my text file. is their software which can do this job, for exemple my text file has:

Description:

TITLE:

TYPE:

PLACE:

i need scrapper data which will be based only in that website and will use my custom text file as a template, then it will remplace auto data scrapped from that website and remplace each data in exact place of my text file.

So anytime i give it that URL, it will generate those data. sorry for my bad english","['Hi, I can help you with this, check your dm.', 'You can do this with [MrScraper](https://mrscraper.com). \n\nSimply extract each data into 3 different extractos: title, type and place.\n\nThen use the API, Zapier or any other no-code tool to print this variable in a doc üëç']"
"Between Stable Diffusion and ChatGPT, its clear blocking bots only stop the small guy.",https://www.reddit.com/r/webscraping/comments/10egpxv/between_stable_diffusion_and_chatgpt_its_clear/,webscraping,"We always knew this was the truth, but it doesnt get more 'in your face' than seeing AI art and ideas scraped from websites with anti-scraping technology. 

Its a good thing they defeated the anti-bot, because if they didn't we wouldn't have 2 new and useful technologies.

But why does wealth decide who gets access to public facing data?","[""Are you saying some sites can't be scraped by little guys?"", ""Can you please help me understand how Stable Diffusion and ChatGPT relate to web scraping?  Not saying they are unrelated, I just don't get the connection.  Appreciate if someone can enlighten me here."", 'I see this different - it‚Äôs a resource game, it always was/will be. ChatGPT has very broad use case scenarios, that‚Äôs why they had to put so much effort and resource to make it, which they had. There‚Äôs obvious gap in the technology right now, because to train large amount of data you need powerfull and expensive compute power. \nBut with such a big steps in ML which are revealed everyday, I think that webscraping will change also, and soon it will be really hard to prevent scraper to do it‚Äôs job. Data access was never as important as right now.', ""as with any sort of security it's always an arms race.""]"
bet365 or other identical sites stats to excel,https://www.reddit.com/r/webscraping/comments/10do8vm/bet365_or_other_identical_sites_stats_to_excel/,webscraping,"   I am looking for a site or a way to get live stats from bet365 or  other identical site that has the same stats , i could look into web  scraping but from what i understand, it's illegal to scrap the stats  cause of the terms of violation.

I need a website suggestion that actually does this work with  subscription or not or a site where it accepts web scraping and give  identical stats.  
any help appreciated","['The terms of violation? lol', 'What are you looking to accomplish specifically? What data?', 'hehehee. Webscraping is not ilegal, so long as the data is on the public domain, then its ethically right  to take that data and use it the way you want. I have been scraping Bet365 realtime data for more than 3 years now. \n\nI think they use terms like ""Violation"" to scare  people like you.\n\nWhich starts are you looking for to be specific?']"
Looking for a web scraping tool with export to rss feed,https://www.reddit.com/r/webscraping/comments/10dhi2k/looking_for_a_web_scraping_tool_with_export_to/,webscraping,Is there any web scraping tools that have the ability to export the data as rss feed or send it to discord/other platforms?,"['RSS feeds are just XML (usually, but sometimes they are JSON)\n\nYou could easily create a script (or hire someone off Fiverr, Upwork) that builds the XML structure from the scraped data and then uploads it to a web server somewhere or just a static site hosting platform like Netlify or Vercel. \n\nThen use a service like [IFTTT](https://ifttt.com) to send data to a Discord webhook when a new item is posted to the RSS feed.']"
Scraping google maps for website URL,https://www.reddit.com/r/webscraping/comments/10de4tl/scraping_google_maps_for_website_url/,webscraping,"Hello, I have been trying to scrape google maps for websites along with the name for quite some time now and have had no luck after trying countless solutions. Most things i find will collect some information but nothing I have used yet will copy the website link into the csv file. Has anyone tried to do this and found something that has worked for them? I would love to hear it! Thanks","['Funny enough, I built something to scrape regular google search results and this is how I did it (using python).\n\n    def scrape_google_results_page(html):\n        soup = bs4.BeautifulSoup(html, ""html.parser"")\n        links = soup.findAll(\'a\')\n        results = []\n        for link in links:\n            if link.has_attr(\'href\'):\n                url = link[\'href\']\n                if url.startswith(\'/url?q=\'):\n                    url = url.replace(\'/url?q=\', \'\')\n                    url = url.split(\'&\')[0]\n                    results.append(url)\n        \n        return results\n\nView the full source in the context of the larger script [here](https://github.com/crock/worksauce/blob/8eca606fdd5146e06eb7c93a43c863088dbdcea7/search-result-extractor.py#L32:L44).']"
Hosting web scraped data on vercel?,https://www.reddit.com/r/webscraping/comments/10do4wp/hosting_web_scraped_data_on_vercel/,webscraping,"Hello, I created a web scraper using playwright that scrapes several sneaker sites and puts it into a json format using node for an api. But, I keep getting error 500 function invocation failed. It works fine in local.   


This is what some of my logs look like:

    [GET] /
    10:55:15:55
    Please run the following command to download new browsers:              ‚ïë"",""‚ïë                                                                         ‚ïë"",""‚ïë     npx playwright install                                              ‚ïë"",""‚ïë                                                                         ‚ïë"",""‚ïë <3 Playwright Team                                                      ‚ïë"",""‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"",""    at /var/task/index.js:24:34"",""    at Layer.handle [as handle_request]

Is it not normal to use playwright like this? I understand playwright is usually used for integration testing. Should I be sending the data scraped to a database first and then pull data from there for the api.  Totally new to building my own api , so this is all learning process if someone can point me in the right direction <3.","['hum I don‚Äôt see your code, neither am I a playwright dev, but here are my 2 cents:\n- I don‚Äôt know how long are your scraper is taking to return that information, since this is supposedly an asynchronous process, are you sure your return API code is prepared for that?\n- it‚Äôs not like you cannot use a scraper with an API, but have you considered implement a webhook? just an idea.\n- why not Puppeteer if you‚Äôre already using NodeJS? imho is a more mature framework for scrapping']"
Help with WebScraper.io?,https://www.reddit.com/r/webscraping/comments/10dkyb4/help_with_webscraperio/,webscraping,"Before you start, no, I know nothing about programming or writing code. But is there anyone out there who can help write a sitemap for the WebScraper.io Google Chrome extension? I‚Äôm unable to download anything new on my laptop so I‚Äôm looking for someone who can write the code that I can copy and paste into web scraper io.",[]
Using selenium with proxy still hit bot detection,https://www.reddit.com/r/webscraping/comments/10d0x5r/using_selenium_with_proxy_still_hit_bot_detection/,webscraping,"Trying to scrape a site that uses cloudflare ([axs.com](https://axs.com)) and I keep on getting hit by their bot detection. No captcha or anything just a full block. What's weird is that if I use a full vpn (surfshark) and using another country like belize, I could load the seats properly but if I use selenium then it gets detected.

Is there a list of recommended settings either with firefox or chrome drivers that would imitate a regular browser?","['Try using direct HTTP requests instead of selenium. This is a way better, quicker method.\n\nWith this method, you can use cloudscraper to bypass cloudflare.', 'use undetected chromedriver', 'AXS notoriously difficult to scrape for counts my dude', 'A few things that come to mind and are worth looking into are:\n\n[https://github.com/lwthiker/curl-impersonate](https://github.com/lwthiker/curl-impersonate)\n\n[https://github.com/berstend/puppeteer-extra](https://github.com/berstend/puppeteer-extra)\n\nAnd if not then you need to upgrade your proxies and send the requests via an advanced [web scraping api](https://brightdata.grsm.io/vitariz-unlocker).']"
Mayday! Mayday! Impossible site to webscrape!? REWARD for solution!,https://www.reddit.com/r/webscraping/comments/10d881i/mayday_mayday_impossible_site_to_webscrape_reward/,webscraping,"I have no idea how to scrape [these](https://ibb.co/HFNbw3j) (IV) numbers from [this](https://marketchameleon.com/Overview/IP/IV/) website. It contains stock numbers and I have tried to scrape them off the website for eons. And although I have made advancements I am yet to actually scrape them. I am a noobie at web scraping and coding overall but maybe you guys know how to obtain them. I am coding in python >3 and I have figure that the site is ajax-based since it wouldn‚Äôt work with a me want me get requests. PS A loggin shouldn‚Äôt be required since the numbers still show up in inspect although not being logged in.

[This](https://textdoc.co/pnuygOileDQf6YV1) is the script I am using at the moment. But it wouldn‚Äôt give me the numbers.

I have googled and apparently using a chrome driver should fix the Ajax problem. Therefore I have tried using [this](https://textdoc.co/BoglTirm1SA3Mt5R) script. But it doesn't work for whatever reason. And I have no clue how to fix it.

I‚Äôll reward you who finds a python code that can obtain these numbers for me and put them in a list or string. Have a great new year everybody!!!!","[""The script you're refering to at [https://file.io/DfRNXlJsVfbb](https://file.io/DfRNXlJsVfbb) has been deleted. Also you need an account to scrape the site which I don't have (and yes there's a 7 day trial but not looking forward to using that). Your own python script has also been deleted from https://file.io/J2azbyhI8ElM."", 'First off, Chrome\'s ""inspect element"" shows a mix of server-rendered HTML + client-rendered HTML. If you want to view just what comes from the server, right click on the page and choose ""View Page Source"". That\'s what your scraper is getting and with the modern web, that\'s what most sites send to the data and then they hydrate the page client-side, which is why you are having trouble with scraping the data you want.\n\nOf course, there are ways. Mainly using headless browsers (phantomjs) or browser automation tools like Selenium.', ""What's your budget?"", ""By the way, nothing is impossible... üòé\n\nNote: maybe it's not worth it (too expensive, too much effort, etc.)""]"
How hard is it to scrape that?,https://www.reddit.com/r/webscraping/comments/10cyco7/how_hard_is_it_to_scrape_that/,webscraping,"Hello guys! I'm very new here, so excuse me if my question is stupid, but I'm trying to figure out how hard it is to scrape the following data and send it to something like google sheets.

I have a WooCommerce website, and I need to extract a specific page from the WooCommerce Analytics tab on an hourly/daily basis. [Here is a link](https://imgur.com/UHthsj3)

P.S. (Using the native WooCommerce API is NOT an option)

Thanks!","[""As you say you can't use the API and considering you'll need to log into the backend, perhaps look into using selenium with a Python script and running it periodically.""]"
"Octoparse pagination ""next page""",https://www.reddit.com/r/webscraping/comments/10cy6ml/octoparse_pagination_next_page/,webscraping,"hello, i'm trying to make octoparse click on ""next page"" to continue the scraping. I tried to create a loop with pagination but it never works... the result is that the first page is correctly scraped, but the second, third, fourth, etc. are not scraped et the first page continue to extract duplicated datas.

someone knows where the problem comes from ?",[]
Javascript,https://www.reddit.com/r/webscraping/comments/10d1n4g/javascript/,webscraping,"Hey, got a page that one hit returns some js that then needs to be actioned to submit to the final end point page. 

Other than selenium what other options do u have, the faster and more robust the better. Unsure how I could use curl for somthing like this but open to all and any ideas.",[]
can someone guide me about how to setup scrapy project,https://www.reddit.com/r/webscraping/comments/10cm3ox/can_someone_guide_me_about_how_to_setup_scrapy/,webscraping,"I am starting a project where I have to scrape around 50 to 60 news website for live and current news. I am currently making individual scripts for now as all the websites have different tags for their article information like headline, date and article body. How do I go about setting a single project where all the scripts will run simultaneously, and factors that I should keep in mind. 

Like - As all websits have different tags, I don't think item loaders will be of help as I have to consider all the scenario where I have to perform a check on all tags related to that information i am about to extract.

I am fairly new at scrapy so any idea about how I would  go about it would be appreciated.",['Dm me i could help you. No paying by the way.']
What database do you guys use to store data? And why?,https://www.reddit.com/r/webscraping/comments/10c3uq1/what_database_do_you_guys_use_to_store_data_and/,webscraping,Bonus question: What database do other data aggregating businesses use?,"[""SQLite, because it doesn't require hosting a server. Also easy to backup the database file."", 'SQL for data that is used in analytics and MongoDB for ""record keeping""', ""Google BigQuery, usually. The data is easy to share, export, make reports from and query, and the Business Intelligence dept of most companies already have accounts.\n\nIt's also priced only per Terrabyte queried, so no ongoing server cost when the DB is not used. This makes it practically zero-cost for most projects, unless data sizes are enormous (may even fit into the free tier in many cases)"", 'Notepad++\n\nEdit:  Forgot to say why.', 'Json, readable easy to modify and user friendly', 'I do very small hobby projects so a .csv file does just fine.', 'Mostly csv or txt files, cuz my projects are relatively small scale.', 'Firestore, but looking into Dynamo. Looks promising', 'I usually use feather or parquet files']"
Yellowpage scraper.,https://www.reddit.com/r/webscraping/comments/10cbygu/yellowpage_scraper/,webscraping,"Hey everyone,

I've been working on a web scraping project using Python to extract data from [YellowPage](https://github.com/sushil-rgb/YellowPage-scraper) and I wanted to share my experience and some tips for anyone else looking to do the same.

First, I used the popular library BeautifulSoup and Playwright to navigate and automate the website. The script asks user to enter a business name, location and number of pages to scrape and save it into an excel database accordingly. It extracts all the necessary data including emails as well. I feel I used lots of try and except clause, if someone has better approach them please free to share.

Another thing to watch out for is that the website structure can change frequently, so it's important to regularly check and update your code accordingly.

Overall, it was a fun and challenging project that taught me a lot about web scraping and working with dynamic websites.

Let me know if you have any questions or tips of your own to share!","['This is pretty awesome. I am also working on a similar project.', ""That's great\n\nWere you able to extract all the emails from the sites\n\nI have a project at hand too using selenium python library\n\nI'm having 80% success with several try clause as well"", ""I don't think I can switch from selenium at least for now"", 'Why did you use Playwright? requests would have worked fine as this page is not being rendered by JS in the browser.  \nSee how you can [wrap try except in a decorator](https://stackoverflow.com/questions/15572288/general-decorator-to-wrap-try-except-in-python).', ""This is really cool!\nI've been looking for ways to improve my webscraping skills, so I guess I'll try something similar."", ""Since I switched from beautiful soup and I've been working with selenium and I found it more interesting perhaps because I've not tried playwright"", 'Thank you for sharing. Helps me on my webscraping journey. I just learning to program. How can you tell which programs to use for which sites?', ""have an exact project using scrapy and mysql. word to the wise their css node names don't change often"", 'Why are you tracking your virtual environment? You can ignore it since it can be easily created.']"
I want to make a demo web scrapper,https://www.reddit.com/r/webscraping/comments/10c0qjs/i_want_to_make_a_demo_web_scrapper/,webscraping,"Which scrapes live score from site like espn Cricinfo and updates live score on my web app.
I never scraped a live website before so your  suggestions or any resources will be helpful üòÅ

Thanknging in anticipation.","['What programming languages can you program in? Python? Java? JavaScript?\n\nIf you know Python, then do the scrapy tutorial:\nhttps://docs.scrapy.org/en/latest/intro/tutorial.html\n\nIf you know any other language, google for a Selenium tutorial in that language.\n\nIf you don‚Äôt know any programming language, then first learn Python until you‚Äôre able to do that scrapy tutorial.\n\nIf you want to learn more about what scraping entails, check out some YouTube videos by John Watson Rooney:\nhttps://youtube.com/@JohnWatsonRooney\n\nI recommend this one as a starter:\nhttps://youtu.be/nCuPv3tf2Hg\n\nGood luck with your learning!']"
Where can I find a mentor?,https://www.reddit.com/r/webscraping/comments/10blltx/where_can_i_find_a_mentor/,webscraping,"I find myself hitting a ceiling a lot and I don't know where to go next in order to become more advanced. Currently, I'm maybe at the intermediate level with an elementary knowledge of things such as browser fingerprinting, bypassing bot protection, captcha management, networking, and general web development.

What I'm really struggling with is not knowing what I don't know and not knowing how to find out what I don't know. Instinctually, I wanted to learn networking and back-end development at a deeper level as I believe that would at least give me an idea of what sort of information I'm sending to a website and what a website can do with that information. Then be able to reverse engineer that information somehow to at least give myself a better chance. But then again, it goes back to not knowing what I don't know.

Either way, any pointers would be greatly appreciated. I have a lot of really good ideas for projects that keep being put on hold because of the web scraping hangups so now is the time for me to really step up and put my money where my mouth is.","['For some additional ideas, check out this list of ways to level up your scraping game I made last month:\n\nhttps://reddit.com/r/webscraping/comments/zf9a4v/_/izavkfw/?context=1', 'Describe one of these hang ups', 'have you tried the plugin Stealth with puppeteer? there‚Äôs a huge NodeJS/Puppeteer community creating new amazing plugins and sharing snippets that you may be missing, most of people here tend to use scrappy/pyrhon though, so unless you‚Äôre considering change your setup choice(which I do not recommend cause Puppeteer is an excellent tool for automation/scrapping) I sugest to basically ignore them and look elsewhere (no offense python users, both environments are decent, is just a matter of choice).\n\nI worked exclusively with Node/Puppeteer for almost 2 years, Freelancing at Fivver, never was unable to do what I needed and my only limitations where my inability to see the real problem from time to time + limited time to try different approaches.\n\nWhat you said about learning how to backend is kinda valid, not really a must, but does help, my personal style is actually the opposite of mimicking a user(which is valid sometimes) I avoid direct interaction(clicks) as much as possible, nowadays we have many many websites written with angular, react, svelt and similars, I love those because I can just intercept their data in the background and without a single interaction you could just harvest so much information‚Ä¶ another thing you can do is, you can find a function that makes a request you want, lets call it function X, you inspect it, copy that guy, slightly change it to a format that works for you and you can write it in your main page, sometimes overwriting the original one, or just creating another version of it, that you can call it and harvest content‚Ä¶ you have a fricking browser on your hands theres so much you can do‚Ä¶ feel free to reach me if you have questions brother!', 'You said it yourself, learn a backend.... Or even better, learn a few. \n\nI recommend Pluralsight as a learning platform.', 'Everyone has trouble with blocking.  If you read around this sub you\'ll see it\'s less about understanding every aspect of how you might be getting blocked and more about finding the right software/config combination to overcome the blocks with this site or that site.  There\'s no exact science to web scraping and the techniques used to fingerprint you are always evolving.  There are third party services that people use to protect their websites whose only real job is to constantly find new ways to identify bots and headless browsers.  You don\'t want to be the one reverse engineering things.  Getting around blocks is always a ""hack"" and so it\'s going to always differ between sites.']"
cost of webscraping,https://www.reddit.com/r/webscraping/comments/10c1n65/cost_of_webscraping/,webscraping,"I've been trying to scrape product pages from Amazon with selenium.  I've been having connection issues, which makes me think I need to use proxies.   I started looking at the cost, and I'm seeing roughly $10 per gb for rotating residential proxies.      I'm not sure of the exact size but let's say an Amazon page is 2mb. That'd mean it'd cost me $20 for every 1,000 Amazon pages I get the info from.   Am I missing something?  It seems like webscraping is insanely expensive","['You only need residential proxies for the most protected sites. You can definitely use datacenter proxies for Amazon, which are much cheaper.\n\nAlso, there are cheaper residential providers, like [https://packetstream.io/](https://packetstream.io/) is just $1/GB - although you get a much smaller pool and much higher error rates compared to premium providers.', 'No way any page is 2MB of source code.  It is expensive though.', 'If you move away from Selenium and just use a HTTP client like Python Requests then you will be able to scrape at a fraction of the price. Using headless browsers drive up you proxy bills (if paying per GB) and require you to use higher-performing servers.']"
"How to use ""for"" to ""loop"" multiple urls ?",https://www.reddit.com/r/webscraping/comments/10bz75l/how_to_use_for_to_loop_multiple_urls/,webscraping,"The current code is perfect to scrape the information for only one Url, and i would like to be able to scrape from multiple urls at once ( maybe use For url in Urls ) , i would like to add this ( URL : [https://www.6pm.com/p/gbg-los-angeles-ayvie-slate/product/9479982/color/642?zlfid=192&ref=pd\_detail\_1\_sims\_cv](https://www.6pm.com/p/gbg-los-angeles-ayvie-slate/product/9479982/color/642?zlfid=192&ref=pd_detail_1_sims_cv)). Here is the current code for just one url below. Please any help or direction would be appreciated

 

`import datetime`  
 `from bs4 import BeautifulSoup`  
 `import requests`

`def get_url_data_from_url_request(url):`  
  `print("">> get_url_data_from_url_request: ""+str(url))`

   `url_data = None`  
  `headers = {""user-agent"": ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML,`   
 `like Gecko) Chrome/90.0.4430.93 Safari/537.36""}`  
  `s = requests.session()`  
  `s.keep_alive = False`  
  `request = s.get(url, proxies=None, headers=headers)`  
  `print(""request.status_code: "", request.status_code )`  
  `url_data = request.text`  
  `request.connection.close()`  
  `s.close()`  
  `return url_data`

`def main():`  
  `print(""bdr.sandbox"")`  
  `generated_on = datetime.datetime.now()`  
  `print(generated_on)`  
  `source_product_url = ""`[`https://www.6pm.com/p/easy-spirit-epic-gray/product/9450972/color/11`](https://www.6pm.com/p/easy-spirit-epic-gray/product/9450972/color/11)`""`  
  `url_data = get_url_data_from_url_request(url=source_product_url)`  
  `soup = BeautifulSoup(url_data, ""lxml"")`  
  `id_element = soup.find('span', {""itemprop"": ""sku""}).text`  
  `print(id_element)`

`if __name__ == '__main__':`  
 `main()`","['Does this code make sense?\n\n\n    urls = [""https://www.6pm.com/p/gbg-los-angeles-ayvie-slate/product/9479982/color/642?zlfid=192&ref=pd_detail_1_sims_cv"", ""https://www.6pm.com/p/easy-spirit-epic-gray/product/9450972/color/11""]\n\n    results = []\n\n    for each_url in urls:\n        url_data = get_url_data_from_url_request(url=each_url)\n        soup = BeautifulSoup(url_data, ""lxml"")  \n        id_element = soup.find(\'span\', {""itemprop"": ""sku""}).text\n        results.append(id_element)\n\n    print(results)']"
401/403 Error But I Can Access the Site (Java),https://www.reddit.com/r/webscraping/comments/10brqr1/401403_error_but_i_can_access_the_site_java/,webscraping,"I'm pretty new to this and am trying to take info off [https://core-api.prod.blur.io/v1/collections/azuki/executable-bids?filters=%7B%7D](https://core-api.prod.blur.io/v1/collections/azuki/executable-bids?filters=%7B%7D) but my code throws me a 401/403 error. I can view it on chrome so I'm confused.  


Heres what I have:

URL url = new URL(""https://core-api.prod.blur.io/v1/collections/azuki/executable-bids?filters=%7B%7D"");  
 HttpURLConnection con = (HttpURLConnection) url.openConnection();  
 con.setRequestProperty(""User-Agent"", ""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/98.0.4758.102 Safari/537.36"");  
 con.setRequestMethod(""GET"");  
 con.connect();",[]
Where to start with webscraping ?,https://www.reddit.com/r/webscraping/comments/10agkmn/where_to_start_with_webscraping/,webscraping,"So far I only have experience with webscraping by using regex, which works nice. I googled a bit during the past days and it seems that DOM with javascript are popular. I don't know what the best way is but I like to know more about webscraping. What tutorials, books, etc.. would you recommend a newbie ?","[""I wrote several in-depth introductions in various languages:\n- [Python](https://scrapfly.io/blog/web-scraping-with-python/) (Python is recommended for web scraping as it's a very strong data language)  \n- [Javascript (NodeJS)](https://scrapfly.io/blog/web-scraping-with-nodejs/)  \n- [R](https://scrapfly.io/blog/web-scraping-with-r/)  \n- [PHP](https://scrapfly.io/blog/web-scraping-with-php-101/)  \n- [Ruby](https://scrapfly.io/blog/web-scraping-with-ruby/)\n\nThough here's a quick primer: all you need to scrape the web is a way to retrieve the web content (HTTP client or a web browser) and a way to parse it (HTML or JSON parser). Most programming languages has these two things!\n\nHTML parsing is a bit complicated, but HTML is a machine-readable format that represents a tree of elements:\n\n```html\n<head>\n  <title>hello world</title>\n</head>\n<body>\n  <h1>Product Name</h1>\n</body>\n```\nJust from indentation you can see the tree structure of this format and imagine how would you navigate to a particular element like `h1` -> `body->h1`.\n\n This is great for parsing as you can rely on strong, predictable structure to find the data instead of using regex where you rely on unpredictable text patterns (easy to break). To parse HTML there are 2 popular standards: \n- [CSS selectors](https://scrapfly.io/blog/parsing-html-with-css/) that's the stuff you use to select elements to apply CSS styles for (e.g. `.product>.title{color:blue}`)\n- [XPath selectors](https://scrapfly.io/blog/parsing-html-with-xpath/) similar to CSS selectors but more powerful. Were invented to parse XML documents when that was the dominant data format (compared to today's JSON)\n\nThe other hard part is blocking. HTTP is a very straight-forward protocol. You ask for something and you get it - a done deal! The challenge arises when you don't get a response because you look unusual (like a bot) or missing some parameters or tokens.\n\n---\n\nFor actual learning, it's best to pick a real practical project, but since blocking is such a daunting subject, you should probably choose a smaller target that is less likely to block. In other words, don't scrape Instagram or Google or any major scraping target for now."", 'What programming languages can you program in? Python? Java? JavaScript?\n\nIf you know Python, then do the scrapy tutorial:\nhttps://docs.scrapy.org/en/latest/intro/tutorial.html\n\nIf you know any other language, google for a Selenium tutorial in that language.\n\nIf you don‚Äôt know any programming language, then first learn Python until you‚Äôre able to do that scrapy tutorial.\n\nIf you want to learn more about what scraping entails, check out some YouTube videos by John Watson Rooney:\nhttps://youtube.com/@JohnWatsonRooney\n\nI recommend this one as a starter:\nhttps://youtu.be/nCuPv3tf2Hg\n\nGood luck with your learning!', 'I would recommend to learn/practice following:\n‚Ä¢ Python\n‚Ä¢ Python libraries: request, tqdm, json, pandas, regex(u know this already), bs4, csv\n‚Ä¢ Microsoft Excel\n‚Ä¢ Knowing JS vanilla and modern JS is huge plus\n\n\nLearn more about how API/requests work via browser inspector and it will ease ur scraping process/development.\n\nEdit: avoid Selenium. Thank me later']"
Checking Marketplaces for new products?,https://www.reddit.com/r/webscraping/comments/10aq27y/checking_marketplaces_for_new_products/,webscraping,"Hello - is there any chance to check for a specific search on marketplaces eg.

[https://www.facebook.com/marketplace/104047599631322/search?query=omnipods](https://www.facebook.com/marketplace/104047599631322/search?query=omnipods)

So it returns allways the new places products?  
And eg. checking this every 5-10 minutes?  
Probably this can¬¥t be really done manually - but probably is there also some services in places for stuff like this?","['No', 'You could try some of the point and click services or browser extensions, there are plenty out there so just search Google and try a few of them to see which one works best for your use case (and it‚Äôs r too expensive to run)']"
Is it possible to create a script like this?,https://www.reddit.com/r/webscraping/comments/10aixb5/is_it_possible_to_create_a_script_like_this/,webscraping,"[Mountainproject.com](https://Mountainproject.com) has data for 279,958 climbing routes. When searching for routes, you can modify based on location, climbing type, difficulty rating (as a range), and quality rating. At the results page, it gives you the option to export the first 1,000 results into an excel sheet.  


I'm interested in getting all of the route data together, but in order to do that I would need to create at least 280 separate results files, each with no more than 1,000 rows. I want to create a ""results checker"" script that runs an array of searches and reports the results for each one. For example, there are 36 different options for climbing difficult grades. I could have the script run 36 times and spit out how many search results there are for each grade. From there, I could get a sense of which grades I would have to further subdivide. The lowest difficulty grade only has 277 routes, so that would work, but there are quite a few with over 1,000 results.  


Is it possible to have a script do something like that?","['Yeah that sounds fairly reasonable.', ""I would check to see if the data is available for download anywhere maybe send an email and ask I mean it don't hurt to ask just it don't hurt saves ya alot of work unless your just doing this for practice then have at it""]"
Simple Scraper worked for me before but now it seems to be driving me mad....,https://www.reddit.com/r/webscraping/comments/10afnj7/simple_scraper_worked_for_me_before_but_now_it/,webscraping,"I'm trying to scrap this page ([https://elgl.org/celebrate-90-of-elgls-top-100-local-government-influencers-for-2022/](https://elgl.org/celebrate-90-of-elgls-top-100-local-government-influencers-for-2022/)) to create a base in Airtable. Simple Scraper will let me select all ""Names"" and ""LinkedIn"" links however it won't select all photos, bios, or locations. Do anyone have a suggestion as to what I'm doing wrong or perhaps an alternative? Thank you in advance for your time.","[' ```\nfrom requests_html import HTMLSession\nfrom bs4 import BeautifulSoup\nimport re\n\nsession =\tHTMLSession()\n\n\nurl = ""https://elgl.org/celebrate-90-of-elgls-top-100-local-government-influencers-for-2022/""\n\ndef get_bs(strObj):\n\treturn BeautifulSoup(strObj,\'html.parser\')\n\ndef get_details(pTags):\n\tdata=[]\n\tfor tag in pTags[:-1]:\n\t\tpText =tag.get_text()\n\t\tif \'|\' in pText and not(tag.find(\'a\')):\n\t\t\tdata.append(pText)\n\tif len(data)==1:\n\t\treturn data+[\' \']\n\treturn data\n\t\t\n\npage =\tsession.get(url)\nprint(page.status_code)\n\nbsObj =\tBeautifulSoup(page.text,\'html.parser\')\nprint(bsObj.title)\n\ncontentDiv= bsObj.find(\'div\',{\'class\':\'entry-content\'})\ncelebDetails =str(contentDiv).split(\'<hr/>\')[1:]\n\n\nfor content in celebDetails:\n\tcontentSoup =\tget_bs(content)\n\timg=contentSoup.find(\'img\')\n\tname =\tcontentSoup.find(\'strong\').get_text()\n\tlinks   =contentSoup.findAll(\'a\')\n\tpTags =contentSoup.findAll(\'p\')\n\toccupations,quality=get_details(pTags)\n\tbio=pTags[-1].get_text()\n\tprint(name)\n\tprint(img)\n\tprint(links)\n\tprint(bio)\n\n ```\n\ntry this. It is not best solution so If you find a better one let me know']"
You need to verify if you're a person or a bot when using googles advanced parameters.,https://www.reddit.com/r/webscraping/comments/10agca5/you_need_to_verify_if_youre_a_person_or_a_bot/,webscraping,"I'm writing a movieprogram using webrequests and googles advanced parameters are very handy for this.

For example, you can't search imdb's lists but when you write i.e.:

inurl:https://www.imdb.com/list/ intitle:""heist""

You find plenty of heist lists.
But googles constant verification makes it impossible to use, is there a way to circumvent the verification procedure ?",['duckduckgo.']
Can I be IP banned from a website if I try to scrape it?,https://www.reddit.com/r/webscraping/comments/109b2yg/can_i_be_ip_banned_from_a_website_if_i_try_to/,webscraping,"Basically I'm using Vinted (second hand selling platform) to sell some clothes, I also want to create simple scraping tools to understand better the price of items similar to mine and to get some statistics that could help me in my activity.  


I'm scared that if I start doing tests Vinted might block me somehow (ip ban or else), which would be terrible since I have been working on my account for a year now (I have more than 150 reviews).  


I know there are a lot of approaches to avoid being blocked (IP rotation, proxies, changing user agents..) but I haven't tested anything yet because of this fear.  


I know that complex things are easy once you have the whole picture, so I'm wondering if anyone with that level of knowledge could assist me on that.  


Thank you in advance :)","['Yes, it is definitely possible to get IP banned from scraping. Even when doing your test scripts, I recommend using a proxy that doesn‚Äôt leak.', 'You might check for a robots.txt file, if present it might list a query interval. For testing and small jobs I typically just set the delay to 3 or 4 seconds per request,1.5-2.5 was getting me blocked from certain sources', 'If you are only scraping at small volumes then you could just use the free plans of some of the paid proxy providers. Some have free plans with 10,000 free requests per month. [Check out this list.](https://scrapeops.io/proxy-providers/comparison/free-proxy-providers)', 'Try creating a throw away account and run code from that account.', 'They‚Äôre really easy to scrape. I‚Äôve built one. Use aws lamda and you‚Äôll be fine', 'If you are afraid of getting ip banned you can always try a VPN', 'yes very common', 'yes', 'Honestly, what content does Vinted have that is worth scraping?']"
Looking to scrape all the svg files on the internet (or at least a lot of them). Anyone has any thoughts on how to do that?,https://www.reddit.com/r/webscraping/comments/109lqmo/looking_to_scrape_all_the_svg_files_on_the/,webscraping,"It‚Äôs somewhat straight forward to land on a page and identify all the places where a url points to an svg or an svg tag appears explicitly in the html. 

The piece I‚Äôm struggling with might be super trivial to more accomplished scrapers out here: how do I find a seed list of reasonably professional websites to scrape (assuming professional websites have higher quality svgs generally). 

And also probably a basic question: given the landing page of a domain, it‚Äôs there any simple way to determine all the pages on that domain so I can scrape it?

I‚Äôm pretty handy with selenium but the basics of how to do mass scraping escapes me.",[]
Scrape Instagram posts,https://www.reddit.com/r/webscraping/comments/1093gcr/scrape_instagram_posts/,webscraping,"When you `add ?__a=1&__d=dis` to an Instagram post URL like this `https://www.instagram.com/p/CnEl_HyM0_H/?__a=1&__d=dis` you get a lot of JSON data returned with info on an Instagram post. This even works in incognito mode when logged out. 

However when I try to access this using node.js on a render.com server I get:

    {""message"":""Please wait a few minutes before trying again."",""require_login"":true,""status"":""fail""} 

I get the same response when accessing the page throug a TOR browser. Any idea how I could fix this?","['Even in incognito mode, your browser can add a guest id in the request header.   \nHave you tried to pass the header from your browser in your node.js script ?', ""It's because datacenter IPs (and definitely Tor exit node IPs) are blocked by default. You will need at least residential IPs for scraping Instagram.\n\nBTW, I wrote a blog post on [scraping Instagram](https://scrapingfish.com/blog/scraping-instagram) some time ago, you might be able to borrow some code.""]"
Is this a fair price for web scraping?,https://www.reddit.com/r/webscraping/comments/1097o1y/is_this_a_fair_price_for_web_scraping/,webscraping,"Hi all,

After messing around with Github and realizing I know absolutely nothing about Python, I'm thinking about commissioning someone to do a project using Python script to scrape the Jeopardy archive at [J-archive.com](https://J-archive.com) into CVS files using 6 fields (air date, round, category, value, answer and question). I wouldn't be looking to scrape the entire archive, but instead from the year 2020 to the current date. Here's a few examples of parsers that perform(ed) this job featured on Github repositories: [https://github.com/whymarrh/jeopardy-parser](https://github.com/whymarrh/jeopardy-parser)

[https://github.com/jbovee/j-archive-parser](https://github.com/jbovee/j-archive-parser)

Knowing nothing about Python, I have been unable to get those parsers to work for me, so I took to Fiverr in order to get a quote on how much it would cost to have someone do this. After chatting with the guy for a while he said he could do it and asked me what my budget was, which I found a little curious because I was assuming he was going to quote me at least some kind of rough price and then we'd go from there. When I responded that I didn't come in with a set idea for a budget and instead am looking for someone who can perform the project and give me an estimate on a price he came back with $130. When I told him to let me do some more research and think about it he immediately dropped the price to $90, which is the point where I started to get car salesman vibes.

I don't know what a fair price for a project like this is, and I'm certainly not disputing that this price may very well be fair, and obviously I want this deal to be good for both sides, but how we got to that figure made me think I better at least go to Reddit and ask.

Also, is Fiverr OK to be going to for a project like this? The last thing I'd want to do is drop $100+ on a project and not have it work as intended.","[""well you opened negotiations by saying you don't have a set budget, don't be surprised he started negotiating"", ""Pricing varies widely. I think you could get it done for less, but I don't think he's ripping you off. Scraping is relatively simple and can be done anywhere in the world, so it doesn't cost much. It usually only gets expensive if you want to scrape difficult sites routinely. You have to pay significantly more for guaranteed success month after month.  \n\n\nYou should only pay him for his work after he has provided a preview of the data."", 'when you are web scraping for a living, sometimes you assume projects that turn out to be completely different from your expectations when estimated it‚Ä¶ sometimes you‚Äôll get lucky, but most of time there‚Äôs always be an risk of getting screwed with extra work‚Ä¶ so yes imho he‚Äôs not ripping you off, mostly he‚Äôs just desperate to get something to work with', 'DM‚Äôd you a cheaper alternative', 'Im like web scrapig, this page is a little easy for get the data with web scraping. check the `table` in http for get all data of ech page and the link page only change one number.\n\nBut this is the work of the guy. The cost depend of time for maked the script.']"
Scraping embedded Google Slides?,https://www.reddit.com/r/webscraping/comments/1095z54/scraping_embedded_google_slides/,webscraping,"There's a website with over 40 embedded Google Slides (download, print disabled). Are there any tools to scrape or automate taking screenshots of the Google Slides?",[]
StaleElementReferenceException,https://www.reddit.com/r/webscraping/comments/1090134/staleelementreferenceexception/,webscraping,"im using python3 selenium with firefox.

how can i avoid this particular exception? it seems like everytime i try to do a loop over elements i get this exception sooner or later.

&#x200B;

    data_and_resources_ul = driver.find_element(By.CLASS_NAME,'resource-list')
    csv_or_tsv_total = data_and_resources_ul.find_elements(By.CLASS_NAME,'format-label')
    for csv_or_tsv in csv_or_tsv_total:
            csv_or_tsv.click()
            time.sleep(1)
            navbar = driver.find_element(By.CLASS_NAME,'tabs--primary')
            all_buttons = navbar.find_elements(By.TAG_NAME,'a')
            back_to_dataset = [a for a in all_buttons if a.get_attribute('href').endswith('dataset')]
            back_to_dataset[0].click()
            time.sleep(1)

this is my code csv\_or\_tsv.click() takes me to a new page so new url then i will add more code there after that i press back\_to\_dataset\[0\].click() takes me to the previous page where csv\_or\_tsv\_total exists.

so my for loop should not fail because the same elements where gathered in the first place when i was on that page initially.

the for loop crashes on second iteration with StaleElementReferenceException

how can i fix this?",['Try finding the element again. Treat it as though the element has changed. So you have to grab it again.']
Online services to run selenium scripts with GUI,https://www.reddit.com/r/webscraping/comments/108z1gj/online_services_to_run_selenium_scripts_with_gui/,webscraping,"Hi everyone!
I am working for a client and he asked me to scrape Craigslist. I made the script in selenium Python. Now he wants to run that script on some online server/cloud service. But I do not have any experience in that.
I tried digital ocean droplet with Ubuntu OS but it did not work and everytime I start the script it gives some error. 
Actually the script does not have headless web driver and the droplet is purely command line. I tried installing GUI libraries but many of them Did not work or they were very slow.

So is there any other online service with Windows OS or any other with GUI?","['Here is the best way to go about it IMO:\n1. Get a Linux server, standard Ubuntu server ( [here](https://m.youtube.com/watch?v=NKc3k7xceT8) is a tutorial for an always free cloud machine)\n2. Install docker on the machine ([link](https://docs.docker.com/engine/install/ubuntu/))\n3. Run the selenium/standalone-chrome image\n4. Run your selenium script\n[Here](https://stackoverflow.com/questions/45323271/how-to-run-selenium-with-chrome-in-docker) is a stackoverflow question that can guide you.\n\nIf you need to schedule the script (run it every day, look into cron jobs).\n\nIf you have any questions I can help you out.', ""Why do you need windows? \n\nAnyway i ran selenium scripts in the past using heroku. They have some sort of plugin system, it allows you to install selenium\n\nEdit: I found some tutorial for digitalocean + selenium just now, so i'm pretty sure it can be done on there too""]"
"What do these Fiverr ( Indian , Pakistan etc) Guys do for scraping any different than Google Search?",https://www.reddit.com/r/webscraping/comments/1091mnd/what_do_these_fiverr_indian_pakistan_etc_guys_do/,webscraping,"I've asked some guys to go to some webpages and scrape some companies leads for me.   
They say ' I can't see the data' on that page.   
What basically comes down to, they do what anyone can do and they just put it on excel file.  
I ask them 'what can you find as results that I can't find on Google Map or Google Search', none of them could give me a sharp answer.  


They call it scraping and all fancy words but they basically google search and go through first 1-2 pages and get information  that way.  


How's that scraping? How's that different than 'google search normally' ?","[""Scraping is just collecting data that is available on the internet, usually in an automated way.\n\nAutomation is just to save time, it would take months to go through, say 100k pages manually, someone can automate that in a few hours potentially.\n\nIt's not magic though that can get information that is not available otherwise."", '[deleted]', 'what most of those lead services provide are webcrawlers that normally will fillow a start point ‚Äúgoogle‚Äù and after that they will read websites returned and will try to scrape content from them in a certain depth, I will adsume that none of them are going as far as you want, because they are not intent to do that in first place what you are describing is a little more specific than what it is available in your regular Fivveer freelancer.\n\nI used to freelance over there 2 years ago and I am trying to start over again, but speaking for my personal perspective(and no offense intended) I never did nor intent to do webcrawlers because costumers looking for those are always trying to squeeze every single peny they are expending for those leads they are sp desperately looking for, with no regards about how hard it is and how much tine did it took you to write it down or how low are they dropping the ball on their budget.\n\nWebcrawlers are amazing, I got myself wanting to write a solution alike for many many years, but I always stoped because when you step back and look at the big picture, you just realize that they are normally the trashiest services on this particula field.', ""What data are you trying to get and what are they providing?  It is very unclear from your post.\n\nI wouldn't expect anything totally revolutionary for 5 bucks.""]"
What would you like to see in a free scraping service?,https://www.reddit.com/r/webscraping/comments/108krfw/what_would_you_like_to_see_in_a_free_scraping/,webscraping,"Hello Everyone! I am running a scraping startup.

I think most services are ridiculously expensive and I would really like to give back to the community by offering a free tier that would suit most or even all personal needs.

So my question to you guys is how many requests per month would you like to see in such a service for free? Please be honest and realistic. I would love to give everyone milions of requests per month for free, but there are significant costs associated with running such an infrastructure.

What kind of features would you like such a service to have?

Currently I offer 2 main functionalities:

* Scraping API. It returns data from a target URL using proxies either purely as HTML or scraping specific fields and returning them as JSON
* Crawling. In the user panel users can configure scraping profiles to be used for different web pages with an UI that allows you to interactively click on elements of the target page to be selected for scraping. Full website crawling is configurable by creating a crawling agent which consists of list of URL patterns which should either be followed and/or scraped using an extraction profile. All this can be run as a job resulting in a JSON or CSV file with rows populated from all scraped pages.

The bottom line is I want to understand what you would like to see in a free tier of such a service and I will try my best to meet it.

Thanks for your time!","['In my case, I have a list of company names and only need the company url', 'for functionality‚Äôs I would say the same level you can find at PhantomBuster‚Ä¶ what they have there is quite efficient', 'For non tech users a nice UI where they enter in their desired fields easily (say comments from a page), a decent number of API calls, or built in cookie deflections when needed. If you could scrape TikTok comments that would be ü§Ø\U0001fae1', 'The ability to export data to rss feed or other application like discord/telegram']"
Need a recommendation for good residential proxy services provider,https://www.reddit.com/r/webscraping/comments/108hys9/need_a_recommendation_for_good_residential_proxy/,webscraping," 

Hi,

I'm working on a small project for personal use (nothing commercial) and I want to try residential proxies to avoid getting CAPTCHA challenges.  
I want to buy a few GB for a trusted/premium provider cause I need those proxies to work at the money time.  
I've contacted Oxylabs but they won't access my url (although my project is 100% legit).  
I also see that this kind of URLs are also banned in Smartproxy, both of the providers have an extensive list of urls that they won't serve.  
Few questions to the experienced folks here:

  
1. Can any of you recommend a legit/trusted provider which has a pay-as-you-go plan and will sell few GBs at a reasonable price (10-20 $ / GB) and doesn't have that strict compliance   
and won't let me down with low quality addresses ?  
2. What do you think of Packetstream.io ? I see a lot of complains about people that share their bandwidth getting paid for the traffic they share, but what do you think about the IPs they provide to their clients ? I'm sure they aren't on par with Oxylabs but for me as a client, will it be throwing away 50$ ?  
Thanks for your words of wisdom","['May I suggest a slightly different approach and not answer your question directly?  \n\n\nIf it is for a personal project I presume you wont generate an insane amount of traffic.\n\nYou can deploy your own residential proxy using a Raspberry Pi for example and a 4G stick + sim.  \n\n\n1. Install Ubuntu\n2. Install ZeroTier or TailScale peer-to-peer VPN (they are free for personal use). This will allow you to access the Pi using its VPN IP from another computer on the same VPN network.\n3. Install the 4G stick\n4. SSH using the VPN IP to verify everything is working.\n5. Install an HTTP proxy service. There are plenty of choices which you can install with a single command\n\nDone. You have your own residential mobile network proxy. This is actually the most expensive type of proxy on the market.\n\nHint:  \nSome carriers allow you to have a duplicate SIM to your main contract which will share the voice and data quota from your main card for just a few bucks a month. Here in Bulgaria you can get it for 2 EUR per month.  \n\n\nBonus points:  \nMobile carriers do not guarantee you a dedicated IP, which actually might benefit you. The IP will change from time to time. If it is every few hours or days, noone can say, but still.', '[SOAX residential proxies](https://soax.com/residential-proxies/?utm_source=social&utm_medium=reddit&utm_content=answer) would fit your purposes: reasonable pricing, reliable and stable service and a wide pool of IP addresses, what is more - they have a customer support included to each tariff, so you could get consultation on using proxies for your project.', 'Whats the website you are trying to scrape?', 'Not a proxy service but Mysterium VPN is a cheap VPN that has residential IPs selfhosted by users.', 'Why not doing this from your home? ü§î', 'Please give it a try, I am using it for my personal use and it running smoothly too: https://quickscraper.co/']"
"I was temporary kicked off of LinkedIn, and now my account has been reinstated. When should I start web scraping again?",https://www.reddit.com/r/webscraping/comments/108m6cg/i_was_temporary_kicked_off_of_linkedin_and_now_my/,webscraping,"[here‚Äôs a little background of my story.](https://www.reddit.com/r/webscraping/comments/1071d9r/how_many_li_sn_urls_can_i_convert_to_a_li_public/) so now that Lincoln is working for me again, when should I start back to using my PhantomBuster to scrape about 200 to 300 profiles day?",[]
telegram channels,https://www.reddit.com/r/webscraping/comments/1088sjs/telegram_channels/,webscraping,Any one can help me how to scrap telegrams channels text with python! What is the best ways to do that?,['You can use python module telethon although be carefull with guidelines because I got myself banned while I was playing around with it.']
How to use bs4 to extract only the size available ?,https://www.reddit.com/r/webscraping/comments/1081feg/how_to_use_bs4_to_extract_only_the_size_available/,webscraping," 

Currently working on a project, my goal is to create a scraper to check only the size available of each item with bs4

Website of interest: [https://www.6pm.com/p/gbg-los-angeles-ayvie-slate/product/9479982/color/642?zlfid=192&ref=pd\_detail\_1\_sims\_cv](https://www.6pm.com/p/gbg-los-angeles-ayvie-slate/product/9479982/color/642?zlfid=192&ref=pd_detail_1_sims_cv)

I‚Äôm trying to extract only the available size without showing the size that are not available.

&#x200B;

What i have done : 

size = soup.find('div', {""class"": ""zna-z Ana-z""}).text

print(size)

Return : 5.56.577.588.5 

&#x200B;

and when i try this one

size=soup.find('div', {""class"": ""dqa-z""}).text

Return :5.5     

&#x200B;

My expected return is to get only available size like ‚Äú 6.57 ‚Äú  ( size6.5 and size7) because there are the one available i appreciate any help my way!","['Might not answer your specific question but when you load the page one of the script tags at the bottom has LOADS of data that if you dig into gets you the data you want (stock, price, sizes, styles) and hopefully answers the questions you\'ve been looking for help on.\n\nYou can extract the data like this:\n\n\n    import requests\n    from bs4 import BeautifulSoup\n    import re\n    import json\n    \n    url = \'https://www.6pm.com/p/gbg-los-angeles-ayvie-slate/product/9479982/color/642?zlfid=192&ref=pd_detail_1_sims_cv\'\n    \n    headers = {\'User-Agent\':\'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\'}\n    \n    resp = requests.get(url,headers=headers)\n    print(resp)\n    \n    soup = BeautifulSoup(resp.text, \'html.parser\')\n    \n    search = \'window.__INITIAL_STATE__ = \'\n    \n    dirty = soup.find(""script"", string=re.compile(search)).text\n    dirty = dirty.replace(search,"""")[:-1] # remove initial and end characters to leave only the json data\n    clean = json.loads(dirty)\n    \n    #loads of data here\n    print(clean[\'product\'][\'detail\']) #endpoints for sizes and stlyes includes prices and stock ""onhand""\n\nYou can explore the json yourself, to find what you are after', 'Well bushcat69 is the better way but If like another way with out parsing json you can use this way\n\n""""\nfor tag in div:\n\tinputTag =\ttag.find(\'input\')\n\tif \'checked\' not in inputTag.attrs and not (inputTag.attrs[\'aria-label\'].endswith(\'Out of Stock\')):\n\t\tprint(inputTag)\n""""\n\nparsing all the div tag with class \'dqa-z\'.It will only print input tag with available size.']"
what do you do when you get a access denied for trying to get an url? (Python Selenium),https://www.reddit.com/r/webscraping/comments/107e5cw/what_do_you_do_when_you_get_a_access_denied_for/,webscraping,"&#x200B;

https://preview.redd.it/06zjmlfuo0ba1.png?width=1239&format=png&auto=webp&v=enabled&s=5c92ff00c29ad5fb0437a01debd9ddcb374fce82

im trying to call an url many times for webscraping.

    for i in international_data_indicators:
        for y in countries:
            url = f'https://www.migrationdataportal.org/international-data?i={i}&cm49={y}'
            driver.set_page_load_timeout(10)
            driver.get(url)
            time.sleep(1)
            driver.delete_all_cookies()```

i get the following error attached as picture and basically im blocked, i tried clearing cookies and cache but it didnt work as you can see.

what can i do?

im using python3 and selenium with firefox","[""Your IP address is being blocked, you'll need to use proxies to bypass the IP detection.\n\nhttps://www.browserstack.com/guide/set-proxy-in-selenium"", ""I'm always surprised proxies are still not the default, any website that holds data that's worth scraping will block IPs that send too many requests. There's a quick Selenium integration on this [proxy](https://brightdata.grsm.io/vitariz-proxy) provider's platform.""]"
Web Scraping React Web,https://www.reddit.com/r/webscraping/comments/107hav4/web_scraping_react_web/,webscraping,"Hello, how I can to make web scraping to this page using python ?

[https://rollercoin.com/network-power](https://rollercoin.com/network-power)",[]
is there any way to get member details of telegram channel?,https://www.reddit.com/r/webscraping/comments/1079ih9/is_there_any_way_to_get_member_details_of/,webscraping,I'm not the channel admin.,"['This is the only thing I can find: https://os2int.com/toolbox/investigating-telegram-users-user-groups-and-extracting-youtube-metadata/', 'Following', 'Try Telethon\nhttps://github.com/LonamiWebs/Telethon/wiki/Retrieving-all-chat-members']"
How many LI SN URLs can I convert to a LI Public URL in a day without getting sanctioned?,https://www.reddit.com/r/webscraping/comments/1071d9r/how_many_li_sn_urls_can_i_convert_to_a_li_public/,webscraping,"[I got this error on LinkedIn today after scraping about 1,200 LI URLs to convert them into a public LI URL.](https://imgur.com/a/6q9QdiO) I was using the [Sales Navigator URL Converter](https://phantombuster.com/automations/sales-navigator/9068/sales-navigator-url-converter), and **I'm very nervous to make sure that this doesn't happen again.** 

I have another LI account that I plan on upgrading into a LI SN account. I've had this account for 2.5 years, and I have 100s of connections, and it's got a ""low spam score,"" for a lack of a better term. 

Anyways, I have already ~2,400 LinnkedIn Sales Navigator URLs that I've converted to Public LinkedIn URLs, and I'll need to scrape about 5,000 more. 

How many should I do in one day so that I don't have my account terminated?

I've scraped from a LI SN Lead List using dataminer.io, and I can do thousands of those daily, so I was a bit surprised that I can only scrape ~1,200 LI SN accounts today.","[""if you scraped 2,000 leads from LISN, then you should be able to scrape 1,000 in a day. I don't know what happened to you."", 'Most people recommend a couple of hundred, 200-300. From my limited experience that works over a longer period of time, but it might be a low estimate, especially if you do it only for a couple of days.']"
how to scrape hidden input value with bs4,https://www.reddit.com/r/webscraping/comments/1075ghr/how_to_scrape_hidden_input_value_with_bs4/,webscraping," 

Currently working on a project, my goal is to create a scraper to check the availability of item with their respective sizes (stockId) with bs4

Website of interest: [https://www.6pm.com/p/bogs-b-moc-mid-winter-painted-black-multi/product/9419937/color/80?zlfid=192&ref=pd\_detail\_1\_sims\_cv](https://www.6pm.com/p/bogs-b-moc-mid-winter-painted-black-multi/product/9419937/color/80?zlfid=192&ref=pd_detail_1_sims_cv)

I‚Äôm trying to extract the data from the ‚Äúonly # left in stock ‚Äú and the size inside the <input type:hidden class.

so normally, a website will have out-of-stock on an item by default (if it's out of stock). for this specific site, the user needs to select a shoe size before the target scrape ""only # left in stock‚Äù if inventories are less than 10 for that specific size autherwise nothing is scrape .

What i have done : 

value = soup.find('input', attrs={'name': 'stockId'}).get('value')

print(value)

Return error

My expected return is to get Each size and know ‚Äú only # left in stock ‚Äú respectively if applicable.

i appreciate any help my way!","['There are few different thigns here.\n\n1. You need to click on the size to possibly get this displayed\n2. In order to automate this please look into Selenium or Playwright, can\'t do this with BS4 only\n\nIn general, I would do something like this:\n\n- click on the desired size\n- add if statement, something like: ""if this div is displayed get the value, else add 0 or \'none\' as a value""\n\nThat\'s the rough idea how I would go about this.']"
Scraping only prices from 50 websites,https://www.reddit.com/r/webscraping/comments/1074ycw/scraping_only_prices_from_50_websites/,webscraping,"Hi 

I want to scrap prices from websites to compare the prices from cheapest to expensive?

For ex: I want to scrap price for the best crms out there and wants to list crms from cheapest to expensive and same scenarios for like web hosting or any other niche

There are more then 50 CRMs out there and wants to list them under one roof 

And then wants to create a bot that will check and update the pricing every 3 hours.

Someone has done it for domains as they have their apis
https://www.domcomp.com/

But what about who doesn't have APIs?","['Well if I understand you correctly you want the simplest way to webscrape prices and compare them.\r  \nSo you have the same option as usual.\r  \n1. Use some kind of app (some are paid).\r  \n2. Write and maintain your own code this would need attention.', 'This is a two part problem.\n\nCrawling/Scraping.  There are services you can use. Actually I run my own service and I can hook you up with a discount and/or a free bundle to get you started. If you are interested - DM me.\n\nData ingest. Getting the data is one thing, but ingesting it, structuring it and displaying it in a meaningful comparison is another topic. You will have to provide a bit more details. Maybe 1-2 example websites and is it just prices you want to compare? It kind of sounds like it from your post, but if you want to offer this as a service I suspect this is not enough and you will likely want to compare functionalities, limitations, different features per price tier, etc.\n\nI am curious to learn more.', 'Why do you need to check CRM pricing every 3 hours?']"
Price Scraping and Monitoring Bot,https://www.reddit.com/r/webscraping/comments/106tqgo/price_scraping_and_monitoring_bot/,webscraping,"Hi 

I'm a beginner here 

Is there any readymade script out there with which I can scrap prices from websites to compare the prices from cheapest to expensive?

For ex: I want to scrap price for the best crms out there and wants to list crms from cheapest to expensive and same scenarios for like web hosting or any other niche

How can I do this? Any tool available?  Or do I need a developer to make a bot for each crm provider to get pricing and automate that","[""You don't need a developer to build this scraping. It's one of the simple use cases. You can build this scraping using a no-code scraper. Basically, you configure the URL and the XPath of the pricing HTML elements, and it retrieves the data. \n\n[Byteline WebScraper](https://www.byteline.io/web-scraper?utm_source=reddit&utm_medium=webscraping&utm_campaign=scraper) makes it pretty easy. It also provides a Chrome extension to help you pick the XPaths."", 'there are some tools that are ‚Äúgoogle search‚Äù oriented but they normally sux like badly, they are normaly used to find emails and more simple data such as phone numbers, if you want consistency and quality content you first start by defining the websites you want prices to compare to and then yes, I would say you‚Äôll need someone to write something custom for you, but hopefully I‚Äôm wrong and you‚Äôll find something usefull, doesn‚Äôt hurt trying.']"
Gather public facebook events,https://www.reddit.com/r/webscraping/comments/106n33r/gather_public_facebook_events/,webscraping,"Hello!

I want to fetch Facebook events in my city. Unluckily, it seems like the API only provides this data to ""Facebook Marketing Partners"" (see [https://developers.facebook.com/docs/graph-api/reference/event/](https://developers.facebook.com/docs/graph-api/reference/event/))

&#x200B;

So, naturally webscraping is the only possibility left. However, I am concerned that facebook will detect that I automate stuff and just block my account if I scrape the website every few hours.

Is there another way to solve this problem? I guess keeping the session cookie and not always relogging is a must, otherwise I will run into captchas quickly. Has anyone ever tried this and can recommend something?",[]
How to scrape phone numbers from groups on WhatsApp?,https://www.reddit.com/r/webscraping/comments/105ymmb/how_to_scrape_phone_numbers_from_groups_on/,webscraping,Is there some way?,"['I did it once using puppeteer, I don‚Äôt quite remember fully right now(it was two years ago), but it was something like this:\n\nopen web.watsapp on puppeteer, then there‚Äôs some option that you can set to define sessions to be stored in a local folder‚Ä¶ after you conclude your session you just need to point your session to that same folder and presto, you bypass authentication and other verification methods and can just focus on harvest data', 'What I can think of right now is opening WhatsApp in a web browser and do some selenium.', ""You'll need to be a member of those groups first, and that is not public data!""]"
Has anyone found a way to get around LinkedIn's login wall to scrape content?,https://www.reddit.com/r/webscraping/comments/105r0iq/has_anyone_found_a_way_to_get_around_linkedins/,webscraping,"I'm particularly interested in scraping LinkedIn Jobs info and public posts. 

I know there's a Developer API, but I'd prefer not to sign up for that.

I've also tried signing up for an account and using it to scrape, but its been suspended. 

Any help or info would be great. Thanks in advance!","[""LinkedIn is probably the hardest and/or most expensive website to scrape. There is no real way around using expensive proxies. Aside from that I haven't encountered any issues."", 'those really people interesting in scrapping linkedin??\n\nwhat iinformation you look for there ??', 'just log in, use a cookie inspector and set them on your script along with the same user agent from the navigator you used too', 'You may try extracting google search results by site:linkedin.com and sort by time.', 'Pm me', 'Getsalesfox.com - using cookies', 'Scrapeops.io has a [guide](https://scrapeops.io/python-scrapy-playbook/python-scrapy-indeed-scraper/) with scrapy', 'Hi,\n\nTry [Proxycurl](https://nubela.co/proxycurl/linkedin), it is intended for this. They also [wrote an article on how to bypass authwalls here](https://nubela.co/blog/tutorial-how-to-build-your-own-linkedin-profile-scraper-2020/).', 'Hi. I think i can help you with that. please check out the newly released software I develop https://myfolder.notion.site/myfolder/Phantom-Connect-0aedc60ce03043cc83f8fd55aa558d9c']"
"Is there any webscraping bot, to extract booking.com price information?",https://www.reddit.com/r/webscraping/comments/105pq5r/is_there_any_webscraping_bot_to_extract/,webscraping,"There are free webscraper with them you can extract Hotel informations, rooms & prices on booking.com, if you pretending your travel date and the Hotel.

What I'm searching is something like a bot, extracting the Hotel price based on random travel periods and dates automatically. 

This data set could be analyzed to find pricing errors.

Is there any tool that can be used that way?
I have no programming skills. How difficult is it to sketch a tool doing this kind of work?","[""I wrote an in-depth tutorial on [how to scrape booking.com with Python](https://scrapfly.io/blog/how-to-scrape-bookingcom/) and it's a pretty easy scrape!\n\nFor scraping pricing I found it's best to select values from the pricing calendar as you can get pricing of 30-60 days in a single request!"", ""I'm currently working on the exact project using selenium python"", 'Hopefully it will be ready soon', ""If you guys need real time price information for hotels/air/car/etc (not free), DM me, I got that data.\n\nMight not be exactly what you see on [booking.com](https://booking.com), but it's live data.""]"
extract ebay user listing...,https://www.reddit.com/r/webscraping/comments/105vxmu/extract_ebay_user_listing/,webscraping,"so i'm working on project that helps you to extract ebay user all  listings with price and and all related informations

those that worth trying ?

will anyone be intersting in that ?","["" I've recently worked on getting (via scraping) daily updates on competitor vendor (up to 5) prices in walmart online store."", 'Hello, I am interested. I am a professional web scraper on Upwork and I have completed 50+ data extraction projects and 415 hours on Upwork.\n\nSend me a message with the detail about the project. \n\nThank you.\nKHALIQ.']"
How to scrape Google Trends 'related queries' and auto pull every hour?,https://www.reddit.com/r/webscraping/comments/105osgg/how_to_scrape_google_trends_related_queries_and/,webscraping,"I've tried to use Axiom, Zapier, Python script (not very good at Python though) and can't seem to figure it out, especially trying to get the script to click the arrow key to go to the next 5 results and so on...  


Any help would be great.  


Just to confirm, this is a specific query in Google Trends, specific category, I want to scrape the 25 related queries that appear, and then re-scrape every hour.",['Have you tried https://github.com/GeneralMills/pytrends?']
"Any thoughts on how to ""scrape"" a websocket?",https://www.reddit.com/r/webscraping/comments/105e1gt/any_thoughts_on_how_to_scrape_a_websocket/,webscraping,"I'm trying to build a dataset and it's going 'ok', up until trying to ""catch"" all the traffic from the games on [this website](https://acquire.tlstyer.com) (link to code on site).

Part of me says ""Selenium"", but part of my wants to leverage having a copy of the server code. Can I use any methods from the code to ""decode"" the websocket messages?  I've scraped plenty, but websockets are new to me for scraping.","['The other ""tricky part"" is that I kind of want to capture about a year\'s worth of games (or at LEAST a month\'s worth).  So I was thinking of running a VPS and dumping each day to a CSV of \'moves\' or \'games\' or something.', 'Which pieces of data do you need? Are they present on the page, or do you need to access the raw websocket data?', 'You can create web socket connections in any programming language']"
Ideas for how to pull HTML from a dynamic web page? (i.e: page source doesn't show all the items on the live web page).,https://www.reddit.com/r/webscraping/comments/1058heb/ideas_for_how_to_pull_html_from_a_dynamic_web/,webscraping,"Hi all,

I am trying to scrape information from this web page (https://ircc.canada.ca/english/newcomers/services/index.asp#table1caption, set show locations to all), but I'm having trouble getting the HTML I want to scrape.

I'm on Firefox - when I right click to view source, the information for each row of services isn't in the HTML. However, when I right click and inspect, I see the HTML for the information I'm interested in.

Does anyone have insight into how I can get the HTML from inspecting? I've tried googling my problem, but couldn't find anything. Thanks in advance!","['It seems the service info you want is loaded after the fact, hence why it isn\'t in the page ""source"" but is present when the page is inspected. I\'m not sure about FF, but in chrome you can inspect the page, pick a parent element for the data you want and just do a right click -> copy -> copy element. That table with id table1tbody should do nicely after setting the display to All. If you\'re looking for a programmatic solution to pull data from dynamic pages then selenium will do it, though it may be overkill for this', 'Load the page up and go to the developer tools, and then sources at the top for chrome or debugger in firefox. under services there\'s a file with all the table data in, its called ""services-info"". I\'d just save it and parse it', ""What you are describing is called Single Page Application. It loads a minimal HTML page along with the javascript. Then the browser evaluates it and generates the HTML content on the fly.\n\nThe page you shared is not a classic example, but it seems to also generate the content you are interested in using JavaScript.  \n\n\nFor this type of web page you need a browser to obtain its contents.   \nI suggest you use Puppeteer. It will help you manage headless browser and use it to send requests and receive the data you need.\n\nIf you don't want to bother with the implementation you can use a scraping service.  \n\n\nDM me if you need any help.""]"
need help with puppeteer radio button clicking,https://www.reddit.com/r/webscraping/comments/104yosd/need_help_with_puppeteer_radio_button_clicking/,webscraping,"im using puppeteer to automate a survey, but the selector id of the buttons change every time so how can i always look for the right button","[""Dm the details if you don't mind solution in selenium"", 'OK', 'Dude, use the text property', 'sometimes when you have a dynamic form is easier to listen to scripts being fired in the background than trying to physically click them‚Ä¶ use the console inspector in the network tab‚Ä¶ if you gor pne of those forma you just hit the jackpot, cause it will also give you links to next pages and even content', 'There has to be another selector. If you can share html, I can probably help.']"
A Year of Writing about Web Scraping in Review,https://scrapecrow.com/year-of-writing-in-review.html,webscraping,,
Does anyone knows how to surpass the download restrictions on Telegram?,https://www.reddit.com/r/webscraping/comments/1055xb6/does_anyone_knows_how_to_surpass_the_download/,webscraping,"So, as title says, Is there anyway to surpass the media content (images/videos) restrictions on some Telegram Channels/Groups? I mean, Telegram some months ago added a function to disable  to download content if the channel/group owner wanted to. And I want to know if it's possible to avoid that blockade and download content anyways.

Thanks in advance.",[]
Open Source AI Image Classifier with Automatic Dataset Creator,https://github.com/serpapi/serapis-ai-image-classifier,webscraping,,
"Linkedin Comments Scraper - Script to scrape comments (including name, profile picture, designation, email(if present), and comment) from a LinkedIn post from the URL of the post.",https://github.com/gurbaaz27/linkedin-comments-scraper/,webscraping,,
Best Proxy Lists?,https://www.reddit.com/r/webscraping/comments/1043rhg/best_proxy_lists/,webscraping,What reliable sources of proxies have you all had success with? Preferably places that don't break the bank.,"['ProxyAxe and webshare are two that have been recommended before on here.', '/r/Proxylists and /r/ProxySites may interest you as well. I second the webshare recommendation, FWIW', 'Hey guys with I am a private 4G proxy provider based in Ireland. As I would not want to promote here you can DM me for details if you are interested.\nHave a great', '[removed]', '[removed]']"
"Sorry if this is the wrong sub, but is it possible to extract an email from an old youtube account?",https://www.reddit.com/r/webscraping/comments/104fxv6/sorry_if_this_is_the_wrong_sub_but_is_it_possible/,webscraping,"Basically I can't remember the email I used to create a youtube account from back in 2010. I've tried retrieving it using google's tool where you enter your phone number but I have several gmail accounts linked to the same phone number. And it showed me a dead account I no longer use instead of the three active accounts also linked to that number, so it wasn't very effective.",[]
Looking for people with datasets for sale!,https://www.reddit.com/r/webscraping/comments/1043a47/looking_for_people_with_datasets_for_sale/,webscraping,I‚Äôm looking for individuals that have data for sale. It can be any kind of interesting marketable data that another party might be interested in purchasing. I‚Äôm doing research for a project also as see if the option for monetization is possible. Thanks!,"['I could download data with web scraping of relatives important sites.', 'Sent a dm', 'I have 3+ months of daily supermarket prices, many shops.\n\nSend me a dm if u r interested.']"
Are reddit's classes names change periodically (those with random letters and numbers and what not),https://www.reddit.com/r/webscraping/comments/103xy6z/are_reddits_classes_names_change_periodically/,webscraping,"I'm building webscraper for the final project I'm doing, and I wonder is it a wise path to hardcode their names, or to just think of something else?

I saw other advice of searching through elements until I find something recognizable, but I'd rather do this because this is my first time web scraping.

I want to grab links to posts from the subreddits main page, then use those links to request HTML of these individual posts.","[""They are randomly generated strings and will change constantly. Try looking into xpaths or if you want to scrape Reddit, look at praw - it's Reddit's api""]"
Scrape Videos from multiple websites,https://www.reddit.com/r/webscraping/comments/103xtjl/scrape_videos_from_multiple_websites/,webscraping,"Hi,

I have seen many posts in this subreddit about scraping videos from one specific website. My use case is however a bit different since I am theoretically interested in all videos on the web. My question would be how would one go about this since the location of the videos in the HTML differs for each webpage, video sitemaps are not always present or use different formats and sometimes there are multiple videos like ads present.

To my knowledge, this should be possible since Google seems to be quite reliable able to identify videos on any webpage.

Thanks for your help.","['Videos should be inside video tag, no?\nAnd I think ads are mostly in iframe tags.\n\nSo scraping ‚Äúvideo‚Äù tags would make it work', 'I would like to collab. dm me']"
Anyone want to write me a program that can automate generating a pdf of a magazine subscription?,https://www.reddit.com/r/webscraping/comments/103s1uu/anyone_want_to_write_me_a_program_that_can/,webscraping,Noob here looking for a quick fix. Budget to pay you is limited.,"['Hello, send me a message I can help me you with that.', ""I can do that  using selenium python library \n\nJust send me the details \n\nI've worked on similar projects in the past one that download examination reports from indian patent site (INPASS) as another one I'm currently working on is the one that download statements of the Monetary policy from South Africa reservation Bank site"", 'ChatGBT FTW.', ""What's your budget?""]"
Scraping a Dynamic Webpage with rSelenium,https://www.reddit.com/r/webscraping/comments/1036j0g/scraping_a_dynamic_webpage_with_rselenium/,webscraping,"Hi! 

&#x200B;

I have been attempting to find a workaround for a web crawler that I am building to download a datafile file on a schedule. I have encountered a problem when trying to get the path for a dropdown menu, my problem specifically is that I just can't figure out the xpath or selector for it. 

[Here](https://opendata.dc.gov/datasets/integrated-tax-system-public-extract/explore) is the website. After navigating to the page of interest by clicking the download button, I then need to click the ""Download Options"" button to bring up a drop down where I can then click the dropdown element which initiates the file download. I've attached pics for reference of the download option button I am referencing. Additionally, I've provided my script thus far at the end. 

&#x200B;

Thank you in advance for your help! 

    # Load Packages
    ## Data Manipulation
    library(tidyverse)
    ## Webscaping
    library(RSelenium)
    ## Selenium Remote Server
    library(netstat)
    rs_driver_object <- rsDriver(
      browser = ""chrome"", 
      chromever = ""108.0.5359.22"", 
      verbose = F,
      port = free_port()
    )
    rem_dr <- rs_driver_object$client
    # Open a chrome page
    rem_dr$open()
    # Navigate to webpage
    rem_dr$navigate(""https://opendata.dc.gov/datasets/integrated-tax-system-public-extract/explore"")
    # Fit window to full screen
    rem_dr$maxWindowSize()
    # Navigate to Download Button and Click 
    rem_dr$findElement(using = ""xpath"", ""//*[contains(concat( ' ', @class, ' ' ), concat( ' ', 'btn-default', ' ' ))]"")$clickElement()
    # Navigate to Download Options and Click
    rem_dr$findElement(using = ""xpath"", ""//div//calcite-dropdown"")$clickElement()

&#x200B;

[First step in accessing the download options dropdown](https://preview.redd.it/ra5diarnp1aa1.jpg?width=1667&format=pjpg&auto=webp&v=enabled&s=a2e747be8c6e42115e3f0d00ddd33d01e270f462)

&#x200B;

&#x200B;

[Final step to initiate the download for the file](https://preview.redd.it/mzmnj2nsp1aa1.jpg?width=1667&format=pjpg&auto=webp&v=enabled&s=8fce7b7a584f8c02cc995888fe8a10843c6f0a51)","['Why not just scrape their backend api delivering the content?', 'Ya I agree but also got to your web browser download I been using selenium ide on chrome just record a test click on the button and it will give you all the things']"
Is there a way to convert LinkedIn Sales Navigator URLs to a LinkedIn public URL?,https://www.reddit.com/r/webscraping/comments/1039q3b/is_there_a_way_to_convert_linkedin_sales/,webscraping,"I have [many LI URLs but in Sales Navigator format](https://imgur.com/a/wvGHHiS), and I'd like to convert them to public profile LI URLs so that we can upload them into our CRM. My LI SN URLs are in an CSV or Excel format. 

How do I go about doing this?","['Can you show us the process of turning them public and then we can see what we can do.', 'Dm me a sample and I can help']"
Gurufocus / Implemented new cloudflare protection?,https://www.reddit.com/r/webscraping/comments/102zfub/gurufocus_implemented_new_cloudflare_protection/,webscraping,"Hello - i was scraping data from gurufocus for a long time - eg. from this site

[https://www.gurufocus.com/term/pb/AAPL/PB-Ratio](https://www.gurufocus.com/term/pb/AAPL/PB-Ratio)  


But resently i saw a new protection from gurufocus and get this page when try to scrape data:

https://preview.redd.it/6sgt2395zz9a1.png?width=1320&format=png&auto=webp&v=enabled&s=6ab9538f367de0c6880f02afcee7308d38248ff0

I can find a workaround using residental proxies eg. from smartproxy.

Is there any other (maybe cheaper) solution to still get the data form gurufocus?","[""There are a number of ways to bypass Cloudflare:\n\n**#1 -** Finding the origin server for the website and sending your requests to that instead.\n\n**#2 -** Using a fortified headless browser to solve the JS challenges. Good options are the [Puppeteer stealth plugin](https://github.com/berstend/puppeteer-extra/tree/master/packages/puppeteer-extra-plugin-stealth) and [Selenium undetected-chromedriver](https://github.com/ultrafunkamsterdam/undetected-chromedriver).\n\n**#3 -** You could also use a Cloudflare bypass tool like [FlareSolverr](https://github.com/FlareSolverr/FlareSolverr), which is a proxy server you can use to bypass Cloudflare and DDoS-GUARD protection. \n\n**#4 -** The other option is to use a smart proxy solution like [ScrapeOps Proxy](https://scrapeops.io/proxy-aggregator/) which does all 4 steps for you and includes a Cloudflare bypass built-in. You just send it the URL you want to scrape and it will take care of rotating the proxies, generating real browser headers, using a headless browser to bypass anti-bot JS challenges, and dealing with ban pages & CAPTCHAs.\n\n[This guide goes through in more detail how to scrape Cloudflare-protected websites.](https://scrapeops.io/web-scraping-playbook/how-to-bypass-cloudflare/) \n\nI've tested it with [ScrapeOps Proxy Aggregator](https://scrapeops.io/proxy-aggregator/) and that URL is working when you enable the Cloudflare bypass by adding `bypass=cloudflare` to your request. You can test it yourself by [signing up for a free account here](https://scrapeops.io/app/register/proxy).""]"
key word search,https://www.reddit.com/r/webscraping/comments/102s9rc/key_word_search/,webscraping,does anyone know a place where I can insert multiple urls and scrape them for specific keywords,"['Neilpatel.com', 'What do you mean by scraping URLs for specific keywords?']"
Scraper to collect APY data from Web3 frontends,https://www.reddit.com/r/webscraping/comments/102vcbo/scraper_to_collect_apy_data_from_web3_frontends/,webscraping,"I'm working on a project which offers auto-compounding vaults for yield-bearing opportunities across a variety of Web3 protocols/dapps. Due to the nascent nature of this industry, there aren't many reliable sources of data and it looks like I'll have to scrape a few front-ends to grab the listed APYs in some cases. For example, I need to scrape the list of farms and their associated APYs from the Sushi.com front-end.

Any recommendations for the best route to go about doing this? I personally have no experience with scraping, but have a decent grasp on Typescript, JavaScript & Python. Appreciate any guidance you can share in this regard. Thanks!","['Is it me or I don‚Äôt understand the request?\n\nIt kinda look like what I can find on r/masterhacker so I‚Äôm confused', 'Need to provide more info', 'I would go with python & beautiful soup for this task as you are navigating thru HTML trees and tables to find such data. I also assume you would want to update the data to a CSV or database of some sort.\n\nI can make this script for you as well, DM for more information\n\nHeres a bs4 tutorial by Tech With Tim https://www.youtube.com/watch?v=lOzyQgv71\\_4', 'DM me']"
Webscraper for job postings hiring physics majors,https://www.reddit.com/r/webscraping/comments/102sas0/webscraper_for_job_postings_hiring_physics_majors/,webscraping,"Hello, I‚Äôm looking for guidance on where to start with designing a program that goes through indeed and finds listings of jobs hiring a physics major to find all the potential jobs that would hire me with my physics major. I have a pretty limited knowledge of python. Thank you!","['Here is a guide and working code for [how to scrape Indeed jobs using Python Scrapy](https://scrapeops.io/python-scrapy-playbook/python-scrapy-indeed-scraper/).', 'If you want to scrape Indeed without getting blocked - this is for you:  \nhttps://www.page2api.com/blog/how-to-scrape-indeed/']"
"Your Advice: How to scrape a webpage with pagination and an AJAX ""wall "" to download pdf's after the wall has been crossed?",https://www.reddit.com/r/webscraping/comments/1024ead/your_advice_how_to_scrape_a_webpage_with/,webscraping,"Let me know if you'd like to see the link to the page.

Edit:
I am struggling to scrape this site: https://www.resbank.co.za/en/home/publications/statements/mpc-statements

What i am specifically looking to do is to go from page to page and click the links, which will open to new windows that contain pdf documents which I would like to download and zip together. I am specifically interested in the ""statements of monetary policy"" document.","['Dm with the details, I have similar similar project I just completed', ""Could you provide more details on what you mean by AJAX wall?\n\nIf you mean pagination limit e.g. there are loads of results but the max page is 10 then there aren't many options. You can try to sort the pagination from and approach it from multiple ends giving you 20 pages (e.g. sort by highest price and then by lowest). Then, if the pagination offers any filters you can apply them in various order to reach as many results as possible."", 'I would use Puppeteer Network inspector to monitor those ajax results, if they\'re not encrypted you could possibly just intercept them directly, or even find what and how they are being requested and call that function yourself... which would save you toons of work on ""navigating"" through pagination links']"
how many pages can be loaded from amazon before being banned?,https://www.reddit.com/r/webscraping/comments/1021x0d/how_many_pages_can_be_loaded_from_amazon_before/,webscraping,"I've been building a webscraper for amazon.  It takes about 1 minute per product page.   Will that let me fly under the radar?  I assume I'm fine when I run it for an hour at a time, but once I get all the bugs worked out, I want to run it basically nonstop.  Will amazon ban me for loading 10,000 pages in a week?","[""It depends on many factors starting from your IP address to the way your scraper works. \n\nScrapers can be identified in dozens of different ways^1 and assigned trust scores (how likely the client is a bot). So, the only way to know is to try and optimize your scraper from there. \n\n10,000 pages a week isn't particularly a lot but my guess would be that if you're running from a single IP with basic web scraping then it's very likely you'll get blocked. Note that banning is not very common, Amazon will simply start blocking you or ask you to start solving captchas.\n\n1 - see [this in-depth guide](https://scrapfly.io/blog/how-to-scrape-without-getting-blocked-tutorial/) I wrote if you want to learn more"", 'No I don‚Äôt think amazon will ban you even if you scraped 100 pages per second and why will they?\n\nGoogle and other search engines also use scrapers and there is no limit to search speed declared in robots.txt \n\nthis is why when you search for example ‚Äúiphone 14‚Äù on google, google shows you amazon in their search result. Because google has scraped that amazon page.\n\nBy declaring your header as google-bot‚Äôs you should be good to go.\n\nI haven‚Äôt tried it myself but, I have done a similar thing on facebook, for scraping public page‚Äôs about section, I would scrape 500 pages per minute, no ban no nothing happened']"
How would you web scrape marketwatch's virtual stock exchange?,https://www.reddit.com/r/webscraping/comments/101u3b9/how_would_you_web_scrape_marketwatchs_virtual/,webscraping,"Hi, I'm new to all of this. I just want some general pointers and maybe links to some tutorials for web scraping Marketwatch and creating orders in its virtual stock market exchange -[https://www.marketwatch.com/games?mod=side\_nav](https://www.marketwatch.com/games?mod=side_nav)","['You would want to start with requests and bs4.\n\nRequests helps you with fetching the html data.\n\nbs4 helps you find specific elements within the html data.\n\nIf it requires javascript rendering you can learn selenium which automates a browser for your task.\n\nIf you want to make post requests i would recommend going with fiddler for beginners.\n\nFiddler is basically a program that shows you your actions on your browser for example logging into a website it will show you made a post request for logging in. You can replicate that post request to maybe login a different account. (paid program)\n\nYou can also use your browser but the downside is if the website reloads or redirects you then any post or get request will be cleared.\n\nA couple tips i can give you is always look out if the data is being via an api.\n\nHow can you tell? go to the network tab and check for any get requests that returns json data. Those will usually be delivering content.\n\nAs for post requests there are two types which people usually get confused with. Data and Json. You can tell you make post request with Data is when you look at the original payload it can look something like this  ""username=1&password=1"". With json it will look like this {""username"":""noob"", ""password"":""noob}. This would be very helpful when you try to create orders on your virtual stock market exchange via python.\n\n&#x200B;\n\nHeaders are very important as well. Many website use this as a tactic to stop web scraping bots. The most important one would be user-agent.\n\n&#x200B;\n\nYou can probably buy a course on udemy that are on discount.\n\nThis isn\'t very hard to learn so any course on youtube will do.\n\nThe subjects for your needs is just python requests, bs4, json, selenium and post requests.\n\n&#x200B;\n\nYou can also ask me any questions and ill be glad to help you out :)']"
How do you generate leads ?,https://www.reddit.com/r/webscraping/comments/101l3jg/how_do_you_generate_leads/,webscraping,"Hi everyone,
I‚Äôm just wondering how do you guys generate leads by web scraping?

I‚Äôm just thinking for example about real estate agencies and what kind of leads they might be interested in?

Any ideas üí°?",['Are you asking for sources or how do we get clients by web scraping?']
Scraping Aliexpress search page does not return all products,https://www.reddit.com/r/webscraping/comments/101k1rd/scraping_aliexpress_search_page_does_not_return/,webscraping,"

I have the below code, which I expect to return 60 products, but instead only returns 16:

    driver = webdriver.Firefox(service=Service(GeckoDriverManager().install()))
    
    url = 'https://www.aliexpress.com/w/wholesale-silicone-night-light.html?SearchText=silicone+night+light""&""catId=0""&""initiative_id=SB_20230101130255""&""spm=a2g0o.productlist.1000002.0""&""trafficChannel=main""&""shipFromCountry=US""&""g=y'
    
    driver.get(url)
    
    driver.execute_script(""window.scrollTo(0, document.body.scrollHeight);"")
    
    html = driver.page_source
    soup = BeautifulSoup(html, 'lxml')
    
    product_links = []
    
    
    def get_element_title(element):
        return element.select('h1[class*=""manhattan--titleText--""]')[0].text
    
    
    def get_product_links(soup):
        for element in soup.select('a[class*=""manhattan--container--""]'):
            link = f""http:{element['href']}""
            product_links.append(link)
            print(get_element_title(element))
    
    
    get_product_links(soup)

I manually checked the class name for all the products, since I  thought maybe some of them have different class names in an effort to  stop scraping, but they all have the same class name.

Screenshot since I think the class names are randomly generated for different people

&#x200B;

https://preview.redd.it/ri63jykmdo9a1.png?width=490&format=png&auto=webp&v=enabled&s=93588d01bcab0e6b7c857e4548002d166ccc5aa4","['Two things: have you tried running it headed, and seeing if that `execute_script` did as you requested? And then, related to that: did you check `driver.page_source` was what you expected?', 'Instead of using selenium have you tried using the back end api aliexpress uses to deliver the content?', 'Selenium is a bit of an overkill to scrape Aliexpress\' search. \n\nYou can use simple HTTP requests via `httpx` or `requests`:\n\n```python\nimport httpx\n\nquery = ""drill""\nsort_type = ""default""\npage = 1\nrespons = httpx.get(\n\t""https://www.aliexpress.com/wholesale?trafficChannel=main""\n\tf""&d=y&CatId=0&SearchText={query}&ltype=wholesale&SortType={sort_type}&page={page}""\n)\n```\n\nAll of the preview data is even available in hidden web data, so you don\'t need to parse the HTML:\n\n```\nimport json\n\ndef extract_search(response):\n    """"""extract json data from search page""""""\n    sel = Selector(response.text)\n    # find script with page data in it\n    script_with_data = sel.xpath(\'//script[contains(text(),""window.runParams"")]\')\n    # select page data from javascript variable in script tag using regex\n    return json.loads(script_with_data.re(r""window.runParams\\s*=\\s*({.+?});"")[0])\n```\n\nSee this [full guide I wrote on how to scrape Aliexpress](https://scrapfly.io/blog/how-to-scrape-aliexpress/#scraping-search) for more.', 'Question was answered:\n\n[https://stackoverflow.com/questions/74985825/scraping-aliexpress-search-page-does-not-return-all-products/74992964#74992964](https://stackoverflow.com/questions/74985825/scraping-aliexpress-search-page-does-not-return-all-products/74992964#74992964)\n\n    def launch_url(url):\n    # create webdriver object\n    chrome_srv = Service(driver_path)\n    driver = webdriver.Chrome(service=chrome_srv)\n    driver.get(url)\n    # find doc/window height and compute page count\n    doc_height = driver.execute_script(""return document.body.scrollHeight"")\n    win_height = driver.execute_script(""return window.innerHeight"")\n    num_pages = int(doc_height / win_height)\n    print(f\'doc height=>{doc_height}\\tpages =>{num_pages}\')\n    # scroll through the document\n    for page in range(num_pages):\n        driver.execute_script(""window.scrollTo(0, arguments[0]);"", win_height * (page+1))\n        print(f\'scrolling to=>{win_height * (page+1)}\')\n        sleep(2)\n\n    # get all product anchor tags\n    anc_elem_list = driver.find_elements(By.CSS_SELECTOR,\'a[class^=manhattan--container--1lP57Ag]\')\n    # get all product title tags\n    title_elem_list = driver.find_elements(By.CSS_SELECTOR,\'h1[class^=manhattan--titleText--]\')\n    print(len(anc_elem_list),len(title_elem_list))\n    for anc_elem,title_elem in zip(anc_elem_list,title_elem_list):\n        print(anc_elem.get_attribute(\'href\'),title_elem.text)']"
thread-safe: a simple tool for saving local copies of your favorite Twitter threads,https://www.reddit.com/r/webscraping/comments/101f7tx/threadsafe_a_simple_tool_for_saving_local_copies/,webscraping,"Hey Everyone,

Happy new year! I wanted to share a CLI tool I built for saving a local copy of any Twitter thread. It's called thread-safe and it's designed to do just that - keep your favorite threads safe on your local machine. This way you never have to worry that they might one day just disappear...

More seriously, I wanted a simple way to save threads of interest \_without\_ having to use a third-party app that needs access to my Twitter account (or vice-versa) and that forces me to reply to the thread to ""unroll"" or otherwise save a copy.

thread-safe generates an HTML file containing all of a thread's contents including each tweet's text, links, and media attachments (images and videos). This file, all attachments, and a JSON data file are saved to the local filesystem and the HTML can be used to display the thread locally in a browser at any time.

By using a dedicated directory for all generated files, thread-safe can be used to maintain a local library of saved threads that can easily be searched using standard commandline tooling like (rip)grep, fzf, fd, and any other awesome tool of your choice.

I built thread-safe because I often find myself saving links to informative threads and am interested in preserving the author's content. This is exactly the use case that thread-safe addresses: generating local copies of these single-authored, consecutive series of tweets. Notably, thread-safe intentionally does not save the comments or discussion from other users that follow.

[https://github.com/dkaslovsky/thread-safe](https://github.com/dkaslovsky/thread-safe)

I hope you might find it useful and I'd love to take any feedback or suggestions that might come to mind!",[]
Best web scraping api's at the moment?,https://www.reddit.com/r/webscraping/comments/1016j3l/best_web_scraping_apis_at_the_moment/,webscraping,"Hi, we are currently using 3 web scraping API's mostly for legacy reasons and to be able to have a variety of web scrapers for different sites.

I am finding 2 of these performing poorly and am looking for alternatives.

Currenly using:

ScraperAPI. Have a legacy cheaper plan so have kept it, but often it will return a 500 error when scapfly works every time.

ScrapingBee. Got in when the started and they were very good. Also noticing a lot of failures where scrapfly would work.

ScrapFly. Seems to work really well, but pissed they decided to double our price for our plan.

Would like to keep scrapfly and find another solution and get rid of scrapingbee and scraperapi.

ScrapingFish and Scrapeops Proxy look good.

Any recommendations?","[""If you're running a legitimate business just hire a developer. These scraping tools are a joke."", 'Scrapfly definitely the best at the moment, to have tested and used almost all serious web scraping api, switching to their solution was day and night for us (real estate company), \\~80 targets migrated for now, before/after stats are greatly improved. Compared to traditional proxy solution, it saves cost arround 60% due to a lower retries and the bandwidth wasted disappear', ""Ideally you should build one yourself. Nothing will perform better.\n\nStill if you don't want to maintain your own infrastructure for this, I would give [Crawlio](https://www.crawlio.net) a try - It is very similar to ScrapingBee in terms of API and is way faster."", ""At [Scraping Fish](https://scrapingfish.com), we have a very user friendly pricing which is usage based instead of monthly subscription so you don't lose unused requests at the end of every month. In addition, it's predictable as the cost of each request is the same regardless of which options you use. All requests use the same premium mobile proxy and you don't pay anything extra for JS rendering, scraping google, or other features. Please [contact us](https://scrapingfish.com/contact) if you need a free trial account to try it out.  \nYou can read more on how we compare to ScraperAPI and ScrapingBee here: [https://scrapingfish.com/how-we-compare](https://scrapingfish.com/how-we-compare)"", 'Give [ScrapeOps Proxy Aggregator](https://scrapeops.io/proxy-aggregator/) a try. It aggregates all the proxy providers together so you have access to over 20 proxy providers (including all Proxy APIs) from a single API endpoint.\n\nYou send us the request and we find the cheapest proxy provider that gives you the best performance for that target domain.', 'Scrapeninja.net is another one to try.', 'Did you try wintr and scraping ant?', 'I would recommend [ScrapeStars](http://scrapestars.com), they are team of professionals.']"
How will ChatGPT affect web scraping?,https://www.reddit.com/r/webscraping/comments/100scxg/how_will_chatgpt_affect_web_scraping/,webscraping,It‚Äôs a pretty open ended question because I just want to know the general opinions of web scrapers on ChatGPT,"['I believe that, as for all areas of software engineering, it will just reduce the Googling time at best, which may be less valuable the more experienced you are.', 'what do you mean by that? why did you union chatgpt and webscrapers? can you elaborate on this?', ""Not ChatGPT itself, but similar technologies and AI in general already has uses - mainly for unstructured data, or when you want to scrape different websites without writing a script for each - say many different ecommerce sites.\n\nAlso, GitHub Copilot (which is based on a very similar text model) is extremely useful for helping with HTML/JSON parsing code and other monotone tasks in connection with web scraping.\n\nThat said, I don't think AI will revolutionize anything here; it's just a question of a few more use cases and convenience. One possibility where things could change more may be bot detection (but those also already use AI, yet somehow, they are almost always possible to bypass).\n\nAlso I should note that while ChatGPT is a great demonstration of how advanced AI got, but it's not in itself a solution to most things, task-specific models work much better."", ""Why do ppl have such a hardon for ChatGPT? There's literally nothing intelligent about it. It's just another stats based bot that's tuned a little better than others and has the Elon sticker slapped on it. Nothing revolutionary about it... ppl so easy to hype these days.""]"
Any alternatives to Browserless.io,https://www.reddit.com/r/webscraping/comments/100z2f5/any_alternatives_to_browserlessio/,webscraping,"I really like the ease of using Browserless.io, especially when dealing with AWS Lambdas, but they seem to be too expensive and the self-hosted option would require me to pay for a license.

Are there other alternatives I could look into?

Thanks!","['[Scraping Fish](https://scrapingfish.com) has clear and transparent pricing. It‚Äôs going to be cheaper especially if you need JS rendering and need flexibility in terms of how many requests per month you do: [https://scrapingfish.com/how-we-compare](https://scrapingfish.com/how-we-compare)', 'If its for web scraping then there are a couple similar ones. ranked from favorite to least favorite in my opinion.\n\n&#x200B;\n\n[https://scrapingant.com](https://scrapingant.com)\n\n[https://www.wintr.com](https://www.wintr.com)\n\n[https://scrapingbee.com](https://scrapingbee.com)\n\nhttps://www.scrapingdog.com\n\n[https://proxiesapi.com](https://proxiesapi.com)\n\n&#x200B;\n\nYou can automate the signup process to some of these websites helping you bypass the scraping limit.', 'Crawlee', 'Can you give an estimated number of requests per month you would be requesting?\n\nI have a few ideas.']"
Here is my issue,https://www.reddit.com/r/webscraping/comments/100xmj8/here_is_my_issue/,webscraping,Selenium seems to work different on every device I use if it works at all I been trying playwright out and I think I like it but does anyone have any issues with it or suggestions or anything idk I'm board,"['I think if you post this in r/Python you would get the responses you want.', ""Ya lately I've been trying playwright I kinda like the API less extra fat on it like 3 different action modules for the same action is not needed also the async or sync option is nice that and fack that it self installs all the required driver's and all is cool I need to use it more thou really for some form filling I just haven't had time also it's smaller which I like cus a lot of sights use anti bot and JavaScript  and I feel better about just going playwright off the rip then trying requests only to get a 404 no matter what""]"
https://preservedbritishsteamlocomotives.com/,https://www.reddit.com/r/webscraping/comments/100wht2/httpspreservedbritishsteamlocomotivescom/,webscraping,"Anyone know how this site could be scraped for an offline mirror? I'm only familiar with wget and they seem to have blocked it. 

[https://preservedbritishsteamlocomotives.com/](https://web.archive.org/web/20211104032702/https://preservedbritishsteamlocomotives.com/)

Thanks in advance",['You can use requests and bs4. \n\nRequests to fetch only the html.\n\nBs4 to get any specific elements.']
Looking for python developers specialized in web scraping,https://www.reddit.com/r/webscraping/comments/zzyspg/looking_for_python_developers_specialized_in_web/,webscraping," I've been developing this automation software for almost one year. The software is PhantomBuster alternative, and it's released now. I plan to expand features that will make it more unique, and I'm looking for a python developer to join me in building software that will help people in the marketing area. More about the software - [https://myfolder.notion.site/myfolder/Phantom-Connect-0aedc60ce03043cc83f8fd55aa558d9c](https://myfolder.notion.site/myfolder/Phantom-Connect-0aedc60ce03043cc83f8fd55aa558d9c)","['Hello, I am python developer and I specialise in Web scraping. I freelance on Upwork and I will like to be a part of this project. Send me a message so that we can discuss about this better.\n\nThank you.\nKhaliq.', 'Dm me pls', 'I have two years of experience in web scraping and possess extensive knowledge of web-based automation tools such as Selenium and Playwright. I have completed several scraping projects in my recent work and would be happy to connect and learn more. You can view my work on my [GitHub](https://github.com/sushil-rgb?tab=repositories) profile for your reference.', 'My main job function as a Python dev is web scraping and automation.']"
Why can't I scraping this site?,https://www.reddit.com/r/webscraping/comments/1001jfp/why_cant_i_scraping_this_site/,webscraping,"Hi. Below python code gives all urls in a site. It works on every website i tried. But it did'nt work on one site. Site is [eksisozluk.com](https://eksisozluk.com) . Console is empty. It does not give any error. But it does not give any url although even there is. Why do you think this might be?

    import requests
    import re
    from bs4 import BeautifulSoup
    
    url = 'http://tuskolik.com'
    response = requests.get(url)
    html = response.text
    
    
    soup = BeautifulSoup(html, 'html.parser')
    
    
    links = soup.find_all('a', href=re.compile(r'/\d{6}\.html'))
    
    for link in links:
        print(link['href'])",['Have you checked the response html you actually get back?\n\nI have double checked. add some headers in there and this website has cloudflare.']
python package or regex for crawling emails?,https://www.reddit.com/r/webscraping/comments/zzuhmz/python_package_or_regex_for_crawling_emails/,webscraping,"I have a list of ~2000 unique urls I scraped for different stores. I'd like to crawl them for any emails found on the landing page or on the contacts page if there is one.
I've tried a couple of open source packages on GitHub as well as implementing a couple of email regex finders but none of them are really doing the job right.
I know I'll never be able to capture all of them, but was wondering what your preferred methods are in this case?","['The lowest hanging fruit can be captured by looping through each unique URL and appending ""/contact-us"" and downloading the information using the requests library for Python. BeautifulSoup can parse the HTML and regex can find any link or text with an email signature (regex for email id using re in Python = \'\\^\\[a-zA-Z0-9.!#$%&‚Äô\\*+/=?\\^\\_\\`{|}\\~-\\]+@\\[a-zA-Z0-9-\\]+(?:\\\\.\\[a-zA-Z0-9-\\]+)\\*$\'). \n\nThis should work for many sites because ""/contact-us"" is standard. This will fail for some Java based websites and if they do not have the standard ""/contact-us"" URL path.']"
possible to automate listing an item to sell on Ebay with python selenium in 2022?,https://www.reddit.com/r/webscraping/comments/zzjb40/possible_to_automate_listing_an_item_to_sell_on/,webscraping,"It doesn't look that simple up front because the UI looks different depending on what item category you type inside the search bar. Does anyone have a working solution that still works? I am typing this message on 12/30/2022, so heading into 2023.","['ebay have api , you may check that', 'You can use fiddler and then make a regular posting. It should show you the post request you made to make the listing. All you would need to change is the payload inside to your new listing. If you don‚Äôt have fiddler you can also use your browsers network tab']"
Life insurance leads,https://www.reddit.com/r/webscraping/comments/zzkoz9/life_insurance_leads/,webscraping,Hi I‚Äôm pretty new to this but been spending all month learning as much as I can. I‚Äôm wanting to scrape websites for potential clients looking to buy life insurance. I would really appreciate any wisdom.,"['Life insurance can be bought by anyone, so i guess... yellow pages, correlate the entries with the leaked credit score data and filter out people below a certain score :P']"
Need help with selenium and web scraping,https://www.reddit.com/r/webscraping/comments/zzcb8k/need_help_with_selenium_and_web_scraping/,webscraping," Im trying to click the marketplace icon on Facebook and it's an icon with an anchor tag. Ive read the docs and they suggest using link text and using the text between the <a></a> tags but there is no text between the tags. Ive attached an image of what the button is exactly 

&#x200B;

 [https://imgur.com/ZH28HCg](https://imgur.com/ZH28HCg)","['Instead of clicking it you can use bs4 to get the href element and then paste that in your browser.', 'You can let us know what you‚Äôre trying to achieve and then we can see what we can help you with', ""Get selenium ide for chrome or something similar and find the class name or Id or css tag something like that import By\nFrom selenium.webdriver.common.by import By\n###and to select an element\nwbd.find_element(By.ID, idname)\n\nSorry I'm on my phone and it's I'll say impossible but probably more of a pain to do code blocks on here"", 'I think you can select it by ‚Äúhref‚Äù\n\nPress ctrl+F in chrome inspect element and search for \n\n‚Äú/marketplace/?ref=app_tab‚Äù\n\nIf there is 1 href like this then you can use\n\n\nurl = ‚Äú/marketplace/?ref=app_tab‚Äù\ndriver.find_element_by_xpath(\'//a[@href=""\'+url+\'""]\')', ""Find_element(By.Name, 'Marketplace')""]"
How to scrape data that is not visable on the site with Octoparse,https://www.reddit.com/r/webscraping/comments/zz33l7/how_to_scrape_data_that_is_not_visable_on_the/,webscraping," Hi. I am new to programming and scripting. Learning now, but I would really need some help right now for a project if somebody would be nice to help me out. When using the Octaporase, it is pretty straight forward with extracting data that is visible on the page. Put when you want to extract data that is hidden, you need to know a bit more scripting I guess. 

I would like to extract the sku number from this site  [https://www.nespresso.com/se/se/order/capsules/vertuo](https://www.nespresso.com/se/se/order/capsules/vertuo) but I don¬¥t know how.

The SKU number is not visible on the website but is in the background e.g( Nb-sku-coffee id=""109877"" where id is the product number) The Sku number is the ID of all product.

Could someone help me and explain how to extract this data that is not on the front page.  


Best regards","['Hi, considering that you have the whole html data from octaparse you can apply the current code to get the sku. All you need to do is change the req.text.\n\n&#x200B;\n\nhttps://pastebin.com/2vc8JzKz']"
How to monitor a page for content changes?,https://www.reddit.com/r/webscraping/comments/zyu7hq/how_to_monitor_a_page_for_content_changes/,webscraping,"I have this page:

[https://creditcards.chase.com/all-credit-cards](https://creditcards.chase.com/all-credit-cards)

I'd like to get an alert on whenever there are changes. 

Are there any services to do this?","['You can make a post request to the page every x seconds, minutes or hour and then check if the html source is the same as the previous one. Id it isn‚Äôt the same then something has changed.', 'You need to monitor post requests', 'Depending on your needs and update frequency, things like wachete or visual ping are full featured and usually cheap.  Otherwise yes, you can ping and compare responses ever X interval for elements you care about.', 'What do you want to monitor on that page? \r  \nIt is a list, I don‚Äôt see any service available to monitor a list/table for changes and better approach could be to create a script to parse and convert into CSV, use csv diff for every x hour.', 'I can build you a discord bot to do that.', 'Visualping website does that. They give you a few free requests per day. Very easy to use interface.', 'Theres websites that do that']"
Web scraping orders from Amazon: is still possible?,https://www.reddit.com/r/webscraping/comments/zyy2dt/web_scraping_orders_from_amazon_is_still_possible/,webscraping,"Hello there!

I‚Äôve made a few searches and found old replies to the same question but there are two differences to what I‚Äôve learned trying to scrape the ‚ÄúMy Orders‚Äù pages‚Ä¶

First, there‚Äôs no built-in report function for my country (Italy).

Second and most annoying: I‚Äôm trying with a simple JavaScript function to be copy-pasted and run directly in the browser that involves use of the default fetch and querySelectorAll API. The point is that the DOM nodes resulting from the fetch call that there were supposed to hold the relevant informations about the orders are encrypted and I can‚Äôt read them.

I‚Äôve found no trace of this, is it a new thing?","['Have you checked properly maybe they are in hexadecimal? Or even if they are somehow encrypted there must be some sort of function to decrypt it and you might be able to find it in sources', ""Is this as a seller or a buyer? I've used this Chrome extension as a buyer and it works well: [Amazon Order History Reporter](https://chrome.google.com/webstore/detail/amazon-order-history-repo/mgkilgclilajckgnedgjgnfdokkgnibi)""]"
Python script that scrapes the People also ask section from Google in the niche you want and publishes it to a WP website.,https://www.reddit.com/r/webscraping/comments/zyve7l/python_script_that_scrapes_the_people_also_ask/,webscraping," 

I found a python script that scrapes the people also ask section in your niche and publishes automatically to your WordPress website.

[https://www.youtube.com/watch?v=JJMHZ2qbjBg&t=139s](https://www.youtube.com/watch?v=JJMHZ2qbjBg&t=139s)

Based on the article it scrapes 25 questions and answers in your niche and publishes them to your WP website as a post. It also scrapes an image and YT video based on the title.

More info [https://sarc-wv.com/people-also-ask-script-scrape-and-publish-full-step-by-step-installation-guide/](https://sarc-wv.com/people-also-ask-script-scrape-and-publish-full-step-by-step-installation-guide/)

I am wondering, how to create something like this, without paying for it.

Thanks","['Well to ‚Äúcreate something like this, without paying for it‚Äù you need to know python\n\nDo you have any knowledge of python? or maybe any other language like JavaScript?']"
Beginner tutorial on scraping websites in Javascript,https://youtu.be/ssRo5nVOvrQ,webscraping,,
scraping JavaScript based website,https://www.reddit.com/r/webscraping/comments/zydznc/scraping_javascript_based_website/,webscraping,"Hi guys, this is my first time taking a task on web scraping, I'm trying to scrape a JavaScript website, the problem is that I'm already using selenium by certain tags don't seem to be scraped even tho they appear in inspect tool and after disabling JavaScript

If anyone can help i will be sooo grateful, and thank you in advance

This is the link of the website: https://www.ouedkniss.com/services-evenements-divertissement/1

I'm trying to get the emails if those announcements: 

from bs4 import BeautifulSoup
from selenium.webdriver import Chrome
from selenium.webdriver.chrome.service import Service
from selenium.webdriver import ChromeOptions
import pandas as pd

Options = ChromeOptions()
Options.headless = True
driver_service = Service(executable_path=r""C:\Users\Lilia\Desktop\WebScraping\chromedriver.exe"")
driver = Chrome(service=driver_service)
driver.get('https://www.ouedkniss.com/services-evenements-divertissement/1')
soup = BeautifulSoup(driver.page_source, 'lxml')


def Extract_Emails():
    elements = soup.findAll('div', class_=""col-sm-6 col-md-4 col-lg-3 col-12"")
    script = soup.find('script')
    print(script)
    
    for element in elements:
      link = element.find('a', class_='d-flex flex-column flex-grow-1 v-card v-card--link v-sheet o-announ-card-content theme--dark')
      driver.get('https://www.ouedkniss.com'+link['href'])
      soup1 = BeautifulSoup(driver.page_source, 'lxml')
      email = soup1.find('span', class_='v-chip__content')
      print(email)

Sorry, i couldn't attach the pic of the output of the inspect tool","[""I'm on my phone now so can't really check it, but maybe look for the hidden api: https://youtu.be/DqtlR0y0suo\n\nThe website is probably hitting an api to generate the data you need to scrape and then using javascript to actually embed them, check the video it explains a lot!"", 'Share the website and what element you want to get. And maybe share your code so we can see what you did wrong and we can fix it for you.', 'There is a graphql endpoint that you can query quite easily, if you look at your browsers Network tab when you reload the page you\'ll see a bunch of requests that get the data from the backend api.\n\nI\'ve recreated the two important requests below, first to get all the events (and their ids) then to get their email address (using the event id, there is a query for their phone number too, lol, seems safe) the below code is very rough but will get all the emails:\n\n\n    import requests\n    \n    graphql_url = ""https://api.ouedkniss.com/graphql""\n    \n    for page in range(1,25):\n    \n        events_payload = {\n            ""operationName"": ""SearchQuery"",\n            ""variables"": {\n                ""mediaSize"": ""MEDIUM"",\n                ""q"": None,\n                ""filter"": {\n                    ""categorySlug"": ""services-evenements-divertissement"",\n                    ""origin"": None,\n                    ""connected"": False,\n                    ""delivery"": None,\n                    ""regionIds"": [],\n                    ""cityIds"": [],\n                    ""priceRange"": [None, None],\n                    ""exchange"": False,\n                    ""hasPictures"": False,\n                    ""hasPrice"": False,\n                    ""priceUnit"": None,\n                    ""fields"": [],\n                    ""page"": page,\n                    ""count"": 48,\n                },\n            },\n            ""query"": ""query SearchQuery($q: String, $filter: SearchFilterInput, $mediaSize: MediaSize = MEDIUM) {\\n  search(q: $q, filter: $filter) {\\n    announcements {\\n      data {\\n        ...AnnouncementContent\\n        smallDescription {\\n          valueText\\n          __typename\\n        }\\n        noAdsense\\n        __typename\\n      }\\n      paginatorInfo {\\n        lastPage\\n        hasMorePages\\n        __typename\\n      }\\n      __typename\\n    }\\n    active {\\n      category {\\n        id\\n        name\\n        slug\\n        icon\\n        delivery\\n        priceUnits\\n        children {\\n          id\\n          name\\n          slug\\n          icon\\n          __typename\\n        }\\n        specifications {\\n          isRequired\\n          specification {\\n            id\\n            codename\\n            label\\n            type\\n            class\\n            datasets {\\n              codename\\n              label\\n              __typename\\n            }\\n            dependsOn {\\n              id\\n              codename\\n              __typename\\n            }\\n            subSpecifications {\\n              id\\n              codename\\n              label\\n              type\\n              __typename\\n            }\\n            allSubSpecificationCodenames\\n            __typename\\n          }\\n          __typename\\n        }\\n        parentTree {\\n          id\\n          name\\n          slug\\n          icon\\n          children {\\n            id\\n            name\\n            slug\\n            icon\\n            __typename\\n          }\\n          __typename\\n        }\\n        parent {\\n          id\\n          name\\n          icon\\n          __typename\\n        }\\n        __typename\\n      }\\n      count\\n      __typename\\n    }\\n    suggested {\\n      category {\\n        id\\n        name\\n        slug\\n        icon\\n        __typename\\n      }\\n      count\\n      __typename\\n    }\\n    __typename\\n  }\\n}\\n\\nfragment AnnouncementContent on Announcement {\\n  id\\n  title\\n  slug\\n  createdAt: refreshedAt\\n  isFromStore\\n  isCommentEnabled\\n  userReaction {\\n    isBookmarked\\n    isLiked\\n    __typename\\n  }\\n  hasDelivery\\n  deliveryType\\n  likeCount\\n  description\\n  status\\n  cities {\\n    id\\n    name\\n    slug\\n    region {\\n      id\\n      name\\n      slug\\n      __typename\\n    }\\n    __typename\\n  }\\n  store {\\n    id\\n    name\\n    slug\\n    imageUrl\\n    __typename\\n  }\\n  user {\\n    id\\n    __typename\\n  }\\n  defaultMedia(size: $mediaSize) {\\n    mediaUrl\\n    __typename\\n  }\\n  price\\n  pricePreview\\n  priceUnit\\n  oldPrice\\n  priceType\\n  exchangeType\\n  __typename\\n}\\n"",\n        }\n    \n        event_resp = requests.post(graphql_url, json=events_payload).json()\n    \n        for event in event_resp[\'data\'][\'search\'][\'announcements\'][\'data\']:\n    \n            email_payload = {\n                ""operationName"": ""UnhideEmail"",\n                ""variables"": {""id"": event[\'id\']},\n                ""query"": ""query UnhideEmail($id: ID!) {\\n  email: announcementEmailGet(id: $id)\\n}\\n"",\n            }\n    \n            resp = requests.post(graphql_url, json=email_payload).json()\n            \n            print(event[\'title\'],\'|\',resp[\'data\'][\'email\'])', ""In most cases it is a good idea to wait for a particular selector and then obtain the contents.  \nI don't know about Selenium, but with Puppeteer some websites take longer to load and if I do not wait for the container I am interested in, it will not be present in the scraped HTML.\n\nI hope that helps.""]"
"Built a Telegram Scraper, need suggestions",https://www.reddit.com/r/webscraping/comments/zydj5y/built_a_telegram_scraper_need_suggestions/,webscraping,"Hey guys, I've built another web scraper that can scrape a telegram group members and saves them as a contact, the scraper then adds the contact created to the desired group. The scraper is scraping 700 contacts per hour, I'd like suggestions to put this scraper to some good use, your suggestions are much appreciated.
Thanks",['Sell it to some crypto start ups']
Recapture data from deleted Reddit replies,https://www.reddit.com/r/webscraping/comments/zy8caf/recapture_data_from_deleted_reddit_replies/,webscraping,"I posted in a Reddit sub asking if it was ok to post a product I‚Äôm developing once it‚Äôs finished, in order to get peoples feedback. No one actually answered my original question but turns out a lot of people were interested and put their hand up to beta test the app once it becomes available. 

Turns out I should have read the rules - no ‚Äúadvertising‚Äù is allowed in, but that was what my initial question to the sub was about. 
The post stayed up for about a week and then the mod came along and deleted every response I got to the post. 

I would like to get the usernames of the people who responded to me so I can DM then in the future (most of them asked me to). Is there any way to recapture this data? I don‚Äôt know if scraping is an option for this? Or
might an older version of the post be cashed on my device somewhere?",['You can try archive.org']
Is there a site where I could run a bunch of data or even a url through it and it could machine learn enough to come up with questions?,https://www.reddit.com/r/webscraping/comments/zxzpoj/is_there_a_site_where_i_could_run_a_bunch_of_data/,webscraping,"
For example, say I wanted to run all the post titles of a sub and the machine could come up with its own questions using similar formats for questions from prior posts? 

Or if that would take a bunch of coding to implement, is there a way to easily webscrape a bunch of titles from a sub so I could at least see the most commonly used words?","['Webscraping all the titles probably wouldnt be that hard. You could honestly just find an intro to webscraping guide on youtube and just copy the code in the example and use that with a few slight modifications. Most examples will pick stuff from a page and do something with it so you just chamge it slightly to work for reddit and automate a way for it to look through all the links. It shoulsnt be too bad with a tool like playwrite for nodeJS.', 'One way I think you can do it is by scraping the titles and asking ChatGPT to come up with questions like these', 'You can add whatever data you want to GPT-3: https://openai.com/blog/customized-gpt-3/\n\nDepending on your use case, this may not even be necessary.  You might be able to just stuff a dozen examples of the questions you want into the prompt and be off to the races.']"
Scraping tumblr,https://www.reddit.com/r/webscraping/comments/zxz7a7/scraping_tumblr/,webscraping,"Hi everyone!  
I come to you in a time of need, since I have no idea how scraping or programming works, so I was hoping there's an easier way that I haven't found yet.  
Here's the deal: I need a way to find every post on tumblr that has a specific note. For example, if I were to reblog or like a post, my username would show up underneath and it'd say ""'username' liked this.""   
As you can imagine, there are millions of posts and going through all of their notes manually is impossible, so I figured that:  
a. Either I download the whole thing and somehow search locally on my pc, though it'd probably take a lot;  
b. Find a software that crawls the site and then apply a filter to that username to find the posts they've reacted to.  
Is this doable? Is there anyway someone could do this?  
I'm sorry if I don't make much sense, I have no experience with python and other stuff that is usually used in this sort of things. Thank you so much!",['that sounds like big task.\n\nFirst off if you want to search through all the posts the first thing you would need to do is create a database and scrape all the posts url.\n\nConsidering it has hundreds of billion of posts it can take millions of man hour just to scrape the whole database. But you can of course bypass that with some proxies.\n\nI never used tumblr before so let say it has the same format as following and followers. If you only wanted to find the posts that you were following then that would be a doable task.\n\nYou can simply use python requests to each username you follow and then copy down each posts link. After that you can go through each link and check the html source for your specific username.']
Need help webscraping a manga I purchased on DLsite,https://www.reddit.com/r/webscraping/comments/zxyuf6/need_help_webscraping_a_manga_i_purchased_on/,webscraping,"I have purchased a few read-only books on DLsite, so I cannot download them like other works I have already purchased. The book I am trying to webscrape is Famiresu Senshi Purin as shown here (NSFW link warning):

https://www.dlsite.com/comic/work/=/product_id/BJ338851.html

For anyone else who uses the webscraper Chrome extension, how would I be able to download the images from the book on DLsite?","[""I have checked out the website. It seems like they are using javascript to load in the content.\n\nYou can use bs4 and selenium. Right click is disabled so you can't inspect element the exact location but i have it down.\n\nI made a quick script that will get all the images from the html source\n\nhttps://pastebin.com/zNa54nwh""]"
Scrape Fb post from group and push to web?,https://www.reddit.com/r/webscraping/comments/zxyu63/scrape_fb_post_from_group_and_push_to_web/,webscraping,"Just came across this website that seems to be pulling content from their group automatically. They are then segmenting the data and pushing it to a site where they are allowing someone to play with filtering options like a live excel. Really curious if this is custom or this a platform providing this service?

The website is larvato.com 
(Not my site obviously)","[""Okay, so there are two features here in this setup. One is pulling posts from Facebook, the other is displaying the data on website. I don't think you will be able to find a solution integrating both features. \n\nSo what you can do is search for a Facebook scraper online, I am sure you will find a few companies providing this service. Then all you will need to do is save this data on your database and display it on your website. \n\nIt will require a fair bit of coding so if you aren't comfortable with it, you can hire someone to do it. In fact, I provide this service myself. If you are interested, you can pm me."", 'You simply need a $3 vps and then run a script that scrapes that group using bs4 and requests and then send it back to the database.', 'Is this a public group?']"
"Webscraping for Emails across Internet, Verifying Emails",https://www.reddit.com/r/webscraping/comments/zxxslb/webscraping_for_emails_across_internet_verifying/,webscraping," I am learning python, and would like to learn how to webscrape for emails across the internet AND verify emails.  

Where can I find more information to focus on this area?  Thanks!","[""What type of emails are you trying to get? in what niche? I'm pretty sure the people that have sources for scraping emails won't share it to profit on it."", ""I will be glad if you check the software I'm developing. You have a chance to become our first customer :)  \nhttps://myfolder.notion.site/myfolder/Phantom-Connect-0aedc60ce03043cc83f8fd55aa558d9c""]"
Having trouble scraping from wiktionary,https://www.reddit.com/r/webscraping/comments/zxq7og/having_trouble_scraping_from_wiktionary/,webscraping,"I don't really know if anyone has experience with this, but I'm trying to web scrape this table of most common Mandarin worsd from wiktionary using BeautifulSoup. 

[https://en.wiktionary.org/wiki/Appendix:Mandarin\_Frequency\_lists/1-1000](https://en.wiktionary.org/wiki/Appendix:Mandarin_Frequency_lists/1-1000)

Three problems: 1) it prints the table really weirdly, where I want it to be like on line 62  (as an example) and orderly (simplified, traditional, pinyin (latin pronounciation), and meaning). For some reason it just outputs the pinyin on the last line on one and starts again on a new line, with NaN and file after it

2) The meaning doesn't show up for any of them

https://preview.redd.it/ldgz5xieeq8a1.png?width=571&format=png&auto=webp&v=enabled&s=3c417e4e38c55ab3a6502dbcab15f38e137d331d

&#x200B;

3) It stops abruptly at line 312 with a bad character symbol when there's way more for it to go

&#x200B;

https://preview.redd.it/28u8jad1fq8a1.png?width=469&format=png&auto=webp&v=enabled&s=f4ca6872fe79e357582243cd2596816073e1e4f1

Any help would be greatly appreciated","[""Here's the code:\n\n`import requests`\r  \n`import pandas as pd`\r  \n`from bs4 import BeautifulSoup`\r  \n\r  \n`wiki_url = 'https://en.wiktionary.org/wiki/Appendix:Mandarin_Frequency_lists/1-1000'`\r  \n\r  \n`response = requests.get(wiki_url)`\r  \n`soup = BeautifulSoup(response.text, 'html.parser')`\r  \n\r  \n`mandarintable = soup.find('table', attrs={'class': 'wikitable'})`\r  \n`print(mandarintable)`"", ""It comes out weird because you didn't also find the child elements like the tr and td. But the other problem i found is the elements inside tr also contains another tr so if you do find\\_all then you it could also cause some automation issues. \n\nThe bad character symbols can be because you didn't add any headers such as Accept-Encoding which usually translate certain texts.""]"
Python Library to scrape RSS-Feeds from waybackmachine?,https://www.reddit.com/r/webscraping/comments/zxduid/python_library_to_scrape_rssfeeds_from/,webscraping,"Hi,
my goal is to Archive all rss-feeds by a website from the last 5 years. Is there a easy way to combine beautifulsoup and some libarys to use waybackmachine for this?","[""I don't have a library but you can use this code which should get you most of the way there, it uses some backend requests to get the data you want. I've broken out of the loops at the end just for testing so delete those to get all the data\n\n\n    import requests\n    import urllib.parse\n    \n    site = 'http://feeds.bbci.co.uk/news/rss.xml'\n    year = 2020\n    \n    safe_site = urllib.parse.quote_plus(site)\n    \n    url = f'https://web.archive.org/__wb/calendarcaptures/2?url={safe_site}&date={year}&groupby=day'\n    \n    resp = requests.get(url).json()\n    \n    for item in resp['items']:\n        if len(str(item[0])) == 4:\n            day = str(item[0])[-2:]\n            month = str(item[0])[:2]\n        else:\n            day = str(item[0])[-2:]\n            month = str(item[0])[:1].zfill(2)\n    \n        day_url = f'https://web.archive.org/__wb/calendarcaptures/2?url={safe_site}&date={year}{month}{day}'\n    \n        time_data = requests.get(day_url).json()\n        print(f'Finished {day_url}')\n    \n        for t in time_data['items']:\n            time_str = str(t[0]).zfill(6)\n    \n            final_url = f'https://web.archive.org/web/{year}{month}{day}{time_str}/{site}'\n            output = requests.get(final_url)\n            print(output.text)\n            break\n        break"", 'You can start with feedparser, it‚Äôs easy to use, if RSS (XML) is properly built.', 'You can explore [FeedParser](https://github.com/kurtmckee/feedparser) too']"
Best method to scrape/copy web quick,https://www.reddit.com/r/webscraping/comments/zwvzkm/best_method_to_scrapecopy_web_quick/,webscraping,"There's a web quiz here: [https://theroasterie.com/pages/coffee-quiz](https://theroasterie.com/pages/coffee-quiz)

Short of clicking through every option and typing it up in a spreadsheet, does anyone have suggestions on a more efficient way to copy this over? A bot maybe?","[""if you're non technical and its a simple scrape, your best bet is checking out some browser extensions"", ""Use Python and Selenium. You automate the browser actions (clicks on elements) and scrape the pages' content as you continue towards the end of the quiz. Pretty basic stuff actually."", 'Requests and bs4 would be even easier. If the data is being provided by an api all you would need to do is parse it with json.', 'This might help:\n \nhttps://docs.google.com/spreadsheets/d/1skwk18o1bj2aU4tkEto11VZZQ1vMpP_ynnGm_ti1CKc/edit?usp=sharing']"
Can you program a BeautifulSoup Web scrapper?,https://www.reddit.com/r/webscraping/comments/zx324c/can_you_program_a_beautifulsoup_web_scrapper/,webscraping,Looking for someone who knows how to program and write a web scrapper using the beautifulsoup software. Message me for more details about the web scrapper I'm looking to have created. Thank you!,"['If the request is not too hard you can message me and I can do it for free.', 'Hey there what is it you want scraped, I can surely help you with that.\nIs there a mail to reach you out something to chat about the details', 'Github - E2E-SSE\n\nEMAIL GNSGroup@mail.com \n\n&#x200B;\n\nI can build scrappers from the ground up utilizing APIs, bs4 and even selenium for advanced scrapping\n\nI am not limited to python either.\n\n$20 ETH or BTC', ""I'm developing automation software that scrapes multiple websites using beautifulsoup. I've also added a custom requests section, and I think I can help you with that. website link - https://myfolder.notion.site/myfolder/Phantom-Connect-0aedc60ce03043cc83f8fd55aa558d9c""]"
Help scraping a Pdf from a Notion Page,https://www.reddit.com/r/webscraping/comments/zvyxik/help_scraping_a_pdf_from_a_notion_page/,webscraping,"Noob here so sorry if this is a common question. I was trying to download the fcp assistant editing pdf thats at the bottom of this webpage.""[shorturl.at/glq06](https://shorturl.at/glq06)"" Ive tried a couple of different way but nothing seems the work Any help is appreciated.",[]
is manual scrapping still alive?,https://www.reddit.com/r/webscraping/comments/zv7t91/is_manual_scrapping_still_alive/,webscraping,"I am trying to understand if the current automated tools cover all spectrum of data scrapping projects? I feel like the automated tools, though beneficial in many scenarios, cannot cover many projects that might be small,m or very complex for an automated tool, or maybe because the tools are complex to use.","[""Manual data entry/scraping is not a thing anymore unless it's something super casual. \n\nHowever, human-assisted scraping, like using bookmarklets or tampermonkey scrape scripts, is totally underrated. Especially when it comes to difficult targets that block hard, like LinkedIn etc. You can navigate to data endpoints and click a script to save the data whenever. It doesn't scale that well if you need thousands of scrapes but for that middle ground where it's too difficult to write a scraper and too exhausting for manual data entry the browser scripting niche is great!"", 'For some client jobs, hand copy and paste is still the cheapest solve VS automation (rarely, but it‚Äôs for sure real)']"
What to do when I just can't solve a problem?,https://www.reddit.com/r/webscraping/comments/zv05nl/what_to_do_when_i_just_cant_solve_a_problem/,webscraping,"I just can't figure out this problem, and what's worse, I can't seem to accurately describe the problem.  I'm wondering if I can hire someone by the hour, but I really don't know where to start with that.

Are there services for something like this?  Any you guys would recommend?","['lol just post the problem dude', 'If you can‚Äôt describe the problem, it means you don‚Äôt understand it, which could mean the problem is elsewhere that you looking. It is more difficult or impossible for us to help you though. \n\nTry to describe it by saying what is related to, and what was your path which ended in facing the problem. Also - do you know why you can‚Äôt solve it? Is it your lack of knowledge or maybe lack of software/hardware resources?', 'Don‚Äôt get frustrated\n\nhttps://www.motogp.com/api/results-front/be/results-api/session/938282af-aed2-4110-bcfd-19bf8210b229/classifications\n\nThis endpoint returns json which has all the info you need', ""Hi, if you'd like I can take a look at this tomorrow. I am a full time webscraping freelancer. Thanks and happy holidays.""]"
Possible to scrape Facebook for Business Pages?,https://www.reddit.com/r/webscraping/comments/zuwqiu/possible_to_scrape_facebook_for_business_pages/,webscraping,title,"['If you can get enough accounts, nowdays as soon as you create an account and the second you do aomething that looks suspicious they require a phonenumber if you arent banned instantly their ai is becomming quite good at detecting stuff like that.\n\nA possible workaround could be trying to scrape the data trough search engines and good proxies so you dont make the requests to facebook but rather look for facebook pages trough search engines. However they have limits as well but again there are workarounds for as well.\n\nIt is not impossible. But it requires some creativity and planning.', 'If you‚Äôre talking about finding pages then it‚Äôs very simple. You can use something called ‚Äúdorks‚Äù it‚Äôs basically a more efficient way of searching for what you need.\n\nExample of google dork site:Facebook.com ‚Äúdogs‚Äù\n\nI‚Äôm not sure if this is the correct way but if it is it should return results with anything facebook links that includes dogs. Of course you would need to tweak the link for it to only show groups.', ""Yes. I'm developing automation software that scrapes multiple websites including Facebook. I've also added a custom requests section, and I think I can help you with that. website link - https://myfolder.notion.site/myfolder/Phantom-Connect-0aedc60ce03043cc83f8fd55aa558d9c""]"
"why some proxy doesn't provide ID, PW, DNS, PORT in simple from??",https://www.reddit.com/r/webscraping/comments/zup8jp/why_some_proxy_doesnt_provide_id_pw_dns_port_in/,webscraping,"recently, I've been trying free plans or trials from so many proxy provider to find valuable.

I found out there are two types.

  \- A : simply provide ID, PW, DNS, PORT and additional. 

  \- B : never provide things like case 'A', but kind of example like below

ex) protocol:// {there own url} & url = {target website url} & api\_key = { api key } & api\_option = true

&#x200B;

I am a noob scraper, so I couldn't imagine how to use them in my puppeteer scripts. I tried google as well but never found about my issue.  One of them had a chat with me, guided me that I just need to take api\_key as username and leave empty for password. That worked with their product but never worked with the others. 

&#x200B;

Please anybody help me to use it as proxy.","['Read about how URLS are formed', 'Type A is a proxy using the official documentation for http/https/socks4/socks5. \n\nType B is just a http endoint (think of it like a normal website, but instead of accesing a website it reroutes to the url)\n\nType A is better supported, has higher bandwith throughput and lower ping, but since the socks4, socks5 and http protocols are pretty limited, servers cannot see which domain, subdomain or stuff, they only know where to connect, your username and in socks5/http your password too (If you use authentification)\n\nUsing a general web server as a proxy has pretty much 0 support, so if your proxy provider stops working for any reason you would have to change your entire code\n\nTo combat this the only way (without breaking backwards compatibility) is to make a new protocol, socks6 sounds like a good ideea if you ask me']"
What's the easiest pre-packaged scraper (not language or scripting tools) that would work with LinkedIn Sales Navigator?,https://www.reddit.com/r/webscraping/comments/zuhqvy/whats_the_easiest_prepackaged_scraper_not/,webscraping,"I'm hearing about Equests + BS4, but these are very technical solutions. I was wondering what scraper such as DataMiner, is the most easiest, but most mature solution out there. 

Thanks in advance.","[""Don't waste your time scrapping data from linked in you will get banned if you do that."", 'Isn‚Äôt LinkedIn kind of militant when it comes to combating scraping? I recently read about their efforts to make it difficult. I have no personal experience on the topic, however.', ""I don't know about a pre packaged scraper but I have built one for it so it's definitely possible."", 'Dux soup or evaboot (sales nav only)', 'You can use third party scrapers that provides you with a pool of ip. Some provides headless browsers for JavaScript loading']"
Selenium's .text attribute isn't working despite being able to find the element,https://www.reddit.com/r/webscraping/comments/zuoijg/seleniums_text_attribute_isnt_working_despite/,webscraping,"`from requests_html import AsyncHTMLSession, HTMLSession`  
`from selenium import webdriver`  
`from selenium.webdriver.common.by import By`  
`import time`  
`import json`  
`import csv`  
`import re`  
`import pandas as pd`  
`import requests`  
`from pandas import json_normalize`  
`from bs4 import BeautifulSoup`  


  
`driver = webdriver.Chrome()`  
`driver.set_page_load_timeout(30)`  
`driver.get(""https://app.prizepicks.com/"")`  


`grid = driver.find_elements(By.ID, ""projections"")`  


`for players in grid:`  
`names = players.find_elements(By.CLASS_NAME, 'name')`  
`scores = players.find_elements(By.CLASS_NAME, ""strike-red"")`  
 `print(scores[3].text)`

&#x200B;

Here, the last print statement is supposed to print an NBA player's name from the website (Prizepicks). It prints whitespace despite the text being in the HTML/CSS, and I have correctly identified the element in my code.","[""Wouldn't it be easier to simply use their API to extract the data you want?\n\nhttps://api.prizepicks.com/projections?league_id=7\n\nhttps://stackoverflow.com/questions/74168861/need-help-scraping-data-from-prizepick-api""]"
"Trying to scrape this side, but the accept cookies button is making other elements unable to be interacted with.",https://www.reddit.com/r/webscraping/comments/zumfh8/trying_to_scrape_this_side_but_the_accept_cookies/,webscraping,"I feel like my html knowledge is the issue here.  I rely a lot on the inspect element function to find the element I want, but I can't seem to right click on the button specifically.

I'm using Selenium right now.  If another tool is better, I'm all ears.

https://www.motogp.com/en/gp-results/2022/VAL/MotoGP/RAC/Classification","['Accept the cookies as part of your script.', ""If you need to click some link:\nUsing Selenium is not like control mouse on your screen, so you can open web page on your real browser, accept cookies and find link you need to click. then put that xpath to your code to see if Selenium can click to that link without accept cookies.\n\nOf you need to get html data:\nDon't use Selenium parser, it slow. Return html and use other parser tool like beautifulsoup (parsel or selextolax is better) to get data."", 'I have ran into this. Try looking up ‚Äúselenium wait for element to appear‚Äù or something like that. I used that to get around it.. or maybe headless browser with options']"
Challenging task. NEED HELP,https://www.reddit.com/r/Automate/comments/10fcdna/challenging_task_need_help/,Automate,"I am looking for a service or way to have people text a SMS number in whatsapp and have an automated response/reply that ask for a sequence of information in response to user input. I also want it to record the user responses into some kind of file or excel sheet.

&#x200B;

What is this called? is there a way to create this?

&#x200B;

If I didn't explain it well, what I am imagining is like a customer support automated text feature where you text a number enter in your name then the automated machine ask for your email, then you send it, then it ask for your order number etc. I need something like that over whatsapp and for the responses to be recorded.","['Not 100% clear whether you\'re looking for something working as you state ""out of the box"" or whether you\'re capable of doing a little programming. Either way, Twilio is one company that will allow you to programmatically SMS. If you\'re not into coding, you can probably get someone from fivver to make you something that will do it for a reasonable cost.', 'ChatGPT + Python + Twilio.']"
How can I automate sending email to recruiters?,https://www.reddit.com/r/Automate/comments/10ew1x4/how_can_i_automate_sending_email_to_recruiters/,Automate,"I've a list of companies(around 1000),  I want to apply jobs for. I want to attach my resume to the email. And a letter telling I want internship at some positions.

What'll be same?

1) Cover letter


2) Attached resume

What'll be different?

1) Email address","['Easy. Microsoft outlook excel and word. Mail merge toolkit (or something similar). You can even customize the cover letter based on fields in excel', 'Where did you get a list of 1000 recruiters?', 'You could use the Mail Merge plugin in Thunderbird: https://addons.thunderbird.net/en-us/thunderbird/addon/mail-merge/', 'Mailmerge.']"
Sending commands to a speaker using a programming language,https://www.reddit.com/r/Automate/comments/10eb9fd/sending_commands_to_a_speaker_using_a_programming/,Automate,"I want to create a custom alarm clock that is controlled over the internet running on a remote server (probably a lambda on a schedule). Ideally I need a speaker which I can send commands to over the internet, unless I‚Äôm missing something. Current options I‚Äôve thought about but seem like a pain in the ass to implement:
- Hacking a google/apple/Amazon device and sending it a command somehow (probably a locally hosted web server, but this defeats the whole thing of running it in the cloud).
- speaker that has an api interface that I can access if I allow it and has some sort of encryption

Any ideas?","['Use the Google search term ""IP Speaker"" where IP stands for ""Internet Protocol"".  This is a speaker that will accept and use an IP address.\n\nexample: https://www.amazon.com/Algo-8186-Paging-Speaker-Ringer/dp/B01G2O5A70/ref=sr_1_3?crid=2J6OEUEHZMVH3&keywords=ip+Speaker&qid=1673975291&sprefix=ip+speaker%2Caps%2C134&sr=8-3&ufe=app_do%3Aamzn1.fos.c3015c4a-46bb-44b9-81a4-dc28e6d374b3\n\nAlternatively, you could also use a bluetooth speaker and connect it to a computer. This would probably be the easy method for what you\'re trying to do. This way you could send your commands to an actual computer rather than trying to figure out how to essentially build your own audio drivers for some random device.', 'Maybe something with a raspberry pi?\n\nhttps://www.makeuseof.com/create-your-own-privacy-friendly-voice-activated-raspberry-pi-smart-speaker-with-mycroft/']"
Google Reveals Its Answer To OpenAI's ChatGPT From DeepMind | Deepmind DreamerV3 General AI | AI Powered Robotic Exoskeleton,https://youtu.be/dvKFiWJAO64,Automate,,
automatically changing TV brightness.,https://www.reddit.com/r/Automate/comments/10ecfb9/automatically_changing_tv_brightness/,Automate,How can I automate my TV to change to yellow mode or less bright? Like through a iPhone routine/ smart home automation,"[""Perhaps something like Logitech Harmony would be a solution? You could script the remote button sequence. Haven't played with one myself but seems like it could work.\n\nEdit: Apparently discontinued but maybe something along those lines."", 'TV or monitor? I just want to clarify']"
Custom shortcuts to automate access AI on your Mac,https://www.reddit.com/r/Automate/comments/10eau6v/custom_shortcuts_to_automate_access_ai_on_your_mac/,Automate," 

Hello folks,

I'm always amazed by the power of GPT-3 and Open AI.

This post is a combination of both information and promotion, so please bear with me.

I've always wanted to use AI directly on my phone and computer, without having to go to OpenAI's playground or ChatGPT in the browser.

For that, I created a tiny Mac app called Elephas. I have shared the app in this group [in the past](https://www.reddit.com/r/Automate/comments/1027x84/using_gpt3_to_automate_content_repurposing_for/) as well and got some amazing feedback from the members :)

Since then many users have asked for the ability to add custom commands in the app, that they can use to invoke AI on their computer.

So I've just shipped a feature called ""Snippets"".

With this, **now you can assign custom shortcuts to OpenAI prompts and use them in your day-to-day workflow wherever necessary.**

This is how it works -

https://reddit.com/link/10eau6v/video/401eus15ilca1/player

 There are many more such utility features that can help you get the power of AI in your daily work.

You can get the app here - [Elephas](https://elephas.app/?ref=rAutomate-snippets)

You can try it out for FREE for 7 days.

Appreciate your feedback.

Do let me know any new features that you would like to see in the app.

Thanks",[]
"Book about the impact of AI in society, employment, etc...""Beautiful tsunami: understanding and thriving in the age of AI"", by Javier Marti. Talks about where we are and where we are going, and how it'll affect all of us, including potential bad outcomes",https://javiermarti.co.uk/JM_website_2016/other/BOOK_Beautiful%20tsunami_AI_Javier_Marti.pdf,Automate,,
r/CodeFight,https://www.reddit.com/r/Automate/comments/10eo64h/rcodefight/,Automate,"The Internet is changing, fast. Time to level-up. And take the fight for digital and cognitive liberties to the enemies of humanity.

Join us at r/CodeFight!","[""After reading this and visiting that subreddit I still have no clue what it's for.  level-up what?"", 'if this is about AI generated content, bro thinks there‚Äôs gonna be an epic code-off showdown between AI and humanity üíÄüíÄüíÄ\n\nit‚Äôs either AI gets stagnant all of a sudden and nothing ever happens, or they develop sentience and murder all of humanity, but the best middle ground is that they develop sentience and try to coexist with us\n\nbut i assure every artist out there, imma be honest and upfront, **i cannot bust a nut to AI generated hentai**, up to this point there‚Äôs still little imperfections with AI generated artworks that i **physically cannot keep my dick hard** when i see them, and they all look same-same\n\nso if y‚Äôall ever feel like there‚Äôs no customerbase left for you, i‚Äôm still here and willing to pay for my custom hand-drawn anime milf hentais aight?', ""What is the point of this? There are dozens of more specific learn to code subs (e.g. learn sql, python, c, c#, java, css, etc. etc. etc.). Then from there are more formal subs for those that generally know e.g. r/Python. And then there are more generic things like r/learnprogramming and a handful of similar. \n\nWhat is an enemy of humanity? Is this some rogue state? AI? Aliens? Rogue states are still humans and aliens, if a threat, are unimpressed by your coding since they apparently have advanced space flight (or are not a threat). So... AI? You going to learn to speak in some form of machine language better than an AI that is an enemy of humanity? What's next water pistols to fight the ocean?""]"
The everything market app,/r/CyberStasis/comments/10e7mco/the_everything_market_app/,Automate,,
Recommendation for automate,https://www.reddit.com/r/Automate/comments/10e1uc9/recommendation_for_automate/,Automate,"I‚Äôm currently a legal Intern and my boss has graciously given the task  to summarize 300+ legal cases by June, I‚Äôd like to know if I can automate this task, by either using a website or by purchasing a software. For any how do I go about doing it. Thanks a lot in advance!!!!!","['One option to check out: https://detangle.ai/\n\nMay be worth getting on their beta and trying it with one case, and see if it gives good results.', ""I feel like a text expander would be a good option here. Depending on your platform, there are lots of good ones. I prefer Text Blaze, but it isn't available on mac yet""]"
Harvesting and bunching radishes,https://gfycat.com/happygoluckybriefeasternnewt,Automate,,
"Hot take: AI and ChapGPT are not ready yet, text expanders > AI",https://www.reddit.com/r/Automate/comments/10dfb32/hot_take_ai_and_chapgpt_are_not_ready_yet_text/,Automate,"AI has a lot of promise, but I feel like they should only be used for idea generation right now. They're just too new to actually use for real work and I've seen many cases where they just aren't as accurate as they could be. They definitely could get there one day, but they aren't ready yet. 

Personally, I prefer to use a text expander (automates typing using pretyped phrases) to automate my writing. Text expander, Text Blaze, and aText are solid options. They aren't AI like ChatGPT, but they can help you automate without the risk that AI has right now. 

Just my thoughts, as I see people post ""Is ChatGPT the future"" every day in every single thread. Looking forward to everyone's thoughts!","['I feel you, but I‚Äôm also using Espanso and have been playing with OpenAI api to add flair to the expansions.\n\nhttps://maxziebell.de/2022/12/21/setting-up-an-ai-expansion-using-espanso/\n\n(Not my blog, but I did stumble on it when setting my own stuff up)']"
Is Chat GPT the future?,https://www.reddit.com/r/Automate/comments/10ctghc/is_chat_gpt_the_future/,Automate,,"['the future of what?', 'For automation? No absolutely not. Asked it a few coding questions it failed. It gives out pretty believable output but in practice you still have to fit it into whatever use case you have beyond a simple example. I did enjoy discussing art thefts with it though. As a random conversation buddy you ask questions its pretty fun. Ps it has no connection to the internet, so cannot look up anything for you.', ""ChatGPT is the future like one level higher than Alexa was the future in Fall 2014.  It's the best in its space, hands down (asking it to compose songs about various topics is quite amusing), and will probably serve as a foundation upon which various other services, apps, etc., can be based on... That said, ChatGPT4 is said to be on the way and supposedly will be just as remarkable of an advance above ChatGPT3 once experienced."", ""It has a 3 in the name, so probably not. I'd guess it will be part of the present until version 4, which will follow a similar path.\n\nAfter a few weeks of having it around and using it for work (FT law, PT software) it works as a fair assistant. One of my favorite uses is using the normal windows voice to text where I can bumble around inaccurately in my speech, but then also tell ChatGPT to rewrite it as a coherent letter. I do a similar thing with coding issues. Both ... maybe save time mostly."", 'I think ChatGPT and other tools similar to it will have a large role in many applications in the future.  I personally hate talking to many of the chat bots that are used as an initial troubleshooting tool for many companies.  I was chatting with Bluehost chatbot about my website being down recently and it literally couldn\'t understand what I meant when I said ""my website is down"" and I had to rephrase. And it never helped me anyway - I had to call them up and talk to a real person.  \n\n&#x200B;\n\nI think that AI will be able to troubleshoot many of the common problems that people have with various software, but it will take time and having real humans checking the answers before it will be trained enough to solve problems reliably on its own.  You wouldn\'t want it going in and making something worse by its ""solution"".', ""Also, here's ChatGPT's response to this question:\n\nChatGPT is a tool that is part of the current state-of-the-art in natural language processing. It has the ability to generate human-like text, which has many potential applications in fields such as customer service, content creation, and language translation. However, it's important to note that the field of artificial intelligence is constantly evolving, and new developments may supersede the capabilities of ChatGPT in the future.""]"
New Research From Google Shines Light On The Future Of Language Models ‚≠ï,https://www.reddit.com/r/Automate/comments/10bq9gp/new_research_from_google_shines_light_on_the/,Automate,"Last year, large language models (LLM) have broken record after record. ChatGPT got to 1 million users faster than Facebook, Spotify, and Instagram did. They helped create [billion-dollar companies](https://www.marketsgermany.com/translation-tool-deepl-is-now-a-unicorn/#:~:text=Cologne%2Dbased%20artificial%20neural%20network,sources%20close%20to%20the%20company), and most notably they helped us recognize the [divine nature of ducks](https://twitter.com/drnelk/status/1598048054724423681?t=LWzI2RdbSO0CcY9zuJ-4lQ&s=08).

2023 has started and ML progress is likely to continue at a break-neck speed. This is a great time to take a look at one of the most interesting papers from last year.

Emergent Abilities in LLMs

In a recent [paper from Google Brain](https://arxiv.org/pdf/2206.07682.pdf), Jason Wei and his colleagues allowed us a peak into the future. This beautiful research showed how scaling LLMs might allow them, among other things, to:

* Become better at math
* Understand even more subtleties of human language
* reduce hallucination and answer truthfully
* ...

(See the plot on break-out performance below for a full list)

**Some Context:**

If you played around with ChatGPT or any of the other LLMs, you will likely have been as impressed as I was. However, you have probably also seen the models go off the rails here and there. The model might hallucinate gibberish, give untrue answers, or fail at performing math.

**Why does this happen?**

LLMs are commonly trained by [maximizing the likelihood](https://www.cs.ubc.ca/~amuham01/LING530/papers/radford2018improving.pdf) over all tokens in a body of text. Put more simply, they learn to predict the next word in a sequence of words.

Hence, if such a model learns to do any math at all, it learns it by figuring concepts present in human language (and thereby math).

Let's look at the following sentence.

""The sum of two plus two is ...""

The model figures out that the most likely missing word is ""four"".

The fact that LLMs learn this at all is mind-bending to me! However, once the math gets more complicated [LLMs begin to struggle](https://twitter.com/Richvn/status/1598714487711756288?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1598714487711756288%7Ctwgr%5E478ce47357ad71a72873d1a482af5e5ff73d228f%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fanalyticsindiamag.com%2Ffreaky-chatgpt-fails-that-caught-our-eyes%2F).

There are many other cases where the models fail to capture the elaborate interactions and meanings behind words. One other example is words that change their meaning with context. When the model encounters the word ""bed"", it needs to figure out from the context, if the text is talking about a ""river bed"" or a ""bed"" to sleep in.

**What they discovered:**

For smaller models, the performance on the challenging tasks outline above remains approximately random. However, the performance shoots up once a certain number of training FLOPs (a proxy for model size) is reached.

The figure below visualizes this effect on eight benchmarks. The critical number of training FLOPs is around 10\^23. The big version of GPT-3 already lies to the right of this point, but we seem to be at the beginning stages of performance increases.

&#x200B;

[Break-Out Performance At Critical Scale](https://preview.redd.it/n7svd95hv0ca1.png?width=800&format=png&auto=webp&v=enabled&s=282b88e4c256236b65b23de9b8ac392abbb4e656)

They observed similar improvements on (few-shot) prompting strategies, such as multi-step reasoning and instruction following. If you are interested, I also encourage you to check out Jason Wei's personal blog. There he [listed a total of 137](https://www.jasonwei.net/blog/emergence) emergent abilities observable in LLMs.

Looking at the results, one could be forgiven for thinking: simply making models bigger will make them more powerful. That would only be half the story.

(Language) models are primarily scaled along three dimensions: number of parameters, amount of training compute, and dataset size. Hence, emergent abilities are likely to also occur with e.g. bigger and/or cleaner datasets.

There is [other research](https://arxiv.org/abs/2203.15556) suggesting that current models, such as GPT-3, are undertrained. Therefore, scaling datasets promises to boost performance in the near-term, without using more parameters.

**So what does this mean exactly?**

This beautiful paper shines a light on the fact that our understanding of how to train these large models is still very limited. The lack of understanding is largely due to the sheer cost of training LLMs. Running the same number of experiments as people do for smaller models would cost in the hundreds of millions.

However, the results strongly hint that further scaling will continue the exhilarating performance gains of the last years.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you.At **TheDecoding** ‚≠ï, I send out a thoughtful newsletter about ML research and the data economy once a week.No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)","[""It looks like OP posted an AMP link. These should load faster, but AMP is controversial because of [concerns over privacy and the Open Web](https://www.reddit.com/r/AmputatorBot/comments/ehrq3z/why_did_i_build_amputatorbot).\n\nMaybe check out **the canonical page** instead: **[https://twitter.com/richvn/status/1598714487711756288](https://twitter.com/richvn/status/1598714487711756288)**\n\n*****\n\n ^(I'm a bot | )[^(Why & About)](https://www.reddit.com/r/AmputatorBot/comments/ehrq3z/why_did_i_build_amputatorbot)^( | )[^(Summon: u/AmputatorBot)](https://www.reddit.com/r/AmputatorBot/comments/cchly3/you_can_now_summon_amputatorbot/)""]"
The misuse of AI is the familiar promise one thing and deliver something else,/r/CyberAutonomy/comments/10bnig4/the_misuse_of_ai_is_the_familiar_promise_one/,Automate,,
Review of ChatGPT/AI for LinkedIn for marketing,https://www.reddit.com/r/Automate/comments/10bf7sg/review_of_chatgptai_for_linkedin_for_marketing/,Automate,"Recently, I found a Chrome extension called Engage AI. I've been using the tool for the past week or two. I wanted to share my experience with it.

The Chrome extension essentially writes comments for you for LinkedIn posts. All you have to do is copy the link of a post and paste it into the extension. The app scrapes information from the post and comments, then it generates a related comment for you using AI.

The comments generated by the extension are accurate and have perfect spelling and grammar. They sound genuine, human, and high-effort, far better than generic comments such as ""Great post"" or ""Thanks for sharing.""

Unfortunately, the comments aren‚Äôt always accurate. Occasionally, the app will generate a comment that doesn‚Äôt make much sense with the post and I need to refresh it. It‚Äôs also a shame that it‚Äôs specific for LinkedIn and no other platforms, so you‚Äôre out of luck if you don‚Äôt use LI.

It's not for everyone, but for someone like me who uses LinkedIn to build relationships with leads for my employer, it's a great help. I feel like VAs could benefit a lot from this, and anyone else trying to stay in front of your target audience on LinkedIn.

Personally, I comment on prospects' posts on a weekly basis. It can take me hours to come up with, say, twenty insightful and well-thought-out comments. With this extension, those hours are reduced to just a few minutes. I've gotten positive feedback from the comments I've made with it so far.

Overall, the app is a great time-saver and saves me the effort of needing to write a comment that makes sense in a field I‚Äôm not always familiar with. I‚Äôm already on the paid plan, but there‚Äôs a free trial if you want to test it out.

If anyone else has tried it, I would love to hear your thoughts.","[""Yeh I tried using ChatGPT recently for an article, asking it to add some stats and cite publications.  Everything it provided sounding exceptionally convincing (Authors, papers, dates, pages) - except that it was all complete BS.   If it wasn't for me fact checking, I could have easily posted the article.  \nIf we thought misinformation and fake news was bad now, the coming years will be horrible.  I actually don't understand how we will stop it from polluting everything.  In many senses it is going to be more important than ever to be a critical thinking human."", ""What a nightmare world we're entering."", ""I've found the openAI models are good for seeding ideas.  Generally trying to have it write up an entire article is a bit hit or miss factually and the writing style is clearly automated. Human intervention is still required at this point to make it sound good.\n\nThere is also the issue of niche topics. The more narrow your focus and less widespread the information on it, the more likely it is to almost directly copy source material.\n\nIt did offer me a nice poem about unmanaged switches in the style of E. E. Cummings that gave me a chuckle during my Livestream this week."", 'Interesting thank you.  Now I‚Äôm wondering whether it can be used to engage with Reddit posts‚Ä¶.']"
"A.I. APIs Landscape 2023 for Speech and Vision (image and video) analysis, Natural Language Processing and Automatic Document Parsing",https://i.redd.it/51lp4sz9msba1.gif,Automate,,
OpenAI Announces New ChatGPT PRO Version And Watermarking Tool | New Samsung Robot Powered By Artificial Intelligence | Breakthrough Robot Gripper Resembles Elephant's Trunk,https://www.youtube.com/watch?v=tAQOhsaCz8s,Automate,,"['[removed]', 'j', 'Lol, [www.reddit.com/comments/**watch**](https://www.reddit.com/comments/watch) is the URL.']"
Performance of Automation Anywhere v.26,https://www.reddit.com/r/Automate/comments/10avwt7/performance_of_automation_anywhere_v26/,Automate,"Hi, Have you used the latest version 26 of Automation anywhere ? How's it faring compared to the previous AA versions, what better services are being offered ?",[]
New to UI Automation: Seeking Recommendations for Learning UI.Vision,https://www.reddit.com/r/Automate/comments/10anuy5/new_to_ui_automation_seeking_recommendations_for/,Automate,"Hey everyone, I'm new to the world of UI automation and I'm interested in learning more about UI.Vision. Can anyone recommend some good resources or courses for a beginner to get started with UI.Vision? Are there any particular websites or places that you've found to be particularly helpful in learning this technology? Thanks in advance for your suggestions!",[]
Trying to get saved Instagram posts into my Notion databases. Anyway to IFTTT++ it anywhere?,https://www.reddit.com/r/Automate/comments/10ai3jy/trying_to_get_saved_instagram_posts_into_my/,Automate,"Whenever I'm on Instagram, I hit the save/bookmark to denote that I'm interested in referencing something later.

I would love to find a way that when I hit save, the link to that Instagram post gets sent somewhere, anywhere. I'm particularly looking to put it in my notes database, but even if I can get it to a Google sheet, a list app, a doc, whatever, I could automate from there.

Unsure what to do other than manually copy pasting the link and describing it myself.

Note:
Instagram does have a saved items folder system, but the folder process for saved posts can only be utilized when you are saving a post from your feed, and not from inside a reels, or from the Saved section, but then it doesn't tell you which of your posts are not in folders. (imagine having your Gmail All Mail section, and your folders, but no inbox).","['Have a try with Telegram, I know a lot of bots being built to send things there']"
"Recently, I saw a store on the AliExpress platform to buy this product very cheaply. Has anyone used his product? Can you share your experience, thank you very muchÔºÅ",https://i.redd.it/g0fb84ao2lba1.png,Automate,,
Is there an AI that I can train to illustrate my photos in a specific style?,https://www.reddit.com/r/Automate/comments/10aioqh/is_there_an_ai_that_i_can_train_to_illustrate_my/,Automate,"We own a business where people send us their photos to be illustrated in a specific style. Is there an AI tool I can train to start automating this instead? It could help us save a lot of time and money. 

Here are the final [illustrations](https://imgur.io/a/XRmq2AC) - I don‚Äôt want to share the original photos but I‚Äôm sure you could imagine them, too.","['Number of examples and budget?', 'Possible? Absolutely. Like /u/charlesrwest asked, budget and number of examples are a huge factor here. Training data will likely be your limited resource. Not sure how deep a catalogue you have but ai models are hungry.\n\nRather than shooting for 100% photo to final product automation I would probably consider just trying to streamline the process as much as you can, working on individual components of the process, and then stitch it together.\n\n- Background removal\n- Automatic masking of eye features\n- Posterization of general image\n- Isolation of clothing, henna, etc, and higher res posterization of that.\n- Text is straightforward. Could automatically suggest colour based on clothing/contrast evaluation.\n\nEven if these things are done individually and manual work can get you the last 20%, might be the most cost effective solution.', ""Yes, try the deep dream generator first. https://deepdreamgenerator.com/\n\nIf you're technically inclined, the cutting edge is using Stable Diffusion with a custom trained model. But you need a powerful system to run it.""]"
An AI wrote this guys video,https://youtu.be/S7tQGgdpEGQ,Automate,,
Google Calendar events based on Outlook events,https://www.reddit.com/r/Automate/comments/108i6ja/google_calendar_events_based_on_outlook_events/,Automate,"Would anyone know a way to create events on Google Calendar if a new event has been added to Outlook Calendar? It's not an invite or in any way actually ""connected"" ‚Äì basically if an event is created in Outlook, it needs to book the same time in GC with any generic title.","['Needed to do this at a previous org and found this tool worked best - https://calendarbridge.com/pricing/', 'I have been using [this](https://github.com/phw198/OutlookGoogleCalendarSync/) for a couple of years, works like a charm.', 'Zapier']"
Breakthrough Artificial Intelligence Learns To Use Robotic Arm Better Than OpenAI + Google With Reinforcement Learning | New AI Humanoid Robot | New 3D Scene Synthesis AI,https://youtu.be/PW-CO-x1Yrk,Automate,,
I created a program that downloads multiple inputted videos from Instagram and TikTok without a watermark,https://github.com/PabloEscobar1337/tiktok-and-instagram-content-downloader,Automate,,
Intelligent Document Processing,https://www.reddit.com/r/Automate/comments/107n2wu/intelligent_document_processing/,Automate,"Hi!

I am trying to learn about Intelligent Document Processing

Need to build a automation tool to find some words in documents in pdf/word format

Make a check list about what was found 

These documents are digitalizations from a scanner 

Some documents have 900 pages or more, and some have bad quality digitalizations from decades ago (probably need to setup a database for each word)

I know there's several which can do that job, but I am looking for something more accessible, these available are too expensive targeting enterprises 

Any guidance would be very helpful!",[]
The Lazy Productivity Script - A tool that uses OpenAI‚Äôs Whisper and GPT-3,https://twitter.com/AllAbtAI/status/1612317768132558849?s=20&t=4RTBzL77gEOEwgyINkHKzA,Automate,,
Lane following autonomous model car,https://www.reddit.com/r/Automate/comments/107idgh/lane_following_autonomous_model_car/,Automate,"We have to develop a model car that should drive autonomously with the help of floor markings. The 2 floor marking lines are about 30cm apart and can have different colors, i.e. not just white or yellow. Do any of you know an open source project that already implements this or any tutorials I can start with. I don't have the training data to train an AI myself.

As hardware we have a Jetson Nano 4GB Ram, an Intel RealSense D435 Depth Camera and 4 mecanum wheels","['Is this for Amazon Deepracer?', 'Lego robotics had a kit that did this.  Easy to program, used light sensors to guide it along any path you make with tape on the floor.']"
Should I learn powershell or automation tools (Automation 360 & UiPath)?,https://www.reddit.com/r/Automate/comments/105x8ay/should_i_learn_powershell_or_automation_tools/,Automate,"I already know python, I've done some web scraping using it and automated pulling sales data from multiple websites.

I also know SQL, and recently tried using some automation tools such as Automation Anywhere (didn't like it though).

And I'm wondering whether learning powershell would be good for a career in automation, or is it that RPA tools are mostly used in automation?

Thanks in advance.","['Powershell if you eant to work in cloud/devops, uipath if you want to go the RPA route. RPA is a type of automation, but it is not the only way.  With sql and oython you can work in both, it depends more of your final destination.', 'ignore Powershell, its garbage, go with bash']"
Leetcode obsolete?,https://youtu.be/ntKqPEaqso8,Automate,,
New York City‚Äôs education department bans students and teachers from using ChatGPT.,https://medium.com/inkwater-atlas/new-york-citys-education-department-bans-students-and-teachers-from-using-chatgpt-243ef0507f84,Automate,,
Does an AI email assistant exist?,https://www.reddit.com/r/Automate/comments/104vpbv/does_an_ai_email_assistant_exist/,Automate,"Hey everyone,

What I'd ideally like is a kind of AI inbox assistant.

I get \*so many emails\*. I want them filtered into 'Reply now', 'Important', 'Read later', 'Not needed'.

The ideal case is that they would be further categorised by the kind of action to be taken. Then with an AI language model, a draft is there to send - e.g. when someone asks for a call, there are two drafts there: no thanks, and a yes with a link to my calendar. 

Or when a customer asks the same question as has been asked 100s of times before, the draft answer is there to send with 1 click.

Does this exist?","['Oddly enough had this conversation with a friend of mine who works in AI. He sent me this might help?\n\nhttps://ellieai.com/', 'Hey,\n\nA close one, more than an email assistant, it works as a social media assistant as well. Though you cannot save templates, it can write a contextual answer as it takes hints.\n\n[https://www.reddit.com/r/ProductivityApps/comments/zu5lzi/an\\_ai\\_reply\\_assistant\\_for\\_emails\\_and\\_social\\_media/](https://www.reddit.com/r/ProductivityApps/comments/zu5lzi/an_ai_reply_assistant_for_emails_and_social_media/)', 'I haven\'t seen what you\'re asking for, but I know the problem, and I have had a noodle with OpenAI\'s Playground to see if I could train a model.  I called it ""Busy Man\'s Email"".\n\nI dropped a load of my own emails, wrote what the preferred response would be, and it did really well.\n\nI got it to check if the email was from a person or an automated email system (people weighted higher in certain categories). It output a less-than-a-tweets characters summary of the email plus  Classification, Resource Required (i.e. banking, email, web, physical item, phone etc.), Urgency, Action Required Status etc., \n\nIt did a pretty good job. My own idea was to get it so that I could have only \'action required: yes | Urgent\' notifications, and then have a list of the summaries of emails sent to me to review as I have opportunity.  I could also then just ask for all \'banking/finance\' messages to be shown so I could then just do all of that in one go, and likewise all \'email response required\' - keep everything silo\'d if it isn\'t super important/urgent.\n\nIt would be a piece of cake to get the AI to write a response to the email (it excels at that), but writing your-industry-specific stuff would be a lot harder as the fine tuning (the little I know about it) would take a __lot__ of data and a relatively high cost. Fine tuning OpenAi\'s models is quite expensive. Personally I\'d absolutely pay for it if I thought I had a snowball\'s chance of being able to integrate it properly!\n\nHeck, if anyone wants to work with me on it I\'ll stump up the cashola!\n\nIf I could actually code then I would be building this myself.  I __am__ the perfect case for testing!']"
OpenAI to Hit $29B Valuation After Latest Share Sale,https://metaroids.com/news/openai-to-hit-29b-valuation-after-latest-share-sale/,Automate,,
What Job category does warehouse automation fall under?,https://www.reddit.com/r/Automate/comments/104yltw/what_job_category_does_warehouse_automation_fall/,Automate,"https://youtu.be/4DKrcpa8Z_E

Hello you all. Saw this video. I think it would be interesting to work in a field similar to this. 

Where would I begin looking? PLC or another field to work on projects like this?

Thank you","['Based on this, you may be interested in being a Controls Engineer, Controls Technician or joining an Operational Technology team.', 'You will use PLCs for this type of work. Education wise, if you are going for a bachelor‚Äôs, an EE degree is what you‚Äôre looking for. The role you‚Äôd be in is called a Controls Engineer or Tech like the other commenter mentioned. This entails a mix of both mechanical and electrical system design and integration.\n\nI‚Äôm a controls engineer who just started his own firm selling quality testing machinery. If you have any questions don‚Äôt hesitate to ask!', 'Can confirm, the earlier comments are right on the money. I am a controls engineer at an automation OEM.']"
83 People Know the Truth | How To Automatically Update Youtube Video Title?,https://youtu.be/FPL_qfl9M9c,Automate,,
"Browse AI is the first AI-powered web automation software that learns to perform data extraction, monitoring, and automation tasks on the web. Get 200 Credits",https://browse.ai/?via=free,Automate,,
New Nvidia AI Robot Simulation Tech + Breakthrough Google Muse Artificial Intelligence,https://www.youtube.com/watch?v=VETMzQi1-UY,Automate,,"['[removed]', 'j', 'Lol, [www.reddit.com/comments/**watch**](https://www.reddit.com/comments/watch) is the URL.']"
Snake game built automatically with ChatGPT,https://youtu.be/DvqE2iYWyfk,Automate,,
Meet GPTZero: The AI-Powered Anti-Plagiarism Program,https://medium.com/inkwater-atlas/meet-gptzero-the-ai-powered-anti-plagiarism-program-4a6ac41ea0d7,Automate,,
"As AI tools have quickly become a controversial topic in the game industry, modl.ai aims to make AI tools that support developers, not supplant them. Get more details here:",https://www.reddit.com/r/Automate/comments/103wd0o/as_ai_tools_have_quickly_become_a_controversial/,Automate,[https://www.gamedeveloper.com/programming/using-ai-bots-as-game-development-tools-not-replacements-with-modl-ai](https://www.gamedeveloper.com/programming/using-ai-bots-as-game-development-tools-not-replacements-with-modl-ai),"['I would like to see a game that uses A.I. in game to create new map areas, storylines and NPCs.\n\nEssentially, the developers could build a base game with X number of quests, then the A.I builds more quests based on the player‚Äôs interactions and play style.']"
Get ready for Bing Search with ChatGPT!,https://medium.com/inkwater-atlas/get-ready-for-bing-search-with-chatgpt-fb255d63c5f,Automate,,
Memory Match Game Automatically coded in python,https://youtu.be/knm4KOaeSxU,Automate,,
"Nvidia VS Microsoft : Breakthrough 3D Avatar Creator AI Turns Text, Images, and Video Into Realistic Avatars",https://www.youtube.com/watch?v=yZ3RtunGJUU,Automate,,"['[removed]', 'j', 'Lol, [www.reddit.com/comments/**watch**](https://www.reddit.com/comments/watch) is the URL.']"
What to do when hyperparameter tuning doesn‚Äôt improve model performance?,https://www.reddit.com/r/Automate/comments/1027o9d/what_to_do_when_hyperparameter_tuning_doesnt/,Automate,,"[""Check the data for biases or unbalances, try to get more data, try different models, make sure you aren't get stuck on local minima for your tuning""]"
Using GPT-3 to automate content repurposing for social media,https://www.reddit.com/r/Automate/comments/1027x84/using_gpt3_to_automate_content_repurposing_for/,Automate,"Hello folks,

It's crazy how versatile and powerful GPT-3 and Open AI are.

This post is a combination of both information and promotion, so please bear with me.

I got some great feedback and support from the members of this subreddit on [my last post.](https://www.reddit.com/r/Automate/comments/z7sofx/using_gpt3_to_reply_to_automate_email_replies/) So sharing a post here again.

Many of our users had been asking for the ability to repurpose their existing blog and newsletter content into social media posts.

They are mostly busy content writers so this can be really useful to them in their day-to-day work.

So I tried a simple prompt - ""Summarize this for a tweet""

I took the content from¬†an [OpenAI Blog](https://openai.com/blog/our-approach-to-alignment-research/) and summarized it into a tweet.

&#x200B;

https://preview.redd.it/lro33pbout9a1.png?width=800&format=png&auto=webp&v=enabled&s=641e3cbac828c2e0e4b5c4ff06a2568b3ec424e5

 

Next, I tried another prompt - ""Summarize this into a LinkedIn post""

And that worked alright as well.

&#x200B;

https://preview.redd.it/6rf7k1pput9a1.png?width=800&format=png&auto=webp&v=enabled&s=a8f0d633897284bff66e55a0992afe8be800c44e

 

Finally, I tried this prompt - ""Summarize this into a Facebook post.""

&#x200B;

https://preview.redd.it/3bpnuh4sut9a1.png?width=800&format=png&auto=webp&v=enabled&s=48d77576627b8acc3c78dea5b93232ff6b891f83

 

These prompts worked well so I decided to integrate them into our Mac app, and the users loved it.

Here is the final demo of how it works inside my app -

&#x200B;

https://reddit.com/link/1027x84/video/m8qtr6rtut9a1/player

 

It can be difficult to copy and paste the content into the playground.

If you have a Mac and want to do this more straightforward way then please try out my app [Elephas](https://elephas.app?ref=rAutomate-socialrepurpose)

I have built many such utilities into the app to help you use AI on a daily basis.

You can try it for free for 7 days.

Do share your feedback.

Hope you find it useful

Thanks",[]
Hangman coded in 3min 30 seconds automatically with ChatGPT,https://youtu.be/_F2jAoeZMiA,Automate,,
How to Stay Relevant in a World Full of Smart Bots?,/r/OurGreenFuture/comments/102juid/how_to_stay_relevant_in_a_world_full_of_smart_bots/,Automate,,
ChatGPT: Why It‚Äôs Not a Threat to Google Search,https://medium.com/inkwater-atlas/chatgpt-why-its-not-a-threat-to-google-search-639c2f915f53,Automate,,
How to automate the sharing of posts from a facebook page to multiple facebook groups?,https://www.reddit.com/r/Automate/comments/1028csc/how_to_automate_the_sharing_of_posts_from_a/,Automate,"I'm dumb and have limited resources. 

I've seen it was somewhat possible to do with ""make"" (former intergromat) but I really don't know how. 

I just want to share posts from one page across multiple groups. Do you have any idea how I can do this?",[]
Stepper motors with built-in homing sensor/permanent zero index?,https://www.reddit.com/r/Automate/comments/101tzgh/stepper_motors_with_builtin_homing/,Automate,"I am after a stepper motor with a built-in sensor so that I can home multiple stepper motors to the same rotational position (relative to the flattened shaft). I have previously done this with dual-shaft stepper motors with a cam and switch but that was too finicky.

I am looking for an off-the-shelf solution and looked into using the zero index of an encoder. But most stepper motors with encoders are only aligned by eye when installed so the zero index position would vary between motors.

Does anyone know of a stepper motor that has a permanent zero index machined onto the shaft or something similar?

Thanks!","['You can also buy servo motors that are controlled by step and direction.  These can have additional features such as homing modes, etc, with the simplicity of steppers for input.', 'RemindMe!', 'There is a startup company that has this. But it is not common in the market yet.  https://www.vincentgroenhuis.nl/wp/home/2022/09/04/vincents-research-videos/\n\nOther than this you can only go for conventional add-on of an absolute encoder', 'AMCI makes nice steppers with the motor diver and controller built into the stepper. Has the I/O and encoder built into the stepper body. \n\nhttps://www.amci.com/plc-automation-products/smd17e2-networked-series-integrated-stepper-motor-controller-drive/#!/243\n\nThey have NEMA 17 and up and have Ethernet/IP and Profinet Ethernet comms.', 'Hello Realistic_Oven_5349, \n\nI‚Äôm an engineer for Teknic ‚Äì thanks to those who commented about our products.  One clarification I wanted to make is that although the encoders used in Teknic‚Äôs ClearPath servo systems each have an index pulse, these index pulses are not factory-aligned to a mechanical feature on the shaft. However, Clearpath motors do have a feature that would give you the functionality you‚Äôre looking for, albeit implemented in a different (and more flexible) way. \n     \nClearPath SDSK and SDHP motors have a homing feature called ‚ÄúShaft Angle Homing‚Äù where, using the MSP configuration software, you configure the exact homing position within one mechanical revolution of the motor shaft. Then, whenever the homing routine is executed, the motor always returns to this same angular location (you can also specify the homing speed and direction).  Because this position is stored in the motor‚Äôs non-volatile memory, the value is retained even if power is removed. More information and configuration details can be found in our manual, Appendix H (scroll down to the ‚ÄúShaft Angle Homing‚Äù section).  https://teknic.com/files/downloads/clearpath_user_manual.pdf\n\nI hope this helps. If you have any additional questions, feel free to contact Teknic directly at https://teknic.com/contact/ or give us a call at 585-784-7454. \nThanks, Abe A. ‚Äì Teknic Servo Systems Engineer']"
TickTackToe automatically coded in python with ChatGPT prompts,https://youtu.be/m4L2qtNqyus,Automate,,
Ideas for projects to automate?,https://www.reddit.com/r/Automate/comments/101fk0l/ideas_for_projects_to_automate/,Automate,"My friends and I are working on automation projects for learning purposes.

We tried pulling financial statements for every stock from a website and do some analysis on them (calculate current ratio and P/E).

We used Automation 360, and it sucked, but we managed to get it done.

We know python and wouldn't mind using it for automation.

I'm looking for projects ideas to work on that we can put on our resumes.

Thanks in advance.","['Automate extraction of images from PDFs, classification of the document type  eg passport or academic transcript and extraction of the information using ocr or AI', ""You ever get bored when you're doing something you have to do, but would rather be doing something else?  Automate that."", 'Will you take on contract work? \n\nAlso, start a business doing just that and you can be your own boss! the ideas will come to you and you will get paid!']"
"Find out what machine learning has in store for player experience, Julian Togelius chats with Matthew S. Smith about AI and ML-powered Bot testing games and how it will impact the games industry in this WIRED article. Let us know what you think will be the future of ML in games.",https://www.wired.com/story/machine-learning-ai-game-development-bosses-enemies/,Automate,,
What are some common challenges and opportunities in the field of data science and machine learning?,https://www.reddit.com/r/Automate/comments/101bmny/what_are_some_common_challenges_and_opportunities/,Automate,,[]
Prompt Extension Ai tool. Creates multiple enhanced art prompts from a seed prompt. Generates random prompt.,https://www.promptextend.com/,Automate,,
2023 US Automation Events and Conventions,https://www.reddit.com/r/Automate/comments/100vcip/2023_us_automation_events_and_conventions/,Automate,"I work at an automation integration startup, but we currently don‚Äôt attend any machine or automation conventions. 

What are your favorite industry and indie events geared towards robotic and system automation?

This is the list I have so far

DesignCon 2023
Jan 31, 2023~Feb 2, 2023
Santa Clara, CA 

Smart Manufacturing - Take Automation to the Next Level with Sensors, Autonomous Hardware, AI and Software Robots
Feb 02,2023
Online

ATX West
FEBRUARY 7-9, 2023
Anaheim, CA

Promat 2023
March 20-23, 2023, Chicago IL.

Smart Manufacturing Automation Summit
29 Mar 2023 
Rosemont, United States

Automate
May 22, 2023~May 25, 2023
Detroit, MI

Embedded Vision Summit 2023
May 22, 2023~May 25, 2023
Santa Clara, California 

Food Northwest Process &amp; Packaging Expo
05 - 06 Apr 2023
Portland, Oregon 

Automate Show 2023
May 22 - May 25, 2023 
Detroit, MI 

Design Automation Conference 2023
Sunday, July 9, 2023, 
San Francisco, CA

World Congress on Industrial Automation
Mon, 20 - Wed, 22 Jul 2015
Burlingame, USA

Advanced Manufacturing Expo
09 - 10 Aug 2023
Grand Rapids, United States

Pack Expo
September 11‚Äî13, 2023
Las Vegas, NV USA

Fabtech 2023
September 11-14, 2023
Chicago IL

Industrial Automation North America
Sept 12 - 17
Chicago, USA

FA&amp;amp;amp;M Food Automation and Manufacturing
Oct 11~13 
Bonita Springs, FL","['There are a ton of conferences aimed towards specific manufacturing areas that still have a good amount of automation involved. A lot of determining which ones to attend will depend on which section of industrial automation you want to work in.\n\nFabtech - Machining, Welding, etc\n\nPack Expo - Packaging and Processing\n\nIAAPA - Entertainment and Amusment Parks\n\nFA&M - Food Industry Automation\n\nATX West - General Automation\n\nProMat - Supply Chain and Manufacturing', 'We‚Äôre a robotics integrator, I look at the vendors I‚Äôm most interested in seeing then look at the shows they attend as similar vendors will attend. For example, we‚Äôll see what shows Robotiq is attending and compare vendors there.', ""This is great. Don't know any off the top of my head, but I would consider reposting this to r/embedded, r/python, etc depending on the fields that interest you""]"
Chat GPT uses Weather API (bad UI skills tisk tisk),https://youtu.be/vamx_m1wZTE,Automate,,
"ChatGPT-4, The Newest And Most Advanced AI System, Might Prompt A Major Shift In The Way We‚Ä¶",https://medium.com/inkwater-atlas/chatgpt-4-the-newest-and-most-advanced-ai-system-might-prompt-a-major-shift-in-the-way-we-fd764f97212c,Automate,,
Text to video,https://www.reddit.com/r/Automate/comments/100f0pm/text_to_video/,Automate,"What are programs that make it easy to find video or photo clips to pair with an audio file so that I can turn the audio file into a video?  I also want to add background music and sound effects. The audio files are 5 mintues stories are about different animals, trips, and experiences.",[]
Chat GPT writes to-do list Python code,https://youtu.be/2gkNV_vRCK0,Automate,,
Artificial General Intelligence (AGI) and its Role in Our Future,/r/OurGreenFuture/comments/zz8wxr/artificial_general_intelligence_agi_and_its_role/,Automate,,
Best 3D Printed Houses Printed in 2022,https://youtu.be/e5xK2wWUIxw,Automate,,
The Singularity Timeline | The future of Artificial Intelligence + AGI + ASI (2023 - 2100¬π‚Å∞‚Å∞),https://youtu.be/P5HNeahRYDM,Automate,,
What is Data Governance and why is it important?,https://www.reddit.com/r/Automate/comments/zywqkq/what_is_data_governance_and_why_is_it_important/,Automate,,"[""This isn't probably the right sub for a detailed explanation but generally it is the corporate oversight around data so it's collection, storage, and it's use.\n\nhttps://cloud.google.com/learn/what-is-data-governance""]"
Power Machine Learning techniques and AI Apps for Price Prediction for Agricultural Products.,https://i.redd.it/4wmagchj419a1.png,Automate,,
What are the best techniques for feature engineering?,https://www.reddit.com/r/Automate/comments/zxz2t7/what_are_the_best_techniques_for_feature/,Automate,What are the best techniques for feature engineering?,['What application? The field is to broad for that question as you wrote it.']
Draganfly Launches New Flight Facility for Land Mine and Anomaly Detection Protocols,https://draganfly.com/press-release/draganfly-launches-new-flight-facility-for-land-mine-and-anomaly-detection-protocols/,Automate,,
Are there any groups that are trying to help us prepare for the realities of automation?,https://www.reddit.com/r/Automate/comments/zwx1dq/are_there_any_groups_that_are_trying_to_help_us/,Automate,"I've been playing around with ChatGPT for the past couple of weeks, and the potential is incredible. If you haven't tried it, I would highly recommend checking it out.

AI is improving rapidly, and there are very few jobs that I think are safe from being automated in the future. CGP Grey actually has an excellent video on the subject [Humans Need Not Apply](https://youtu.be/7Pq-S557XQU).

I don't think that AI will be ready to replace humans tomorrow, but I firmly believe that it will be possible within my lifetime, if not within the next 10 years.

Having said that, I don't think that our society is ready for millions of people to lose their jobs. We don't have a way to take care of or support these people.

Sadly, I think the ""human"" solution to AI will be to ban it, and guarantee that people will get to keep their jobs.

Personally, I'd like to see us move in the opposite direction. Rather than guaranteeing jobs, I'd rather see us guarantee housing, healthcare, education and maybe a Universal Basic Income?

People would have the freedom to work if they wanted to, but they wouldn't be required to. They could take care of their families, pursue higher education or pursue their passions.

I can't pretend to be an expert or to know what the best way to structure that type of society would be.

But if I can, I want to use my energy to work towards it. What is the best way that I can advocate for this? Are there any groups working on this right now? How can I join them?","[""You may want to join the [https://postscarcitymap.org/](https://postscarcitymap.org/) Discord, it's a small community looking into accelerating the transition to basic-post scarcity. Here you can find some (opinionated) background: [https://lorenzopieri.com/post\\_scarcity/](https://lorenzopieri.com/post_scarcity/) and more resources [https://github.com/lorepieri8/awesome-post-scarcity](https://github.com/lorepieri8/awesome-post-scarcity) ."", 'For this to happen, we need people to let go of the concept of ""earning"" a living.', 'Yeah we‚Äôre definitely on the precipice here, our current societal framework is not ready for automation and we need to figure it out quick because that is not about to stop‚ÄîIt‚Äôs just going to be harnessed in very destructive ways', 'What does ""GPT"" stand for in ""ChatGPT""?', 'Automated nuclear reactor core safety analysis and contributed to automating design 30 years ago. \n\nNothing is safe.', '/r/projectvoy\n\n/r/osd', 'Join the libertarian party']"
Background of Artificial Intelligence,https://medium.com/night-riders/background-of-artificial-intelligence-c055601650c3,Automate,,
Inserting date in URL,https://www.reddit.com/r/Automate/comments/zwrp37/inserting_date_in_url/,Automate,"Hello, I go to high school in Denmark. The online system we use for viewing our schedule, sending messages etc. is called Lectio. It is based on Javascript AFAIK. I want a script that converts the current date to year-month-date, and inserts it in the middle of a URL. 

I have this link for getting my schedule of the day. [https://www.lectio.dk/lectio/202/SkemaAvanceret.aspx?type=ShowListAll&starttime=2023-01-04T00:00:00&endtime=2023-01-04T23:30:00](https://www.lectio.dk/lectio/205/SkemaAvanceret.aspx?type=ShowListAll&starttime=2023-01-04T00:00:00&endtime=2023-01-04T23:30:00)

The dates has to be in the following formate: year-month-date

Example: 2023-01-04

The script is going to run on my Iphone Shortcuts. (Shortcut activated, date inserted in URL, opens the URL in Safari).

Looking forward to hear from you,

\- DIS","[""let yourDate = new Date() yourDate.toISOString().split('T')[0]""]"
New Image-To-3D Artificial Intelligence Beats Nvidia | New Palette-NeRF For 3D Scene Editing | New AI Generalizes Navigation Across Robots,https://www.youtube.com/watch?v=RZu8B69PusQ,Automate,,"['[removed]', 'j', 'Lol, [www.reddit.com/comments/**watch**](https://www.reddit.com/comments/watch) is the URL.']"
RethinkX and the Star Trek economy - interesting take on future of automation,/r/OurGreenFuture/comments/zuyh4n/rethinkx_and_the_star_trek_economy/,Automate,,
What Is A Power Waxer And How To Use It ‚Äì Shine Armor -,https://usabusinessmagazine.com/power-waxer/,Automate,,
HIPAA Compliant Automation?,https://www.reddit.com/r/Automate/comments/zvpdws/hipaa_compliant_automation/,Automate,"ISO of a HIPAA compliant automation software they would recommend. I'm an entrepreneur in healthcare and could benefit from just about anything, ranging from service to document generation.","['It\'s not the software that HIPAA is concerned with.  It\'s the data and what you do with it.  Javascript is HIPAA compliant...so long as you configure your solution to adhere to HIPAA rules.\n\n[Here](https://intraprisehealth.com/5-most-common-hipaa-privacy-violations/) is a FAQ talking about the most common HIPAA violations. You\'ll notice that none of the violations have to do with ""using PHP""...\n\nAs far as actual suggestions for ""automation software"" goes...my suggestion is to look into a combination of PowerShell and Ansible. Both can run on Windows (way more common in healthcare than you\'d think) and Linux. Both are free to use. And although I can\'t give more details, I know for a fact that this combination of automation tech can support one hell of a healthcare related tech stack.', ""I read an article recently about someone using Text Blaze to create documents. Not for healthcare but for government documents. I haven't looked much into it but it sounded interesting"", 'I just finished writing a bunch of automation software for a healthcare business. The only thing you need to worry about with HIPAA is essentially being careless with patient data, in a way that could expose it.\n\nSo if you are just doing everything locally (not sending info over the net) you are likely going to be fine.\n\nIf you do need to send info out, there are a ton of options that can be utilized that are specifically made to be HIPAA compliant. A lot of times you don‚Äôt even need those - for instance one of the things we did was automate scanning & uploading docs to their EMR website. You can just upload that stuff like anything else, as long as you know the destination is compliant.\n\nWhen you say ‚Äúservices‚Äù, what do you mean? Like texting the client for appointment reminders?']"
"""explain the biggest challenge for humanity""",/r/OurGreenFuture/comments/zw0lgn/explain_the_biggest_challenge_for_humanity/,Automate,,
HIPPA Compliant Document Generation from Form Responses,https://www.reddit.com/r/Automate/comments/zvpnlt/hippa_compliant_document_generation_from_form/,Automate,"Seeking best recommendations for a HIPAA compliant document generation platform based on the responses of patients who answer questions on a form, such as Google forms or any other platform. The forms are very long (about 11 pages) and the responses would assemble a customized document. Conditional logic would be necessary.

I have tried out VBA to macros which was limited and tedious. I've made a million templates but tired of endless typing. I'm limited by options because it has to be HIPAA compliant.

I've become aware of Form Publisher in Workspace, Smartsheet, and Documate but haven't used any. Also have observed Typeform integrated with Gorilla Reports. Not sure which direction to go in.

I also suck at tech so would need to be user friendly or something I could hire for.",[]
Introducing Dramatron: The AI Tool From DeepMind That Writes Film Scripts,https://medium.com/inkwater-atlas/introducing-dramatron-the-ai-tool-from-deepmind-that-writes-film-scripts-83f858402ed2,Automate,,
What do you automate and how?,https://www.reddit.com/r/Automate/comments/zux1m4/what_do_you_automate_and_how/,Automate,"I can't think of anything I can automate. Looking for inspiration and ideas.

Edit: thanks for the input people","['From my experience a lot of company processes can be automated. The better question is what not to automate. As time to automate might not even be worth it for some processes.\n\nFor a project - think of something manual you regularly do. It can probably be automated in some way.', 'Build pipelines is a form of automation. And it is very useful to be good at it as a programmer.', 'With a small (cheap) PLC or an Arduino processing kit you can add timers and counters to automate just about anything. \nI built a photo eye sensor unit to detect when the cats jump on the kitchen counter. A small water sprayer thwarts there advances üòâ', 'Business processes, procedures, and practices.\n\nAnything involving digital information moving around in any format.\n\nAnything you spend time doing every day. Follow that by anything you spend time doing every week.', 'I automate my 3D printers to maximize efficiency', 'Automate a binary options trading account. Have a bot make money for you']"
Poe and ChatGPT: The New Kids on the Block,https://medium.com/inkwater-atlas/poe-and-chatgpt-the-new-kids-on-the-block-22b04707280c,Automate,,
How to automate and anonymise process of collecting feedback?,https://www.reddit.com/r/Automate/comments/zub64z/how_to_automate_and_anonymise_process_of/,Automate,"Tl;dr is there a way to collect survey data from multiple people using MS Access?  

I‚Äôm looking to improve an internal process which currently consists of internal feedback being sent to someone‚Äôs email, who then has to manually enter this data into a spreadsheet. This seems like a pretty wasteful process and I also think the lack of anonymity deters colleagues from giving honest feedback. I want to instead collect this feedback from colleagues, ideally as an anonymous form which is easily pulled into a spreadsheet/database.

In my previous role we would‚Äôve used MS Forms, which was great as it would automatically populate a spreadsheet. However we have really strict information governance rules which bans access to MS Forms due to overseas data storage. I have MS Access installed but have never used it before. Is it possible to collect data using MS access? 

I know that there are a lot of paid tools (e.g. surveymonkey) etc that could easily do this. However, I work in the public sector - budgets are very tight and it‚Äôs unlikely they would agree to fund this. Even if they did agree, it would have to go through months of approvals, by which point I will be working on a different project anyway. However if anyone has come across any other Microsoft based solutions or free/open source solutions then that would be incredibly welcome :)",['Depending on the scope of your surveys Zoho Survey does offer a free version of their program. Some limitations apply to it though.']
Task Automation - Help,https://www.reddit.com/r/Automate/comments/zu38ko/task_automation_help/,Automate,"Looking to find a task automation solution that will take a link from a spreadsheet, paste it into a website (webpage speed calculator/analytics), extract the result (1 number) and paste the number back into the spreadsheet in the cell next to the cell with the website link. Ideas? New to the whole TAS world. Microsoft power automate or something similar?","['UIPath ?', 'Except from rpa automation tools, this can be done easily with python/selenium if you have experience with programming‚Ä¶merry christmas everyoneüç∫', 'Thank you both. Did try doing some unrelated stuff with python and selenium but unfortunately I have next to no compsci/coding background. Happy holidays.']"
OpenAI‚Äôs New Point-E Artificial Intelligence Does Text-To-Point-Clouds-3D-Models In Blender 600 Times Faster Than Google,https://youtu.be/-TpvzNTl9VQ,Automate,,
How does one learn to automate tasks with command line like this? (LTT video on hak5 rubber ducky.),https://youtube.com/clip/UgkxahIQjP-bRfVg-f3_SHzR4JfjN6Txqw1p,Automate,,
I created a tool to automate tedious tasks in your browser with AI,https://v.redd.it/cqjzx9ulzg7a1,Automate,,
Google Is Working on Some Amazing Artificial Intelligence Products,https://medium.com/inkwater-atlas/google-is-working-on-some-amazing-artificial-intelligence-products-5bf9a2722178,Automate,,
ñ¶πI asked AI to make a Music Video‚Ä¶ the results are trippyñ¶π,https://youtu.be/XHowvIicYOI,Automate,,
I created a complete (audio) book in 10+ languages in a few days using generative AI: Here is what I learned,https://medium.com/p/f3a553887496,Automate,,
JUNG_E Trailer Teaser (2023) A.I. Combat Warrior Sci-Fi Movie | 4K UHD,https://youtu.be/JZ0ogTJFago,Automate,,
Artificial Intelligence To Nerf Video Copyright With SinFusion Breakthrough | New Google Robotics Transformer Generalizes To Teach New Robots | Robot Dogs Walk On Walls & Ceilings,https://youtu.be/oliXcvdWJkY,Automate,,
[Podcast] JITX aims to change the way engineers design circuit boards using code,https://www.allaboutcircuits.com/podcast/jitx-aims-provide-superpowers-circuit-design-engineers/,Automate,,
RPA Use Cases Leading Businesses To The Next Level With AI-Powered Process Automation,https://www.kdnuggets.com/2022/12/aipowered-rpa-ia-mean-businesses.html,Automate,,
automated DJ software,/r/DJs/comments/z60ahl/automated_dj_software/,Automate,,
AI has reached the solar industry! Find out how this $4 billion valuation company expanded with machine learning,https://www.reddit.com/r/Automate/comments/zqmx3c/ai_has_reached_the_solar_industry_find_out_how/,Automate,[https://www.youtube.com/watch?v=wttfcXQsQfo](https://www.youtube.com/watch?v=wttfcXQsQfo),[]
So we created a series called the History of AI ...,https://www.reddit.com/r/Automate/comments/zppxhi/so_we_created_a_series_called_the_history_of_ai/,Automate,"In this series, we explore the history of artificial intelligence in games and how it's revolutionized video games. Check out our first episode and let us know what you think.

## Watch here now ‚ñ∂Ô∏è:  [https://youtu.be/s2aO7TIJrAc?list=PLEeBsU\_Yq7TPBlT3s1AeSkuiXjgDNjC6U](https://youtu.be/s2aO7TIJrAc?list=PLEeBsU_Yq7TPBlT3s1AeSkuiXjgDNjC6U)",[]
I asked ChatGPT to write a joke in the style of Abbott and Costello,https://vimeo.com/779468532,Automate,,
OpenAI Forecasts $1 Billion in Revenue by 2024,https://medium.com/inkwater-atlas/openai-forecasts-1-billion-in-revenue-by-2024-8089ff2efeea,Automate,,
DIY Two-Wheeled Self-Balancing Robot Project. I have shared all project files & documents as an open-source project on GitHub link given at comment.,https://www.youtube.com/watch?v=LykbhLb3tnc,Automate,,"['[removed]', 'j', 'Lol, [www.reddit.com/comments/**watch**](https://www.reddit.com/comments/watch) is the URL.']"
Q: campaign design automation,https://www.reddit.com/r/Automate/comments/zohof5/q_campaign_design_automation/,Automate,"Question: im a freelance graphic designer looking to automate my workflow. A lot of the work I get from my clients is pretty simple, i create or I am given a hero image and I basically version it out at different sizes and add different logos and slogans to it. 

I can imagine this‚Äôll get automated within the next 5 years but I do wonder.. Is there a way to automate this already? Like, put in the image, the campaign brief with the necessary versions needed and - bam- campaign assets are created? 

If not, do you suggest even trying to automate this? Or is that wayyy too big of a project for a beginner? Or maybe it‚Äôs just not the answer we need in the world lol

I‚Äôm still in the early stages of even understanding ai, automation and software development so any input is helpful. At the end of the day, i just want to get a conversation going about the topic relating to creative careers like graphic design. Feel free to discuss below. Thanks!",[]
"OpenAI's GPT-4 Coming Soon With 100,000,000,000,000 Parameters And Multimodal Input/Output, Meaning It Will Output Text, Audio, And Video",https://youtu.be/SqqXLwlgbew,Automate,,
What are the best platform/CRM for workflow automations?,https://www.reddit.com/r/Automate/comments/znhrde/what_are_the_best_platformcrm_for_workflow/,Automate,"I am working with a real estate investment company and planning to transfer their current CRM over to a new platform. We are looking for a CRM platform that is highly customizable and has strong workflow automation. Ideally, I'd like to build a system that has ""decision tree"" functionality. An example of this would be ""If a new lead is entered into the CRM, then assign the lead to a team member and give them the task of 'call lead'."" From there, I would like almost a prompt to ask the user the following ""did the lead answer the phone?"" If the answer is yes, it would ask the user to write notes and then automatically schedule a follow-up call into their future to-do list. But, for example, if the lead did not answer, I would want the follow-up call set for an earlier date/time so that we make sure to contact the lead before it is too late. Basically, I would like to create a decision tree automation for the entire process of the business so that the system will be followed to the T every time. Does anyone have any suggestions for which CRM would be best for this? Thanks","[""You're describing HubSpot at multiple stages here. But god help you with a migration, they'll probably need Salesforce as well when they're done with it.""]"
Automated batch tool for making preview images of 3D models?,https://www.reddit.com/r/Automate/comments/zn5qms/automated_batch_tool_for_making_preview_images_of/,Automate,"Is there a batch tool, program or script that could take many 3D model files and automatically create a few PNG/JPEG images of different angles for each one?","['I could have used this in so many ways over the last 5 years while automating ‚Äúconfigured to order‚Äù products like windows, doors, signage, and playground equipment. \n\nStill ended up having to run manual engineering tasks in order to properly configure a sales order, but this was not a failure of technological capabilities, rather a function of project budget in every case.']"
Customer Service task automation,https://www.reddit.com/r/Automate/comments/zn69cn/customer_service_task_automation/,Automate,"Forgive me if my question is stupid, but I want to know if it's possible to automate my tasks. I know there's MS PAD but I don't know if it'll work in my case as it is mixture of both desktop apps and web apps. 

So, my task is to pickup tickets on Edesk and respond to our eBay and Amazon customers. We copy the ticket # add it to our Excel tracker. Afterwards, we respond to the customer's message. There are message templates that we use but we still need to edit around it to match the customers concern. After responding, we copy both our response and our customer's message in a notepad and paste it to our internal API for documentation. As you can see it's already menial and boring. How do I automate this? Is there a macro like program that records what you do and simply runs it for you afterwards? Any suggestions are appreciated.","['I have a friend working in customer support and I recently talked to them about automation because I am pretty passionate about it. They told me about a tool they use to automate their work called Text Blaze. It seems pretty useful and I feel like it could do some of this. Not sure, but might be worth checking out. Hope you find a solution']"
How Close Are We From Beaming Energy To Earth? Project Solaris,https://www.youtube.com/watch?v=d_hyEqdm_Hg,Automate,,"['[removed]', 'j', 'Lol, [www.reddit.com/comments/**watch**](https://www.reddit.com/comments/watch) is the URL.']"
I make a video on how to use the AI to your benefit. Give it a watch.,https://www.reddit.com/r/Automate/comments/zmzz5d/i_make_a_video_on_how_to_use_the_ai_to_your/,Automate,"&#x200B;

https://preview.redd.it/d6d2qqhzc56a1.png?width=234&format=png&auto=webp&v=enabled&s=bd1384496385aa16f98f04ae80f15f053fb40eb4",[]
Automating twitter replies to latest tweet of a search term?,https://www.reddit.com/r/Automate/comments/zml9aj/automating_twitter_replies_to_latest_tweet_of_a/,Automate,"Is is possible to monitor a certain phrase on twitter, for instance a mention of my company name and reply to it with pre-written replies.","['I actually made a bot in UiPath for this. Search for *input word* reply with *input phrase*. UiPath is free with community edition', 'You might be able to do it. I found https://dancallisseo.com/blog/seo-marketing/ifttt-post-replies-twitter']"
I want help to automate desktop and browser to download some files from website and upload in the drive. What will the optimal approach for this,https://www.reddit.com/r/Automate/comments/zmo3pe/i_want_help_to_automate_desktop_and_browser_to/,Automate,,"['is it a private project or a company', 'This can most likely be done in a few lines of code using a well known scripting language. I suggest Ruby :) python or even JavaScript will do. Of course the complexity of this varies a lot depending on the file type you are downloading and how you would like to store them on disk.', 'You could probably do this with a few lines of python.\n\nIf you are not technical it could be done in a few tools easily.\n\nIs it a public website?']"
Automate scanned files to text-searchable PDF OCR conversion using OCRvision,https://www.reddit.com/r/Automate/comments/zm4oi9/automate_scanned_files_to_textsearchable_pdf_ocr/,Automate," 

Just drop your scanned files into a folder.

OCRvision software will OCR them and add an invisible text layer to the document.

After OCR, your scanned file content will appear in the text search results.

[https://www.ocrvision.com](https://www.ocrvision.com/?source=Reddit)",['$714 omg']
Six Breakthroughs in Artificial Intelligence in Video Games,https://modl.ai/ai-built-future-of-video-games/,Automate,,
Helllppp pleeeeaasssee,https://www.reddit.com/r/Automate/comments/zm3c7x/helllppp_pleeeeaasssee/,Automate,"Hi!! I‚Äôve been trying to create an automated feature to login to my Amazon associates account to grab data and post to a Facebook page, but I can‚Äôt find anything that will do it all. Everything gets stuck on login. Can anyone point me in the right direction or tell me if it is not allowed (and/or possible) with Amazon associates? This is my last resort as I am not super techy but know my resources. Thank you in advance!","['I managed to do that using Tasker on Android. I automated loging out and loging in once a day, without human assistance, as the app can wake up the phone by itself.', ""When you say it gets stuck on login, do you mean that you configured a workflow that just doesn't do anything? What platform or language are you using? Is there an error message?""]"
can i create an interactive slack bot using my own account?,https://www.reddit.com/r/Automate/comments/zm1kr6/can_i_create_an_interactive_slack_bot_using_my/,Automate,"Im looking to create something that post in certain groups of slack under my personal profile (for example, clock in group, post everyday at 8am ""clock in"")",[]
Nvidia Gives Robot Hand 42 Years of Training To Have Unparalleled Dexterity | New Google AlphaCode Holds Up With Humans In Competition,https://youtu.be/DT_zEcn9h6Y,Automate,,
How can you build Bots VIA API's with ElectroNeek,https://www.reddit.com/r/Automate/comments/zl5r4o/how_can_you_build_bots_via_apis_with_electroneek/,Automate,"Building your first bot on the ElectroNeek platform is simple. There are multiple ways to build a bot on our platform. Learn how you can build bots via APIs using ElectroNeek [Here](https://forum.electroneek.com/t/how-to-build-bots-via-api/902):

You can also join our community at [https://forum.electroneek.com](https://forum.electroneek.com/) for exclusive updates of our platform.

Happy Automation!!",[]
Do You All Think Artists Should Be Worried About A.I. Art?,https://youtube.com/watch?v=9P4tvK2LQSY&feature=share,Automate,,"['[removed]', 'j', 'Lol, [www.reddit.com/comments/**watch**](https://www.reddit.com/comments/watch) is the URL.']"
LaMDA‚Äôs Fear of Being Turned Off Reveals Sentience,https://medium.com/inkwater-atlas/lamdas-fear-of-being-turned-off-reveals-sentience-6ce455d75906,Automate,,
Chatbot requirements: technical and non-technical things to consider when everyone talks about ChatGPT,https://www.reddit.com/r/Automate/comments/zjzcsq/chatbot_requirements_technical_and_nontechnical/,Automate,"Hi there! Just want to share some tips on how to craft the right chatbot when everyone talks about ChatGPT. First of all, a custom chatbot company or any chatbot platform that does custom integration can integrate your chatbot with ChatGPT instead of Dialogflow. So yeah, you can have an outstanding customer service chatbot that can handle other topics. However, the right question is should you? 

If you want a chatbot that does solve issues, not creates more, you must start with **the proper requirements.** Well-structured chatbot requirements lay the right foundation for your future chatbot development.  ChatGPT is just one of the options of how you can use AI and automation and may be not the best depending on your budget and goals. 

**Your chatbot requirements should include these steps:**¬†

\- defining the main problem you want to solve with the chatbot,¬†

\- measuring the impact of the problem,

\- determining the main chatbot goal/objective,¬†

\- understanding the market and target audience¬†

\- paying attention to the ""internal audience"" of the chatbot (the people or the team in your company who will be working with the chatbot).

Imagine you have found a problem when analyzing customer feedback. Most customers are saying the customer service response time is very long, and that's why they are giving you a low rating.

Your objective for the chatbot could sound like this:¬†*""Decrease waiting time to 1 minute by the end of Q3 2023""*¬†or¬†*""Improve customer service response time from 18 minutes to 1 minute in the next Q""*

Having done this part, you can move to the next step, drafting the technical chatbot requirements.¬†

When working on the tech requirements, think about the following things:

* **Channels.**¬†Which channels do you want your chatbot to be on?¬†[Website](https://botscrew.com/blog/how-to-build-a-website-bot/),¬†[WhatsApp](https://botscrew.com/blog/a-step-by-step-guide-to-create-chatbot-for-whatsapp-for-business/), Facebook,¬†[SMS](https://botscrew.com/blog/sms-chatbot-a-complete-guide-for-business-use-cases/),¬†[Instagram](https://botscrew.com/blog/instagram-chatbot/), email, etc.
* **Languages.**¬†Which languages do you want your chatbot to ‚Äúspeak‚Äù? English, French, German, Arabian, etc? Should it speak one language or multiple?
* **Integrations.**¬†Which tools do you need the chatbot to be integrated with? CRM, payment system, calendars, maps, custom internal tool, etc.
* **Chatbot's look and tone of voice.**¬†If you have a specific vision of the chatbot, be sure to include this in the requirements. Also, if you have a very prominent brand personality and tone of voice, include that in your requirements as well.
* **KPIs and metrics.**¬†Be sure to specify if you have any specific¬†[metrics and KPIs](https://botscrew.com/blog/chatbot-metrics/)¬†you have that you want the chatbot to meet.
* **Analytics and Dashboards.**¬†Do you want the analytics to be in real-time? Are there any specific data you want to have on your dashboard like the number of users, automation rate, etc?
* **Technologies.**¬†Do you have any specific technologies you want the chatbot to be built with? Is ChatGPT the right one for you? What are limitations of ChatGPT? 
* **NLP and AI.**¬†Do you want the chatbot to have decision tree logic, Machine Learning (ML), Natural Language Processing (NLP), or Artificial intelligence (AI)?
* **Accessibility.**¬†Do you need to meet some specific accessibility requirements like WCAG or ADA?
* **Users.**¬†How many people from your team are going to use the chatbot? How many of your customers or conversations do you expect to use the chatbot?
* **Rich media**. Should the chatbot‚Äôs responses include text, hyperlinks, images, gifs, video, and PDF attachments?
* **Security.**¬†Do you have any specific security measures and requirements you want the vendor or the chatbot to meet?
* **Hosting.**¬†Where the chatbot and the user data will be hosted: on your own servers or on the cloud? If on the cloud, what will be the cloud service provider and server's location?

You can consider chatbot development and decide on chatbot vendors when you have a chatbot requirements outline. Here you can find what criteria to have [when deciding between chatbot vendors](https://botscrew.com/blog/essential-chatbot-requirements/?utm_source=RedditDecember&utm_medium=&utm_campaign=&utm_term=&utm_content=).","[""Is DRIFT or any of the equivalent players integrating ChatGPT in to their products yet? I'd imagine this is orders of magnitude better than what's been deployed today""]"
Accidentally deleted a flow in PowerAutomate,https://www.reddit.com/r/Automate/comments/zkb1cd/accidentally_deleted_a_flow_in_powerautomate/,Automate,Idk if this is the group even but I accidentally deleted an important flow on PowerAutomate How do I go about re-covering it? ü§¶üèΩü§¶üèΩ,['I‚Äôve never done this myself but the link below would seem to be what you‚Äôre looking for!\n\nhttps://learn.microsoft.com/en-us/power-automate/how-tos-restore-deleted-flow']
Business transformation strategy,https://www.reddit.com/r/Automate/comments/zjvwp7/business_transformation_strategy/,Automate,"I'm planning a digital roadmap for my business anyone got any tips/suggestions? I've been using this as my ""guide"" as it seems to cover most of what I'm looking at https://www.codelessplatforms.com/blog/guide-to-digital-transformation/","['Funny when I see these transformations they gloss over the most important aspect.....the condition of the data.  Of course you can do amazing things if your data is organized and in a constant state of ""clean"".  \n\nYou have to have complete understanding of your current data position is, how it gets there, what is clean up, organizing, keeping cleaning (as it will get dirty within hours of getting it cleaned), ongoing oversight, process controls etc.  It could take year(s) to get the data in a position to start working with.']"
dodge charger 2010 with for cylinder and 100k mileage vs Kia forte koup 2012 with 4 cylinders 150k mileage? as first car which is strong or reliable for high school studentü§î?,https://www.reddit.com/r/Automate/comments/zkkeic/dodge_charger_2010_with_for_cylinder_and_100k/,Automate,,"[""I'd say the Kia. Less on insurance and gas I would think. Also won't give the a power complex. They won't be tempted into dumb stuff as much. Also some people I know swear on the dependency of Kia from other brands they've driven so might be something there. Personally I've never owned either.\n\n\nWhat does this have to do with automation? Lol"", ""Neither.  That Kia is in the range where it can be stolen with just a usb cable.  The dodge does appear to have good reviews but I'd still look at a Honda or Toyota first.  I can't find anything about a four cylinder charger.  Also I think posting this in r/cars would be better.""]"
Rules update suggestions,https://www.reddit.com/r/automation/comments/m0vfh2/rules_update_suggestions/,automation,"Hi all,

It was brought to my attention a mod we thought had left the team was continuing to take actions on the sub. I have removed said mod and undone their actions.

On that note, I think it is worthwhile revisiting the rules and ask the community what they want from this sub.","['No ads. Its cool if people have come across a product they want to suggest but the 10:1 rule and ""are you being paid to advertise"" are pretty easy to follow and do a great job of weeding out all the spam.', 'Educational links of thread would be great. Help those who want to learn more. And keeps from asking questions. But also is an ever expanding resource.', 'Software Saturday / Sunday Sticky?', 'Test Comment', 'Test Comment', 'Test Comment', 'Test Comment', 'Test Comment', 'Test Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.\n\nSit amet consectetur adipiscing elit ut aliquam purus. Morbi non arcu risus quis varius. Felis donec et odio pellentesque diam volutpat commodo sed egestas. Mollis aliquam ut porttitor leo a diam sollicitudin tempor. Neque aliquam vestibulum morbi blandit cursus risus at ultrices mi. Eu volutpat odio facilisis mauris sit amet massa vitae. Mauris commodo quis imperdiet massa tincidunt nunc pulvinar sapien. Erat imperdiet sed euismod nisi porta. Tempor orci dapibus ultrices in iaculis nunc sed augue lacus. Neque convallis a cras semper auctor neque vitae tempus quam. Turpis nunc eget lorem dolor sed viverra ipsum.', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'text Comment', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', '[deleted]', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Edited Comment', 'text Comment', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Edited Comment', 'text Comment', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Edited Comment', 'text Comment', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'text Comment', 'text Comment', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'text Comment', 'text Comment', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Edited Comment', 'text Comment', 'Edited Comment', 'text Comment', 'Edited Comment', 'Edited Comment', 'text Comment', 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Urna et pharetra pharetra massa massa ultricies. Tellus cras adipiscing enim eu turpis egestas pretium aenean pharetra. Mattis nunc sed blandit libero volutpat sed cras ornare. Convallis tellus id interdum velit laoreet. Eu feugiat pretium nibh ipsum consequat nisl vel pretium. Sem et tortor consequat id porta. Morbi blandit cursus risus at ultrices mi tempus imperdiet. Magnis dis parturient montes nascetur ridiculus mus. Ultrices vitae auctor eu augue ut lectus arcu. Cursus eget nunc scelerisque viverra mauris in aliquam sem. Quam elementum pulvinar etiam non quam lacus suspendisse. Et magnis dis parturient montes nascetur.', 'Edited Comment', 'Edited Comment', 'text Comment', 'Explanatory notes embedded within the code. Comments are used to remind yourself and to inform others about the function of your program. Multiline comments are used for large text descriptions of code or to comment out chunks of code while debugging applications. Comments are ignored by the compiler.', 'Edited Comment', 'text Comment', 'Explanatory notes embedded within the code. Comments are used to remind yourself and to inform others about the function of your program. Multiline comments are used for large text descriptions of code or to comment out chunks of code while debugging applications. Comments are ignored by the compiler.', 'Edited Comment', 'text Comment', 'Edited Comment', 'Edited Comment', 'text Comment', 'Explanatory notes embedded within the code. Comments are used to remind yourself and to inform others about the function of your program. Multiline comments are used for large text descriptions of code or to comment out chunks of code while debugging applications. Comments are ignored by the compiler.', 'Edited Comment', 'text Comment', 'Explanatory notes embedded within the code. Comments are used to remind yourself and to inform others about the function of your program. Multiline comments are used for large text descriptions of code or to comment out chunks of code while debugging applications. Comments are ignored by the compiler.', 'Edited Comment', 'text Comment', 'Explanatory notes embedded within the code. Comments are used to remind yourself and to inform others about the function of your program. Multiline comments are used for large text descriptions of code or to comment out chunks of code while debugging applications. Comments are ignored by the compiler.', 'Edited Comment', 'text Comment', 'text Comment', 'Edited Comment', 'Edited Comment', 'text Comment', 'text Comment', 'Explanatory notes embedded within the code. Comments are used to remind yourself and to inform others about the function of your program. Multiline comments are used for large text descriptions of code or to comment out chunks of code while debugging applications. Comments are ignored by the compiler.', 'text Comment', 'text Comment', 'text Comment', 'Explanatory notes embedded within the code. Comments are used to remind yourself and to inform others about the function of your program. Multiline comments are used for large text descriptions of code or to comment out chunks of code while debugging applications. Comments are ignored by the compiler.', 'text Comment', 'text Comment', 'Explanatory notes embedded within the code. Comments are used to remind yourself and to inform others about the function of your program. Multiline comments are used for large text descriptions of code or to comment out chunks of code while debugging applications. Comments are ignored by the compiler.', 'text Comment', 'text Comment', 'Explanatory notes embedded within the code. Comments are used to remind yourself and to inform others about the function of your program. Multiline comments are used for large text descriptions of code or to comment out chunks of code while debugging applications. Comments are ignored by the compiler.', 'text Comment', 'text Comment']"
Jira Automation - Release notes,https://www.reddit.com/r/automation/comments/10f3m0e/jira_automation_release_notes/,automation,"Hi, does anybody know how to Automate the creation of JIRA release notes without the plug in?","[""Here's some [Jira automation templates](https://blaze.today/gallery/jira/) I use"", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
what are these tables called used to assemble the panels and move them around?,https://www.reddit.com/r/automation/comments/10dozf6/what_are_these_tables_called_used_to_assemble_the/,automation,[https://www.youtube.com/watch?v=O3al52UWoc0](https://www.youtube.com/watch?v=O3al52UWoc0),"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'smart table\n\nhttps://thehouseofdesign.com/automation-products/automated-truss-system/']"
Help with automatic extraction of data from PDFs,https://www.reddit.com/r/automation/comments/10dhn2g/help_with_automatic_extraction_of_data_from_pdfs/,automation,"I have 4 PDFs with menus for the different messes in my college. I want to extract and add them to a database. I tried using the pdf2txt program in Linux but the extracted text was not arranged in a manner that I could easily separate menus for various meals of a week. As a temporary measure, I took screenshots of the various menus and passed them into OCR software but it is very time-consuming. Hence, I would like to automate the process. Is there any way programmatically or otherwise that I can easily extract the data? The PDFs in question can be found [here](https://drive.google.com/drive/folders/1QL7kaqUy7nTFG5BWYOsfqLk-sAYFA90W?usp=sharing) (Google Drive link)","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""If pdf2txt is giving you the text you need, but not in the format you want it, you want to just consider another tool or script that can get you that last step of the way from PDF --> Unformatted Text --> Formatted Text.\n\nIf you're using Linux, AWK is a very good command-line program for doing on-the-fly text reformatting. You also might find that writing a simple Python script is a good way to get a text-reformatting workflow in place; but if you're new to programming either option might take a little more work than you are ready to put in, depending on how important the task is to you.  \n\n\nIf you want post an example of a single line of misformatted text and then tell me the format you want it in, I'd be willing to show you the solutionary AWK or Python command to get you started."", 'You can check out this link for Data extraction. Works the best! https://app.docsumo.com/signup']"
How long until cleaning staff are replaced?,https://www.reddit.com/r/automation/comments/10dyhho/how_long_until_cleaning_staff_are_replaced/,automation,"I know this might be a long time from now, or not. But have there been ‚Äúmotherships‚Äù that help/host multiple smaller cleaning robots help clean up rooms and offices? Like have multiple room as and mopping guys coming in and out of it. Idk just an idea I had recently.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Not soon enough!!']"
What‚Äôs the best automation tools you‚Äôve come across for automating the sales process?,/r/SalesTechnology/comments/10d6k0l/whats_the_best_automation_tools_youve_come_across/,automation,,
Beginner - easiest to learn automation for clicking check boxes on forms and pop-ups,https://www.reddit.com/r/automation/comments/10demk1/beginner_easiest_to_learn_automation_for_clicking/,automation,"In my organization, we have to confirm all of our reports every week. We pull up a list of reports and then check them off one at a time. Each report leads to a pop-up where we confirm the order with a password. 

What system is easy to learn and deploy and share with my fellow workers?  Thank you!","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
"Would anyone be willing to share details on how the UIPath pricing works? We are currently on Kofax RPA, I'd love to switch but I fear it will be much more expensive",https://www.reddit.com/r/automation/comments/10dd3sy/would_anyone_be_willing_to_share_details_on_how/,automation,"Hey guys!

I'm the head of our department for Process Automation and one of the tools at our disposal is Kofax RPA. The business bought this in themselves (without telling IT) because a salesman sold it as fine for end users. Out of the 20 that trained, only 1 kept going and managed to DDOS the main system and so it got brought to IT's attention and came under their wing. I was then hired to work with it. I now work with this and several other systems to automate processes.

I love the ease of the software and you can spin up robots so easily. It's not cloud based, but we don't need to have any VMs because Kofax has a sort of emulated desktop where I can run excel, websites etc so we have 2 servers to run the bots as services and nothing else required. It's quick, it's easy.... but I HATE Kofax. 

There is no community, we've been asking for changes for 5 years and nothing happens. They don't offer cloud and our infrastructure if off-shored to TCS and it is always breaking down. The support is non existent. There is no training we had to learn by doing. When you ask their support or training teams, they come back going ""I don't know, we were not trained on this"". Upgrading the on prem software is week's of hard work and planning. The thing is great when it works but so flaky and not getting much investment.

I love the look of UI path but I fear it may end up waaaay more expensive. From what I've seen, you pay per month for the software but you also have to pay per month for each robot? We have 100+ processes running under Kofax and we are on their old licence - so we pay for the amoutn of ""resources"" we use at any given time. So we can run 100 robots just staggered across time so they're not all running at once. And some of the robots are big processes that can take up to a day but only go once a month, and other processes that take days but runs a couple of times a year. I can't pay per robot for a thing that rarely runs (but when it does, it enters 100s of thousands of rates into our system).

I'd love to hear from anybody willing to share a ballpark figure or even just confirm how it works for paying for robots and if I would be shelling out 1000s of dollars a year per process I automate. I will never get that past a business case!

Thanks!","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""I can't speak for UIPath or Kofax, but if you are currently a Microsoft shop, there is a chance you could be licensed for Power Automate. A number of [Office 365 licenses](https://learn.microsoft.com/en-us/power-platform/admin/power-automate-licensing/faqs#what-power-automate-capabilities-are-included-in-office-365-licenses) include some sort of Power Automate usage. Power Automate offers both a cloud based digital process automations (DPA) and on-premises RPA automations. You may find that many of your RPAs can actually be DPAs, which in general have a much higher success rate and less maintenance.""]"
Automating a farm: PLC Opta? or RPi and arduinos with Home Assistant?,https://www.reddit.com/r/automation/comments/10bkhns/automating_a_farm_plc_opta_or_rpi_and_arduinos/,automation,"I'm trying to automating my farm and I have around 20 sensors that would control around 10 devices that should stabilise my environment. It seems like I'm biting off more than I can bite but I'm willing to put in the ground work.

Does anyone have experience automating a farm or something like that? Should I wait for the PLC Opta or use RPi and arduinos with Home Assistant?","['What‚Äôs the extent of what you are trying to monitor? Whats the required latency? PLC Opta might be overkill depending on what you are looking to do.', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'PLC and actually I would use more standardized PLC. Ie. Click from automation direct. \n\nI have these in for automation and been running flawless for fifteen years. The biggest difference is how the programming software monitors operations live and can rapidly determine problems.']"
Looking for Python Automation Project Ideas,https://www.reddit.com/r/automation/comments/10bjn1l/looking_for_python_automation_project_ideas/,automation,"Hello  folk, I've recently started looking into automating random side  projects I had lying around and ideas with Python. I'm having a blast,  but sadly my creativity is somewhat limited, hence this post. My  questions are:

\- what kind of project you have done which you are proud of?

\-  any Python libraries which are absolutely hidden gems? For me it has to  be Playwright, never heard of it before a friend mentioned it and I fell in  love with it

Thank you for your time and answers in advance, any input is highly appreciated. :)","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Some of my best projects came from necessity as you have a real world problem to solve. Being able to think you‚Äôre way through putting the solution into code on the fly will make you a better programmer all around. I‚Äôve made password managers, excel interpreters, PLC communication, etc.\n\nI‚Äôve found that if you are looking to find an easy solution to something complicated there is a 99.9999% someone made a python library for it haha.', 'Selenium for web automation opens up a lot of opportunities. If you can write a good tool to automate posting to sites like ArtStation, deviantart etc, then you have a valuable product on your hands.']"
Requesting direction,https://www.reddit.com/r/automation/comments/10azvcn/requesting_direction/,automation,"I have a process where I need to open \~4,800 individual links - each link will download an Excel file. I have developed processes that help me identify the files that I need to download, and my post-download processes are also confirmed. All of this ends up in a large analysis database that I use to help my company understand their hiccups in our billing process. None of these 4,800 or so files are all that large - about 15kb is the average size. Making it more complicated is that the files are behind a username/password combination. I have looked at PowerShell and for the moment, I have this batch download utility in Chrome where I can do about 500 at a time. But needless to say, this is a day-long job if I want to do this since I have to click the button to save 4800 times. I am not well versed in development languages (I know T-SQL far better) although I'm not afraid to Google anything and see if it works. The few web-based ""macro"" systems that I've tried have made it to about the 10th file and then the speed issues take over. So I am asking the community that if you had a static link with a particular file ID and you had 4800 of those links, what is a good method for automating the opening of the website, and downloading the file?","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""I'd use something like this. \n\nhttps://www.httrack.com/\n\nI presume you can make a html file with a link to what you want to download and then feed that into something like this. It has an option to add a user name and password iirc."", 'You could run it with a semi-simple Python script. It would give you the ability to set where you save the file as well if you setup a main file with all the links and such', 'Hey, this sounds like a either a pyhon script or a bot built to execute on your behalf. If you aren‚Äôt technical sounds like writing the code or building the bot might be off the table so you might want to look at the platform like Wrk. Essentially they take best in class automation but break it down to micro steps that a non technical person can build and configure and enables them to access bots, python scripts. Etc. it‚Äôs just in beta at the moment but you can sign up to try it out here [wrk platform](https://hubs.li/Q01x3nTC0)']"
How to automate a Google login flow using Selenium scripts?,https://www.reddit.com/r/automation/comments/10ak1sw/how_to_automate_a_google_login_flow_using/,automation,"We are trying to automate a Google login flow in our Selenium script.  

When the test runs, Google treats this as suspicious/spam-bot activity, and asks for additional verification. So we get either a Captcha screen or a OTP code login screen. 

Has anyone solved this problem before?","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""I think this does what you're asking. Check out [auth.py](https://auth.py) in the below git:\n\nhttps://github.com/alexgolec/tda-api/tree/master/tda""]"
We made an SDR tool. Is it helpful for you guys?,https://persio.io/ai,automation,,
Automation consultant? Python ninja?,https://www.reddit.com/r/automation/comments/109j9xn/automation_consultant_python_ninja/,automation,"Hi there. I run a small events website based in Las Vegas. I use some automation tools like Visualping and Magical to help me track and input events, but I'm hoping to add some more tools to my arsenal. 

I've toyed with learning some basic Python to help me scrape data, and messed with ChatGPT a little, but it's a bit of a learning curve that I don't have time for. I'll cop to some intellectual flabbiness, too, sure.

Ideally, what I'd like is to describe to an expert what I would like to automate and how I'd like to automate it, walk them through my process, and either have them point me to the right tools or even create the tools themselves. This is something I'm happy to pay for.

Does such a thing exist -- an automation consultant or Python or ChatGPT ninja who can build me a bespoke solution for my specific needs? Thanks.","['We do exactly this! DM me and we can discuss what you need.', 'PM me if you want, I make fast deployment tools in the controls field all the time in python. I‚Äôm sure we could come up with what you need!', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Thanks to both of you! Glad to hear this exists! I‚Äôll be reaching out.']"
Is ChatGPT a trap for businesses?,https://www.reddit.com/r/automation/comments/109c368/is_chatgpt_a_trap_for_businesses/,automation,"I've seen a lot of excitement from various businesses about using ChatGPT to let them reduce their staffing costs in fields like customer service. If you look at the numbers right now, it makes a lot of sense because the costs of ChatGPT are current really, really low. But the terms and conditions of ChatGPT make it very clear that those costs can change, and I wonder if businesses might be walking into something of a trap.   


There's a lot of money to be made in automation, I know, I am an industrial automation engineer. But I expect that OpenAI (the developers of ChatGPT) knew exactly how much money their software could save companies when they developed that software, which is why they did it, and they don't intend to let the companies pocket the lion's share of those savings that they did they work to realize.   


So right now, companies can be early adopters and help ChatGPT build market share, train their AI, integrate it with other software packages and demonstrate it's ability to displace workers in the real world. But companies that go down this route and going to make ChatGPT essential to their business operation. So when ChatGPT decides to 10x, 100x, 1000x their costs, those companies are going to have to pay it, and at that point they may have done a lot of work to make ChatGPT a viable alternative to a human employee only to pay OpenAI some non-trivial percentage of the pay of the human worker their displaced.","[""Not necessarily. It could be that they leave ChatGPT at low cost for small commercial consumers, and make it expensive for larger projects such as government and military contracts. AI will always need to consume a lot of new data, because the world and vocabulary changes constantly. Making it cheap ensures a constant stream of data from small companies, which they can use for their big business contracts.\n\nThat's my two cents, maybe I'm wrong though."", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
I got early access to Bardeen + OpenAI! What's one automation you would love to have?,https://storage.googleapis.com/postly-548c1.appspot.com/PHOTOs/cdc48a1f97099bb9e3283e76ef9717058323c94e55c9fac0dd538326d031a5e8.jpg?GoogleAccessId=firebase-adminsdk-pgu3n%40postly-548c1.iam.gserviceaccount.com&Expires=253376553600&Signature=UM8FHEm5IC1012qXi%2BK1%2FEQO09Bw4qQ99pMbdHjese7FsnR%2BiAgVOxlJsOZRQ52VrRBSCDTiBQAvp9s2Ux28oQdZMQOM0cXhIgh%2FF2UulzUXY%2FPRcmmIl5BzLt1LqwbC8kzdtFJJLRXoFVkRQhqGBhvq%2Bz0jGEVejvMAeLDfwfnspZi7R9ZuF6%2F%2FN01Gd%2BhaqErL9%2B8XyliMhTnrVvX61nn11njKtsHwxyS8rowy1nFNhkBdE4YNluVv%2Fvan3UnMvuxwk9BIEQ0T2Y04Ar0MHuGpYxy1cZbrVyVyC4fn5LRznLIAWJppLliLnc6gsioEtS6Y6hhwmZ7Ne9SlEQ4QTA%3D%3D,automation,,
Need help to automate a WhatsApp group chat data to word,https://www.reddit.com/r/automation/comments/109hw07/need_help_to_automate_a_whatsapp_group_chat_data/,automation,"Hello, so at my work the sales team uses a WhatsApp group chat to communicate. The format is something like: order number, client name, picture of design selected and info about design (quantity for example), then the other product, followed by a dash line to indicate the order is over and then repeat same format for new order.   Now we have one guy who‚Äôs only task is to copy paste that data into word and print is as purchase order. I want to automate this process by directly somehow having people input the data into WhatsApp and it getting converted and pasted to word, so then end of the day all I have to do is to print all.   Any help is much appreciated.","['Could you change their process? That‚Äôs going to be a lot easier than trying to extract from WhatsApp. Extracting over email would be pretty straightforward and easy.', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""Could do this with Android adb to get the messages, something like https://gist.github.com/erickdsama/8b312635ca34770f69d08f58d65f69d1, you could also to use Android emulator and WhatsApp and just copy and paste them all  into word directly much faster.\n\n\nEdit: is this whatsapp on phone? I'm pretty sure there's a website version which you might be able to do with curl to get the messages"", ""There's a desktop version of Whatsapp.  You could possibly do it with that.  Seems like the best option though would be to switch platforms to either email or something not as secure as Whatsapp."", '[wrk](https://hubs.li/Q01x3nTC0)can do that- they would extract the information from the chat daily and then upload directly to word']"
Is there a way to setup Google Sheets to send a weekly message on a Messenger chat?,https://www.reddit.com/r/automation/comments/108m17j/is_there_a_way_to_setup_google_sheets_to_send_a/,automation,I have a facebook messenger chat and I need to send a weekly reminder with the title of the weekly seminar talk from a google sheet - is there an easy way/instructions to send messages to Messenger from an AppScript. Where would I plug in/find FB access keys?,"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Hey, not 100% how they connect but I do know that you can do it via [wrk](https://hubs.li/Q01x3nTC0). Basically it can take the data from g sheets use a pre populated message to then send out to fb messanger users (assuming name is available in g sheet to determine who to send to). Platform is currently in beta but I know they have the capability.']"
No-code Google Sheet automation,https://www.reddit.com/r/automation/comments/108s379/nocode_google_sheet_automation/,automation,"Hi all, I just published an article on the no-code Google Sheet automation. [https://www.bardeen.ai/posts/google-sheet-automations](https://www.bardeen.ai/posts/google-sheet-automations)

It shares detail on how to automatically accomplish the following:

1. Copy LinkedIn company data to Google Sheets
2. Copy a list of meetings during a timeframe to a Google Sheet
3. Enrich TikTok links and save them to Google Sheets
4. Copy ClickUp tasks to Google Sheets
5. Get Google Search Results for a keyword and save them to Google Sheets","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'sweet will check it out, been looking for something similar']"
Logical flow of moes brand zigbee push button?,https://www.reddit.com/r/automation/comments/108fdug/logical_flow_of_moes_brand_zigbee_push_button/,automation,"So I got my first zigbee hub and switches.

Could anyone help a dummy out here?

Here's the situ:

*   3 smart bulbs exist in OFFICE.

*  In Tuya Smart, I've setup the following:  
     IF office(123) OFF and PIR Motion Detected  
     THEN execute automation officeON

I created the inverse of the above so the bulbs turn off when detected as on.

I've also tapped to set ""When ALL conditions are met""

I understand why it does not work:  I've created a loop.  When I press the button, it's triggering both routines.  

The issue is I don't know how to set it up as Tuya wants me to do it.  This would be 1000x easier if the execution simply toggled the power state rather than having to make routines to check the power state. 

Another oddity is in another office, it works exactly as it should but that office only has 1 bulb.  The weird thing is I intentionally created a loop by setting PIR motion sensor to both ON and OFF state. 

Could anyone elaborate how ya'll got yours to work cause mines driving me insane?","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Enhance your Automation Superpowers: connect Python to Google Sheets,https://www.callmefred.com/how-to-connect-python-to-google-sheets/,automation,,
Does a Bachelors degree open more doors?,https://www.reddit.com/r/automation/comments/107ppe8/does_a_bachelors_degree_open_more_doors/,automation,"I work in medical manufacturing and decided to go to school for Automation. I‚Äôm currently in an Associates program for Automation and Robotics Engineering. Most postings for Automation jobs only require a two year degree, but I was wondering if anyone who‚Äôs currently an Automation Engineer has any insight into whether turning it into a bachelors degree would be worth it?","['I‚Äôd say it‚Äôs a different path, depends on your goals and what you want out of career. I have a. BSEE and work with a lot of Automation Technicians. For better or worse we both do similar jobs but a lot more of the grunt work gets done by the Technicians where I develop the overall plan and lead and organize the design and build. I don‚Äôt talk pay with them, but I‚Äôd assume a BS pays more then an Associates. I do think both positions will not have an issue finding work as the company‚Äôs I work with and the company I am at have a hard time hiring either.', ""Another option to the EE route is mechanical engineering. My ME program had an option that focused on controls and mechatronics that would give you all the tools you could dream of to build fully automated lines or a robot from scratch. And an ME degree opens a lot of doors. I would go through the program you're in and look into transferring credits to get an ME degree."", ""I Also have an associates degree in Mechatronis and Robotics and work in my field as a Robotic technician. I am on route through my work to become recognized as a automation engineer within my company. I was going to school to obtain my bachelors degree in mechanical engineering but withdrew during covid. I was going for free and only have about 8 classes left but i have no desire or need to finish. What I have found is that the industry can find mechanical engineers no problem, and to be honest Ive only met one who has any practical mechanical aptitude and knows how to use tools or machine parts, they can play on solidworks and thats about it. I currently make 33 dollars an hour but am on track to make 6 figures in the next three years. You should stick with the associates, get in somewhere on the tech level, learn how to build controls panels, troubleshoot automation issues and turn a screwdriver, program plc's, learn ladder logic, read electrical prints and anything else you can. The need for skilled automation workers is in such demand you will be rewarded handsomley. There are very few engineers these days that have all of those skill sets and you will quickly be more valuable than someone with a bachelors degree. Companys more than ever prefer candidates to have industry experience over degrees. \n\nGood luck!"", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'I‚Äôve only worked for large manufacturing companies, but the people I‚Äôve seen who didn‚Äôt get bachelors struggle to get into leadership positions down the road. \n\nIve talked to a few and they always say they thought they didn‚Äôt want a leadership role, but now with the technical background they‚Äôve developed, they realize how useful they could be as a leader and how they could make a difference, but the lack of degree is the hold up.', 'Unlike a lot of degrees. Technical degrees like this actually can give you more insight into a line fo work. If you did not have the degree you certainly have to have some high level projects that you were involved in intimately in order to show your experience.']"
How would I go about automating my MURAL tasks in my user story map from JIRA? (Project Management),https://www.reddit.com/r/automation/comments/107sgqi/how_would_i_go_about_automating_my_mural_tasks_in/,automation,"Hey guys, I find I'm manually spending quite some time manually updating my user story map every sprint. I'm thinking there must be a way to automate this, in the sense that when someone changes the status of their assigned task in JIRA, it would automatically update in MURAL?

I'm new to automation so any advice would be helpful and a fantastic learning experience. :)","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
What type of automation are you most interested in for your business?,https://www.reddit.com/r/automation/comments/107lin1/what_type_of_automation_are_you_most_interested/,automation,,"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', '[deleted]', 'lead generation, negotiation, development, research, security.']"
Filling the Gaps in Workspace ONE Access Audit Logs,https://mobile-jon.com/2023/01/09/filling-the-gaps-in-workspace-one-access-audit-logs/,automation,,
"Just getting into browser automation, need advice",https://www.reddit.com/r/automation/comments/106zj7u/just_getting_into_browser_automation_need_advice/,automation,Currently using axiom to do some lead generation and simple task. I defiantly see the possibilities but am finding there's not a ton of info online about which programs are the best. If I just used Zapier and Axiom would that be enough to accomplish anything I want to do in terms of marketing and sales data automation or is there other programs I should be looking at?,"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""Hopefully this doesn't sound to much like a sales pitch. I am a huge fan of Zoho One. It has Zoho Flow which is a program like Zapier and also comes with Zoho CRM and Zoho Campaigns, which are powerful tools that would accomplish the things you have listed here. It also comes with a huge suite of other programs for your business. Best part is you can integrate them all together and avoid alot of busy work while getting the most out of your data."", 'Text expanders are solid. I use Chrome a lot and Text Blaze is probably my favorite text expander that works well on Chrome', 'Looking into this too for LLC skiptracing any tips?']"
Document Scanning and Naming to OneDrive,https://www.reddit.com/r/automation/comments/10578r0/document_scanning_and_naming_to_onedrive/,automation,"Hey all!

Just started up at a new Restaurant gig in management and they've got a pretty lengthy process on reconciling and uploading invoices to their corporate storage. 

Essentially after reconciling invoices they have to Scan each document via the OneDrive App (Which managers do with their phone), Deal with the whole Pinch the corners in to crop the actual document, Upload it and rename each Invoice to have the Invoice Number and Total Amount. 

What I'm trying to streamline is :   
If we were to get a [Document Scanner](https://www.amazon.com/Epson-Workforce-ES-50-Portable-Sheet-fed/dp/B07KQZWPYN/ref=asc_df_B07KQZWPYN/?tag=hyprod-20&linkCode=df0&hvadid=312342833501&hvpos=&hvnetw=g&hvrand=1884267105011814510&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=1026528&hvtargid=pla-612329262651&psc=1), Connect to the back office PC , Scan the documents to a PDF, and have either:

*  Invoices Parsed for both the Invoice Number and $Total
* Dialog Box Popped up to input Invoice Number and $Total

and have it uploaded to Onedrive in that format. 

Any suggestions? I've been a reddit Lurker for a while but have barely posted. Anything helps!","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Scan and OCR documents: https://paperless-ngx.com. There may be a more purposed software out there, but this is a good start at least. You can host it on any machine. The more powerful the machine, the faster it is and the more accurate you can OCR.\n\nTo upload to OneDrive, you can either use\n* the official OneDrive sync client\n* https://rclone.org triggered by Scheduled Task (Windows) or cronjob (Linux+MacOS), or a more complex script to trigger on new files detected in the folder', 'Hey, OCR is definitely what you need for the first piece and then you‚Äôll need an api/integration to upload the data. If you want a one stop shop to be able to parse the information/upload data directly [wrk](https://hubs.li/Q01x3nTC0) has these capabilities built in. Beauty is you don‚Äôt need any technical skills to build on it and it cost as little as $1000-5000 to get started and then you just pay as you go.']"
Help automating file saving,https://www.reddit.com/r/automation/comments/1056jkd/help_automating_file_saving/,automation,"Hi all - 

I am looking to get help automating saving a bunch of files, individually. I have an excel sheet that I need to print line by line 100+ times to PDF on a regular basis. It is cumbersome to do this all the time. I have a working macro in excel that will highlight and print each line, but I have to manually add the name and save it. Is there a program or something that I should download that will allow me to write a macro for everything, not just excel, ideally integrated with excel? Or is there a way to do it without having to download 3rd party software?

TIA","[""That sounds horrible. I'd do it with python. If you've got a couple weeks you could learn enough to get it done. Otherwise, you could probably get a freelancer to write it on a day or less.\n\nhttps://automatetheboringstuff.com/"", ""VBA\n\nIf you already have managed a macro in excel you shouldn't have too much trouble integrating some VBA code in the macro editor to make this happen.\n\nedit: read your question again and it sounds like it needs a counter, end of page, or some other trigger to do the file name and save portion. Shoot me a dm with some sample data if you get stuck."", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""Either python byt then you need to have some learning curve and have python env on your PC. Or you could try to do it in VBA - one environment, you don't need to install anything. Python could be useful in many things, so maybe it's worth learning."", ""Windows 11: Microsoft Power Automate. It's pre-installed \n\nWindows 10: If without downloading third party software you mean that you don't have admin access and need to do it without being able to download anything, then Microsoft Power Automate is likely out and VBA is your answer.  If you mean that downloading first party software is acceptable, then Microsoft Power Automate"", 'Thank you all for taking the time to offer advice. I actually took someone else‚Äôs suggestion and used chatgpt this morning and automated a few excel tasks already. Appreciate y‚Äôall for the help though']"
Automate Word/Pages form on Mac,https://www.reddit.com/r/automation/comments/104uxmf/automate_wordpages_form_on_mac/,automation,"Hi. I have a fairly straight forward form I have to fill in to kennel my dog on occasion. Is there anyway I can take data from a Numbers spreadsheet to automatically create the filled in form with dates etc included? I only have Mac but I do have Office Excel and Word if that's the only way, ideally looking for a Mac method using Shortcuts or Automator or something similar. Thank you","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'I am thinking of something sinilar for my daughter‚Äôs school health screening. I will pop back if I get a chance to work on it or look for replies on your end. I imagine you might need to frankenstein it with datajar and keyboard maestro.', ""I'd be reaching for python - you should be able to read most spreadsheet formats using pandas, and filling out a form really depends on what format the form exists in. More info would be helpful""]"
Does a handheld/non-phone remote control for Alexa lights exist?,https://www.reddit.com/r/automation/comments/104d9bh/does_a_handheldnonphone_remote_control_for_alexa/,automation,"Pretty much title.

I‚Äôm looking for a simple remote that can be left on a coffee table.  

One that would allow users of aforementioned remote without barking to Alexa, fumbling through an app, nor getting off the couch.  

So no wall switches or apps. 

I feel like there‚Äôs some competitive reason this doesn‚Äôt exist else I‚Äôm sure I‚Äôd see it advertised everywhere.  Hopefully I‚Äôm wrong on that.

Thanks in advance!","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'No. And it would not be trivial to make one, since you would need to create an Analog/digital interface, where once one turns on/off something (analog, as you described it), it triggers something digital (this can be implemented with zapier + Alexa routine or IFTTT + Amexa) but it would need to be customized either once-and-forget, or each time one wants to change something.\n\nIMO the market is very small.\n\nI am an early adopter of Alexa, and I have had my entire place automated for a few years now.\n\n-----------\n\nEdit: a second thought, this is what you might want to explore: building a small analog device that triggers (on/off) an Alexa routine. This way it\'s not just for the light, but for anything one wishes to do.  I like the Apple AirTag format, small, relatively long battery life (add wireless charging). It would become yet another device in the Alexa world, and that you could ""pair"" the device to a routing (you might need to develop a *skill*).\n\nAt that point, one could assign routines to a device on a whim: *Alexa, assign morning routine to Tag A*. *Alexa, assign kitchen lights routine to Tag B*; or - course - via the Alexa app.', 'Depends on the lights you get. Alexa specifically no I dont think so, but I know Lutron has one.', ""https://www.wired.com/story/how-to-create-custom-alexa-routines/\n\nNot quite what you are looking for but there should be a way to do something like this by the looks.... Create a routine and tie it to a 3rd party server that syncs up to the controller you want to use. \n\nJust a case of finding the parts that play well together or get someone to build a small Arduino or similar device that does what you need. \n\nBut I'm no expert so you will have to explore further.""]"
Top 7 Programming Language For Automation For 2023,https://i.redd.it/7e05ggndw6aa1.png,automation,,
Research to template automation help,https://www.reddit.com/r/automation/comments/102pwz2/research_to_template_automation_help/,automation,"Hey everyone,

I'm doing a project that involves email outreach using templates that I fill in with information that's specific to the person I'm targeting. I'm wondering if there's a way to develop an app or if there's something out there that would allow me to feed it the information on a single person (if I could do multiple that would be even better) then it would provide me with the finished template with everything filled in. Currently, I'm doing everything with find and replace on Word however there has to be a faster way out there to do this. I tried my best to explain what I'm doing but I'll provide a photo of what exactly I mean with the custom email outreach below. Any thoughts or suggestions are greatly appreciated!

&#x200B;

https://preview.redd.it/vurdoataix9a1.png?width=1302&format=png&auto=webp&v=enabled&s=cfafb6558bd628bedb19e086a5f908d813289576","['As someone in sales, you can do this, but please, don‚Äôt. Professional inboxes are overflowing with this kind of spam, and it does not work. It‚Äôs noise.', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""Zoho CRM can do this. Pretty easy actually. You can import all of your target audience in as contacts then set it to send out. It will auto fill the relevant information.   Then it's like 60,000 a day you can send before it asks for more money."", ""I think I have a solution to that problem. There is an AI tool that personalizes the generic stuff that you have. It creates personalized videos and you don't have to re-record for every lead that you have. You can record once addressing generally to their problem and it will personalize it in a number of 1000s within a few clicks. Additionally it incorporates CTA, custom URL's & titles all in a single landing page. Makes them think it's for them. You can check it.""]"
Automation technician/engineer degree help. Can y‚Äôall vets check my associate degree classes and give me advice on if it‚Äôs a solid set of classes to get me started in the field thanks I‚Äôm 22 and wanna break into the automation field. Thanks any input is appreciated,https://i.redd.it/1wvlo1p74y9a1.jpg,automation,,
Keep your resume up to date through continuous integration - Github Action,https://github.com/marketplace/actions/awesome-cv-builder,automation,,
Why doesn't Echo Show 15 detect people instantly?,https://www.reddit.com/r/automation/comments/100txnf/why_doesnt_echo_show_15_detect_people_instantly/,automation,"Some of the newer Echo devices can trigger routines by detecting people present. 

I think most of them go on sounds. Breathing and soft humming won't do it, but speech snaps them to attention instantly. 

My Echo Show comes with boasts that it uses its camera to this end, too. Makes sense. (Not if it's true on every variant Show model.)

So why doesn't it register presence instantly when I come in and open the camera shutter? I'd hoped to set this up like a button or lightswitch.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Looking for feedback - Users subscribing but not understanding capabilities of product,https://www.reddit.com/r/automation/comments/zzfs0a/looking_for_feedback_users_subscribing_but_not/,automation,"I built an application where users can click ‚Äúrecord‚Äù then perform whatever actions in a browser like add data to CRM, send email, send message etc and then replace whatever value they typed in the recording with a dynamic value from google sheets. For example let‚Äôs say you want to send a bunch of users a message on Instagram and you have a list of usernames in a google sheet. You click record, go to Instagram, type in the username, type the message then click send. Then you edit this to use the value from google sheets instead of what you had actually typed.

Most of our users signed up to send automated instagram messages and have understood how that works pretty well but when wanting to automate actions on another site / in a different way it doesn't go too well.

Whatever you record can then be triggered by webhook, new row in google sheet, scheduled etc.

This is working great and we have a number of customers using it to send Instagram messages but they‚Äôre not seeing that the same idea can apply to LinkedIn, Facebook, openphone etc. without spending 10-30 minutes on a call they‚Äôre not understanding whatever action they record can be performed from a cloud service later with dynamic data so they don‚Äôt have to.

I‚Äôm a bit overly technical with explanations which is the fault for the majority of this but how would you better train users on the product without getting on 30 minute calls or building resource pages with videos that are just going unwatched

I understand a lot of these things can be done via api, with zapier etc but most users we have cannot do that and for some sites there is no api so there is no real alternative besides hiring a VA/being a developer to write a custom script/giving up your time

Thoughts?","[""Maybe an intro video that comes up when they first login? At least then it's right in their face."", 'Perhaps a video tutorial, on 3 websites it can work on, or what you think would be its most common use cases. With perhaps some templates people can edit\n\nDumb it down enough that the target market can use it. Perhaps have a friend/family memeber read the instructions/script and see if they understand and can carry out the instructions.\n\nMake sure you maintain documentation for your product also. It should come with basic-advance guides.\n\nDm me and i wont mind going over some sort of script for a video with you.', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'What‚Äôs the product called? I‚Äôm interested']"
Development Environments,https://www.reddit.com/r/automation/comments/zz6qdh/development_environments/,automation,"Hey all, we have an automation company customer specializing in manufacturing systems. They work with all the industry standard tools and controllers. 

Their in-house development is using windows 10 VMs on a VMware host to create POC including programming their controllers and PLC code in house. 

We are looking for a solution to streamline the development process. The hardware on prem is old and we are putting together some paths forward. 

What are others using to develop for customer solutions? We are an IT consulting firm performing an assessment and we wanted to see what others in our industry are doing. Any insight is appreciated. 

One constraint is that they have to bring laptops onsite for the POC and sometimes there is no internet. 

Thanks!","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Hi,\r  \nAI in fintech is the use of artificial intelligence for financial data analytics, customer service, supply chain management, trading advice, and much more. \r  \n\r  \nWe at AIACME provide Artificial Intelligence solutions for your business workspace. We help you to Automate your operations reduce manual errors and increase your productivity.\r  \nReach us at enquiry@aiacme.in']"
Email & Punch Card Automation ideas?,https://www.reddit.com/r/automation/comments/zz5ymx/email_punch_card_automation_ideas/,automation,"I do a lot of interviews and emails for work, and recently HR said they want us to punch in, punch out when responding to an email. Is it a hassle? Yeah. Is it good they want us to get paid to work? Yeah. But I get the feeling it could be quasi-automated.

So the gist of it would be a tool that I can open, makes a logging stopwatch, scores it into a google sheet, which then tallies it into a total clocked hours and can be logged as a single item at the end of the month. It's super rare I'd work overtime in any given week, so not really worried about being stiffed a weekly bump.

This might exist in some form, but if not perhaps the parts of it already do.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'You could use Zoho Desk for this. It allows you to set up an email address that makes ""tickets"" when an email is received. There is a time clock on each ticket and you can pull reports of time spent during a date period. It also can relate emails back to the ticket. That would also allow you track individual situations easier I would imagine vs having it just in your email somewhere.', 'Part of me says ""why reinvent the wheel"" here as there are numerous options that your company could pay for as a turnkey solution.\n\nOn the other hand, this would be easy enough to do in Excel as I\'ve made a calendar for vacation/PTO that would email out to a manager whenever someone made a change.\n\nFind a calendar template, set up a macro, and have a submit button that would sum the hours for the time period and send an email.']"
How Does ChatGPT Help When Writing Automation Code With the Playwright Tool?,https://www.reddit.com/r/automation/comments/zz0plw/how_does_chatgpt_help_when_writing_automation/,automation,"In its first week of use, [ChatGPT](https://openai.com/blog/chatgpt/) smashed numerous Internet records. As someone who works in QA automation, my first idea was how I could use this wonderful platform to make it simpler for testers to work on Web automation.

As ChatGPT may be used to write code in a variety of programming languages and technologies. After more investigation, I made the decision to create some scenarios using it. *I used ChatGPT to develop the Cucumber feature file and various use cases based on UI situations.*

**Please follow the** [**link**](https://qaautomationlabs.com/chatgpt-for-automated-testing-for-playwright/) **for more detail**

*We can use ChatGPT to generate the Code but we can‚Äôt say that the generated code is perfectly fine. The generated code needs to be modified in some situations.*","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
ChatGPT is absolutely insane,https://www.reddit.com/r/automation/comments/zygstz/chatgpt_is_absolutely_insane/,automation,"I've never worked with a learning model that's so flexible and robust in terms of generative output, with the exception stable diffusion and/or midjourney.

Where do you folks see this tech going? Do you think we'll see additional open access, large-scale lawsuits against generative AI, or something else entirely?","['There will be lawsuits and chatGPT with be it‚Äôs own lawyer‚Ä¶‚Ä¶', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
How do you use browser automation at work or in personal life?,https://www.reddit.com/r/automation/comments/zygxp0/how_do_you_use_browser_automation_at_work_or_in/,automation,"Hello all! I'm curious to know if anyone uses browser automation tools in their work or personal life. If so, could you share how you use these tools?  
I'm aware that they are commonly used for testing, data gathering, and marketing, but are there any other applications for these tools?","[""I'm not sure if this fits the bill, but I really like using Tampermonkey because it allows you to write custom JavaScript which can interact with pages on your behalf.\n\nAs an example, I have a project that I was working on which needed to have pages advanced at regular intervals for render testing, both front and back-end, so I wrote a simple script that simulates a click on the advance button after waiting for the page to load.\n\nTaken further, you could theoretically automate quite a few things with an approach like this if you were looking for something more customized, and could even use a framework like Selenium to access additional functionality.\n\n[https://www.tampermonkey.net/](https://www.tampermonkey.net/)\n\n[https://www.selenium.dev/documentation/webdriver/](https://www.selenium.dev/documentation/webdriver/)\n\nEdit: I should mention that you can keep it as simple as you like, or you can go as virtually as complex as your needs necessitate. It's basically injecting custom code into any page that matches the URL path you specify within your browser.\n\n    (function() {\n        'use strict';\n    \n        // Your code here...\n        setTimeout(function(){\n            document.querySelector('.next-button').click();\n        }, 2500);\n    //localhost:8011/home/session*\n    })();"", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""I try to avoid some of the more complicated automation tools because I don't know how to use them. I just use a simple one called Text Blaze to help automate a lot of my work. It helps me send basic emails, messages, and quickly schedule calendar meetings. Overall makes typing pretty fast"", ""I have written bots in python/selenium to assist in buying hard to get items and in social media marketing.  It saves me tons of time and they're fairly easy to do.""]"
Generative AI and automations for Writers in Tech (Free online event),https://www.eventbrite.com/e/generative-ai-for-writers-in-tech-free-online-event-tickets-500154725247,automation,,
Low-Code Developer,https://www.reddit.com/r/automation/comments/zybroz/lowcode_developer/,automation,"You love tech, building systems, and automating, to make it play together tighter than The London Philharmonic Orchestra.  
But there are two major problems.   
1. You are saying the same thing over and over again to customer. You just want to build cool stuff not be a customer relations manager.  
2. The lack of security. One week you have five projects the next week you have one. The feast is great but the famine feels like you have been placed in an Oliver Twist novel.

If you are looking for a new technical challenge and to be part of a fast-growing Marketing Agency (growing at a rate of over 300% per year) this could be the perfect fit for you.  


What we provide:  


1. Guaranteed 40 hours every week
2. Fully remote working (work from anywhere)
3. Competitive salary
4. 28 days of paid time off per year 
5. Regular working hours 
6. Supportive personal growth environment
7. We handle customer communication so you can do what you do best
8. Smart QA processes to make sure you have all the information you need and reduce unnecessary noise.
9. One clear point of communication so you don‚Äôt have to worry about dealing with multiple stakeholders
10. A team that lives by the values of effectiveness, data and accountability
11. Clear and documented SOPs that are constantly evolving to support the team in being as effective as possible.
12. Support and training on new tools and software to give you.
13. Weekly review to discuss anything you need help and support with to be the best version of yourself in your role.
14. Career development opportunities as the company grows. We believe in growing talent from within.
15. A clear vision that you can be part of that supports both financial goals and philanthropic goals to impact more lives in the world
16. $250 a year personal development scholarship that can be used for any kind of training you wish. Whether that be personal growth, learning a new skill, going to a mastermind or an industry event. It‚Äôs totally your choice. We support you.
17. A clear project management software system so you always know what you should be working on and what is a priority each. No more guessing games.
18. A fast-paced environment that is exciting to be part of.
19. To push the boundaries of what is possible with new technologies  
**What you will be doing**

As part of Amplify, you will be helping us complete strategic goals. To add clarity, you will either lead an activity, help manage an activity, and/or be accountable for the outcome of the activity.

**Direct Supervisor:** CEO

**Functional Supervisor:** Project Manager

## LMA Tasks

**Key:**  
L - Lead

M - Manage

A - Accountable  
**Tasks:**

1. LMA - Determining project requirements and developing work schedules for the team
2. MA - Delegating tasks and achieving daily, weekly, and monthly goals
3. M - Liaising with team members, management, and clients to ensure projects are completed to standard
4. A - Identifying risks and forming contingency plans
5. MA - Analyzing existing operations and scheduling training sessions and meetings to discuss improvements
6. MA - Keeping up-to-date with industry trends and developments
7. A - Updating work schedules and performing troubleshooting
8. M - Being transparent with the team about challenges, failures, and successes
9. LM - Writing progress reports and delivering presentations to the relevant stakeholders
10. LM - Create Go High Level automations and templates
11. LM - Create Active Campaign automations and templates

## Salary

1. $8000 per month based on 40 hours per week   
comment on this post to get the assessment link","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Hi there! I‚Äôd love to take the assessment and see if it‚Äôs a good fit :).', 'Send me the assessment.', 'Hi there!!  \nSend me the assessment!!']"
Has anyone ever worked with software from Survalent for SCADA systems?,https://www.reddit.com/r/automation/comments/zxcwg7/has_anyone_ever_worked_with_software_from/,automation,"I am currently working on a SCADA for a shrimp farm, the software we are using is from Survalent. The map editor is SmartVU, and the program to link the variables is STC Explore. 

There is no information anywhere on the internet on how to use this software and I‚Äôm having a hard tome figuring it out.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Help Automating a Word Document,https://www.reddit.com/r/automation/comments/zwvdul/help_automating_a_word_document/,automation,"Hello! So at my current workplace, every time we get a new patient, we manually fill out multiple word documents. I have managed to combine all these word documents into one word document, however, there are too many fields for us to manually fill out and most of the fields are the same thing repeated. This document includes things like the patient's name, DOB, and etc. Is there anyway where I can make it so that whenever we get a new patient, I can just type the patient's name and DOB and it automatically populates the fields in the document? I know I can do this with Microsoft forms but the document is setup weird and has a table in the footer and whenever I submit the form, it wipes out everything in the footer and only leaves the filled in text. Does anyone have any ideas on how I could possibly automate this? Thanks!","['You can use VBA to Automatically fill up word reports from excel data. \n\nsee this video for example\n\n[https://youtu.be/f\\_ya8IIicAo](https://youtu.be/f_ya8IIicAo)', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'In this day and age why is a healthcare company (even the smallest of them) filling out Word forms? Is this for some edge cases or did your workplace never modernize? Most health companies are using a vendor product now (SaaS or maybe still a desktop client).\n\nIf you are going to use Word still for a while, I suggest doing a ""mail merge"". You can fill in the details in Excel then the mail merge will output a Word doc with the completed fields. For one patient or hundreds.']"
Auto play a YouTube video/livestream on a Google TV,https://www.reddit.com/r/automation/comments/zx1951/auto_play_a_youtube_videolivestream_on_a_google_tv/,automation,"I have one of the new Chromecasts with Google TV and was wondering if I could make it always stream a specific YouTube stream as a cable TV replacement for my grandma (she always only watches one specific channel). Does anyone have suggestions on how to either force an Android TV (Google TV is based on android) to play 24/7 while still allowing the TV to turn off, or make it auto-load the video when the TV turns on? Any help would be much appreciated.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Need help with automating the filling up of a word document,https://www.reddit.com/r/automation/comments/zveu7j/need_help_with_automating_the_filling_up_of_a/,automation,"I work for a company that does something called alarm activations. They have a document template that needs to be filled up every time there has been an alarm activated. We then receive a whatsapp message from the guard and take the content and populate a word document template we have and email it to the higher ups. I want to know how I can automate this whole process so that as soon as the message is received, the relevant content on the template is filled and sent to email directly. 

&#x200B;

How can i do this?","[""Does the alarm have an API available that you can either subscribe to a webhook or poll every 1/5/15/30/60/etc minutes to look for new alarms since the last poll? If so, you could extract the alarm details from the API and use PowerShell and some extensions to generate a document from the MSWord template... That's just one way I can think of off the top of my head, but without knowing the details about how the alarm works (or at least, how it communicates events), its difficult to say for sure what the best approach might be."", 'Word VBA will probably be the simplest to fill the form out and email it. \n\nId probably look for some kind of automation that can get you WhatsApp > raw data > network drive or email then VBA can pull the information from there.', ""To provide an alternative to those below: you could write a program that integrates with the Whatsapp API and/or look at twilio for processing whatsapp incoming messages.\n\nOnce you get your data. If you have multiple messages, filter messages by a date (such as today's date), process each message that meets all criteria (you can add validations such as if the guard correctly filled out everything), then write the data into a word file (such as by using a library), and then email the file."", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
"tools for streamlining project paperwork flow on municipal contract jobs. (Submittals, factory testing forms, startup forms, O&M manuals)",https://www.reddit.com/r/automation/comments/zud543/tools_for_streamlining_project_paperwork_flow_on/,automation,"I imagine this is one of those scenarios where it's best built from the ground up by the person asking the initial question. The context is a municipal contract job where you do months of paperwork first before going onsite to do equipment installation testing and commissioning. Is there anything already existing that is almost like a database for a project, where I have an instrument and control cabinet lists where I enter, say, an instrument tag number once. Then, everything in the project mentions that tag number is extrapolated from that initial database entry, so I don't need to repeat entering information. And is there anything built on top of any existing standards like ISA. 

I have my specification packet in PDF form, site drawings (floor plans, electrical and control schematics). I have to itemize everything relevant to my scope in a datatable or database that is derived from the specification packet. I then have to build my documents using adobe pro, word, and excel. Sometimes, im provided template forms that i have to use for every instrument (sometimes 40 identical instruments). I have to fill ouy 3 or for forms for each instrument i procur and field test, then i have to put those field test forms in a O&M manual along with the instrument manuals, cutsheets, warranty policy, manufacturer information, vendor information (location, contact info, latest price)","['I think you might be looking at a document cloud here, not sure if that satisfies all of your needs, but there us Paperless-ng.', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""I'm not sure that this would solve your problem entirely or provide a complete solution, but you may consider looking into the MS Power App platform.\n\nYou may be able to build something custom that transposes data as-needed while keeping everything stored in a relational database, and depending upon how specific you want your functionality to get you may be able to bring on a developer as a freelancer to help you push your system over the finish line.\n\nhttps://powerapps.microsoft.com/en-us/""]"
Created this Updated list of the Best Automation Testing Tools,https://coursesity.com/blog/best-automation-testing-tools/,automation,,
How to automate creating technical evaluation sheets from pdf quotations,https://www.reddit.com/r/automation/comments/ztb6u6/how_to_automate_creating_technical_evaluation/,automation,"Hi, I was wondering how to accomplish automating to create a technical evaluation sheet by extracting data from quotations in pdf files that are of different formats from different suppliers. Would it be possible ? If not should I require suppliers to fill a uniform pdf format?","['You need to provide a lot more detail friend', 'Rather than getting pdf from suppliers give them a well structured google/airtable form which includes all possible fields for information \nAnd tell them to fill this instead', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Runedu.co,https://www.reddit.com/r/automation/comments/zth57w/runeduco/,automation,"Would you like to run your online language course fully digitally?

Digitize your education company:

 1. Minimize expenses  
2. Additional Income with AI  
3. Make decisions with KPI's  
4. Digital presence to boost sales","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'What a low-effort advertisement.']"
Automation Testing Market Witness the Growth of $52.7 billion by 2027,https://www.reddit.com/r/automation/comments/zt9ooj/automation_testing_market_witness_the_growth_of/,automation,"Report determine and forecast the automation testing market based on component, testing type, dynamic testing, non-functional testing, endpoint testing, organization size, vertical, service and region from 2016 to 2027, and analyze various macro and microeconomic factors that affect the market growth.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
[BLOG] Use PowerApps for an automation Front-End,https://www.reddit.com/r/automation/comments/zspzt0/blog_use_powerapps_for_an_automation_frontend/,automation,"To celebrate the [festive tech calendar](https://festivetechcalendar.com/) I've written a blog about how to use PowerApps to create a simple front end to execute Automation scripts hosted in Azure. I thought some people might be interested in it so here you can find it:

[https://autosysops.com/blog/use-powerapps-to-create-a-simple-front-end-for-automation](https://autosysops.com/blog/use-powerapps-to-create-a-simple-front-end-for-automation)","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
trying to connect to the database using python unittest,https://www.reddit.com/r/automation/comments/zrh35d/trying_to_connect_to_the_database_using_python/,automation,"Need to create a testing framework using python unittest and try to connect to the database. I am using the below code for connection which returns the connection. 

&#x200B;

`def connection(self):`

`connection = mysql.connector.connect(host='`[`127.0.0.1`](https://127.0.0.1)`',` 

`database='testingDatabase',`

`user='Admin',` 

`password='admin123',`

`auth_plugin='mysql_native_password')`

`return connection`","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Text expansion app for Android - allows SQL lite files,https://www.reddit.com/r/automation/comments/zrdx60/text_expansion_app_for_android_allows_sql_lite/,automation,"Hi everyone!

I wasn't quite sure what subreddit to ask about this in so please let me know if I'm not in the right place. :)

I'm currently using a piece of freeware for text expansion and simpler macros on my PC that I'm really happy with. However, I'm unable to find an app for my Android phone that's compatible with it. The software doesn't have an official mobile app so I'm looking for any app for text automation that I can use to expand text (duh) while typing on my phone.

However, I'd like to be able to export the SQL lite database from my PC and import it into the Android app so that I have all the snippets ready to go. (I'm not expecting the macros to work or any of the shortcuts that include keyboard-specific keys like Ctrl or Alt).

I realize this won't be an automatic synch, much less a two-way synch, but it's good enough for now. :)

Looking forward to your advice Reddit community! :D I'm sure you'll provide words of wisdom as always!","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
automated DJ software,https://www.reddit.com/r/automation/comments/zq7b83/automated_dj_software/,automation,"I made software using JavaScript that has about 300 songs and the software mixes the tempo matched instrumentals in key, each refresh creates a new endless mix and its powered by the super accurate Web Audio API hardware clock, even works on iOS.

The dopest part is that it is super flawless accurate as far as key matching and tempo matching goes and its all written in vanilla JavaScript. It even does some things DJs cant currently do, like considering the accurate tempo/pitch shifted key (like when a DJ speeds up a song) instead of the one the song is recorded at. As much fun as DJing has been to me for over 20 years, this is even more fun because it comes up with combinations I love and have never used before but they sound great together.

EDIT: [https://cappinkirk.com](https://cappinkirk.com) to listen live and [https://github.com/dmvjs/kwyjibo](https://github.com/dmvjs/kwyjibo) for the source code (doesnt include audio files yet for obvious reasons). This project is originally a hardware idea for selling to clubs but it amazingly it also works well on the web. I make mixtapes with it and export to sounddcloud also

EDIT #2: Happy Cake Day r/DJs!

EDIT #3: i posted a youtube video unedited with details [https://www.youtube.com/watch?v=61mAf\_8swEE](https://www.youtube.com/watch?v=61mAf_8swEE)

EDIT #4:

&#x200B;

[Songs are grouped by tempo and key](https://preview.redd.it/sqyvfp7tjt2a1.png?width=1367&format=png&auto=webp&v=enabled&s=ead23a47dedea9b41b464ce0ab67b4de7564f70f)

&#x200B;

[Adjacent keys are eligible for selection](https://preview.redd.it/uy79eudxjt2a1.png?width=1367&format=png&auto=webp&v=enabled&s=1011dc28b07ec99a7c1c7b089c41de1e4db3d34d)

&#x200B;

[lead files are 16 beats, body files are 64 beats](https://preview.redd.it/wl1qhv31kt2a1.png?width=1366&format=png&auto=webp&v=enabled&s=64afedab344cfe212d4a7384b804a4a86201fbb4)

EDIT 5: kwyjibo got featured in [https://bytes.dev](https://bytes.dev) JavaScript email thanks! [https://bytes.dev/archives/145](https://bytes.dev/archives/145)","['Very cool! What an awesome idea\n\nCan we supply it with any tracks? Or do we also need to provide key/tempo info as well? \n\nHow does it handle when a song changes key? Can it correctly mix into another song after a key change?', 'Damn it looks crazy ....', 'Kudos human, this is incredibly impressive.', 'Damn, my next party is sorted', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Find Retailer Map on Website,https://www.reddit.com/r/automation/comments/zq06ou/find_retailer_map_on_website/,automation,"Is there a way to automate adding in new retailers onto a retailer map on a website? We get form submissions from new retailer accounts, (we have many retailers), and manually entering them into the website takes 2-5 mins each, and we have 267 to input. Could Zapier or something similar help with this? Thank you","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Automate tape application in furniture manufacturing,https://www.linkedin.com/posts/enimac_enimac-tapeapplicationmadeeasy-tape-activity-7010506843839971328-rzeC?utm_source=share&utm_medium=member_android,automation,,
What power connector is used on that Mitsubishi HC-KFS servomotor?,https://www.reddit.com/gallery/zppczq,automation,,"[""It's impossible to say without seeing the wire unplugged and the pin configuration.  It could be something made specifically by/for Mitsubishi."", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Does anyone know what is this 4 pin power connector on Mitsubishi HC-KFS servomotor? Exact model is HC-KFS43 but the same connector is used on many other Mitsubishi servomotors of that era.\n\nOne side of connector is marked MXJ 2. Opposite side is marked 54271. \n\nMitsubishi manual is listing connector and matching receptlaces for all cables attached, but not the one connected directly to motor body (or at least I could not find it). Googling ""MXJ 2 54271"" does not retun anything useful either. Is that some proprietary Mitsubishi plug that you cannot buy, or am I missing something?']"
Is this AB manual wrong?,https://www.reddit.com/r/automation/comments/zo9toh/is_this_ab_manual_wrong/,automation,"My understanding is that a sourcing input is pnp, so it would be expecting an active low signal. Is this manual backwards? https://i.imgur.com/vSwUBlQ.png","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Trying to figure out automatic switching for 220v machines.,https://www.reddit.com/r/automation/comments/zo8x9o/trying_to_figure_out_automatic_switching_for_220v/,automation,So I've bought myself a new wood lathe which is 220v. My air compressor is also 220v. The problem is that I have only one outlet. I've been trying to figure out how I can automatically prevent the compressor from starting while the lathe is running. Any ideas on how I could accomplish this?,"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""So you have a compressor which is left on all the time, starts itself when it needs to build pressure... and you want to ensure that it never starts when the lathe is running?\n\nWith modifying your lathe: You can wire a contactor to the start relay in the lathe and then run the compressor power through the N/C circuit on the contactor. When the lathe isn't running, the contactor will pass power as normal and the compressor can run whenever. When the lathe is running, the contactor will close which will open the power circuit for the compressor thus preventing it running. When you stop the lathe, the contactor will open again closing the compressor power.\n\nWithout modifying your lathe: I would simply build a small enclosure with a switch for lathe power. Use a DPDT (On-Off-On) switch with 220v rating, and wire the plug (to your outlet) into the common on the switch, with the lathe wired to one side of the switch and the compressor to the other. Then just switch between the two as required."", 'Could you not add a larger breaker and then wire in another receptacle in parallel? I mean depends on your total usage and main breaker size. Also depends on the amperage of each of the machines, but why limit run time when both could potentially run?']"
skills for Electromech eng technology,/r/PLC/comments/zlvl64/skills_for_electromech_eng_technology/,automation,,
Are color sensors applicable for checking fruit‚Äôs freshness as a non-contact sensor?,https://www.reddit.com/r/automation/comments/zll1nr/are_color_sensors_applicable_for_checking_fruits/,automation,"So it‚Äôs my very first days with the job, I knew there‚Äôs a problem where fruits are wasted if most of them are moldy. 1/4 of the whole shipment could be wasted if the boxes have moldy ones as they wouldn‚Äôt like it to pass by the conveyer belt and processed with the fresh ones. 
I really would appreciate if I got resources, project‚Äôs vids or documents to check the whole thing, thank you.","[""I don't think that you could do it reliably with just color, if you want vision system you would need to find company that will create software that will spot mould on fruits. Maybe fruits could be rinsed, box by box and then check water after rinsing for mould presence."", 'You need a grading machine with a vision system for detecting external defects. \n\nCheck out equipment from Greefa, MAF, Compaq, or Aweta for more info', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Walmart rolled out self-checkout to streamline operations and reduce labor ‚Äì but employees and customers say it's causing a surge in thefts,https://www.businessinsider.com/walmart-employees-and-customers-blame-self-checkout-shoplifting-rising-theft-2022-12,automation,,
Electrical/Control & Instrumentation Engineer to Automation Engineer,https://www.reddit.com/r/automation/comments/zl4w3x/electricalcontrol_instrumentation_engineer_to/,automation,"I'm an electrical engineer with a couple of years experience behind me. Previously I was an electrician before pursuing my degrees to become an engineer. Based in Ireland. 

I've always loved automation, I excelled at it in college, plc programming, logic, robotics, but I ended up going down the path of an electrical design engineer mostly since leaving college in 2018, most recently I'm also a control & Instrumentation Engineer. I've been working in proximity to automation engineers throughout some projects and really like the idea of doing the role everyday.

What I'm struggling with is how or can I break into an automation engineer role? I've looked at 100s of roles for automation and I don't see any point in applying as I don't meet the criteria but I know I'd love doing all of the responsibilities! What can I do? I can't think of anything other than completing some PLC dojo courses etc but that still doesn't give me the experience required.

Edit: going back to college full time is out of the question, I've already done this to acquire two degrees. I would be willing to do a night time course but there are none I can see, there are some in mechatronics but I'm not sure I'm willing to offload ‚Ç¨10k to get a 2nd level 8.","['Believe I have answered this before here but, the last 3 people I have hired for the automation engineer position have a background similar to what you described. Hiring people who know the hardware side already have proven to be very good at troubleshooting even before they are solid at the programming aspect.', ""My company mostly hires Electrical Engineers for our controls and automation work. We have hired into the team someone that started out as an instrumentation & electrical technicians that have demonstrated an ability and willingness to learn the programming side. However, engineers typically have a quicker path to this. I've seen techs that become programmers and are better than the engineers, but I've seen it the other way around to. It all depends on if you really want to learn it. We would train PLC programming and HMI development. That's not something that people can typically get training for in school themselves in most cases. Our engineers, however, might work well beyond just basic programming and HMI development, and more into complete systems integration, including with network and IT systems. Again, it's all in your willingness to self-actualize, learn, and apply it to be successful."", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
How do i get an automation to go down to the next customer in my invoice register,https://www.reddit.com/r/automation/comments/zkcmfh/how_do_i_get_an_automation_to_go_down_to_the_next/,automation,Hi.  I was tasked to automate some processes at work and was looking for some help.  I have been asked to automate our billing invoices to automatically be assigned in our billing invoice master file.  I have been able to get the automation to work for one entire customer but cant get it to jump to the next invoice.   I was told i need to use some kind of loop but don't really know what kind to use.  Thanks,"['Depending on the language are you looking for a for loop?', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'in Python it would be something like this\n\n```Python\n# Import the necessary library\nimport pandas as pd\n\n# Load the data into a pandas DataFrame\ndf = pd.read_csv(""customers.csv"")\n\n# Iterate through the customers column\nfor customer in df[""customers""]:\n  # Run the billing process for the current customer\n  bill = calculate_bill(customer)\n  send_bill(customer, bill)\n```']"
Starting School,https://www.reddit.com/r/automation/comments/zkarwx/starting_school/,automation,"My company is putting me through a technical program at the local community college. For the entire duration of the program I will be using SQL and statistics in online college classes. February through March I'll be going through in-person classes on FANUC robotics and PLCs, as well as some GD&T/Schematic reading stuff at the applied technologies center.
  Not sure if anyone here is in manufacturing automation but I'm a little intimidated since my only technical work so far has been using SQL and Excel for some basic data work. 
  Any tips on the learning process? Or does this program even sound like it's covering enough information?","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Doesn‚Äôt sound like it‚Äôs enough at all. You need electrical, mechanical, pneumatic, fluid power, PLC, And more PLC.']"
Requesting advice to begin automation learning,https://www.reddit.com/r/automation/comments/zjqwhw/requesting_advice_to_begin_automation_learning/,automation,"Looking for a learning path and resources where I can learn automation.
A suggestion on route map of this learning path by self

Thanks and appreciation in advance for your guidance.","['there are Google Coursera Python for IT automation courses, you can even get financial aid to get them free as well', 'What sort of automation? Software or mechanical?', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Custom Inventory Management system with automated low inventory alert,https://www.reddit.com/r/automation/comments/zgxi2k/custom_inventory_management_system_with_automated/,automation,"I love building systems with no-code tools. Today, I built a custom Inventory Management system with just no-code tools. The system includes a low inventory alert. Here's a video demonstrating the same, [https://youtu.be/XoAo666kiHw](https://youtu.be/XoAo666kiHw). The tools used were Utilize.app, Make, Google Sheets, and Gmail.

‚öíÔ∏è Utilize is used to build an app to add and withdraw stock. Once the stock is withdrawn, Utilize triggers Make with the SKU information.

‚öíÔ∏è Make is used to trigger Google Sheets and Gmail.

‚öíÔ∏è Gmail sends an alert to the admin.

&#x200B;

I think many small businesses could benefit from a simple inventory management app. Looking forward to hearing thoughts from the community.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Basically what autocrib,cribmaster offers but without the ""vending machine"" You would also need to add ERP  compatibility  and transacrion history logs. Also user profiles for admins and regular users']"
Forward emails and more with a click of the mouse.,https://www.reddit.com/r/automation/comments/zh6p21/forward_emails_and_more_with_a_click_of_the_mouse/,automation,"At work a few people have to do this repetitive function:

* Some emails, but not all
* Need to be forward to a certain email address, always the same email address
* And also BCC to another  email address, always the same email address. BCC is important
* Add a certain message in the body of the email, first line is fine, always the same message
* we use Google Workspace


I am new to automation, but this sounds like a great first project.

What would be best to use? Google Apps Script, Zapier or some other tool?

Thanks in Advance.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', '>Some emails, but not all\r  \n\r\n\nThere can be a number of platforms/ways to do this, but the key to getting the right answer is here.\n\nWhat are the conditions that let you identify which emails you need to forward? \n\nI.e. Do these emails from a particular sender? Do they contain certain keywords? Any other marker to help the desired automation identify those emails?']"
Mitsubishi FX5U connection with Monitouch TS1070s,https://www.reddit.com/r/automation/comments/zd1olw/mitsubishi_fx5u_connection_with_monitouch_ts1070s/,automation,"Hi everyone, I am having a hard time trying to get a connection between this two devices. I am already lost on what went wrong. Please help me\~\~\~I've attached both my devices setting pics. My HMI keeps prompting PLC1 Communication Error Time-Out.

[V8](https://preview.redd.it/jxddi3sym14a1.jpg?width=544&format=pjpg&auto=webp&v=enabled&s=c815d6e53fcb957507876920e636331c0bcb4c12)

[GXworks3](https://preview.redd.it/xsrpvvtxm14a1.jpg?width=1517&format=pjpg&auto=webp&v=enabled&s=639122250ebfb1be722a5380ee09dbd19b96f940)","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
EIT automation online school opinions.,https://www.reddit.com/r/automation/comments/zcg63l/eit_automation_online_school_opinions/,automation,"Hello!

I'd like to further my education. I'm a mechatronic engineer, but worked mostly as a maintenance technician, in the mechanical side. I'd want to pursue a career in automation, but the only chances I have are online schools. I live and work in a little city in Bolivia, in latin america. 

Here is a link to some of EIT's programs.

[https://www.eit.edu.au/?post\_type=courses&s=&course-types%5B%5D=professional-certificate](https://www.eit.edu.au/?post_type=courses&s=&course-types%5B%5D=professional-certificate)

If anyone know about this EIT, and their programs, would you please give me your opinon. If anyone knows about another online program which grants some type of certificate in conjunctions with the learning, please I'd like to know. I know there is a huge gap between using a simulator than a real PLC, but I have a PLC and some stuff that would let me install a tiny system. Automation is huge, but Im more intereted in system dynamics and control (PID controllers, PLC/DCS, plant design and mostly industrial automation).

Thanks and cheers.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
How to automate a specific song to wake me up the 1st of every month?,https://www.reddit.com/r/automation/comments/zaj50h/how_to_automate_a_specific_song_to_wake_me_up_the/,automation,"Siri or Alexa, what automation would allow me to wake up to a specific song at 8:00am on the first of every month?","[""I'TS THE FIRST OF THA MONTH!"", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Apple shortcuts. Select new automation and you can set this up for the 1st of every month at 08:00 and select the song']"
How to Automate WhatsApp Message for free using Power Automate,https://www.reddit.com/r/automation/comments/zad6pd/how_to_automate_whatsapp_message_for_free_using/,automation,[https://medium.com/@vanshkharidia7/how-to-automate-bulk-whatsapp-messaging-without-coding-30fe97f9832c](https://medium.com/@vanshkharidia7/how-to-automate-bulk-whatsapp-messaging-without-coding-30fe97f9832c),"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Nice! Never knew you could do this!']"
ABIR X8 + TUYA app,https://www.reddit.com/r/automation/comments/zal6vp/abir_x8_tuya_app/,automation,I need help with adding the ABIR X8 robot vacuum to the tuya smart app. Has anyone been able to do so?,"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
"""Driveway durable"" LED strips",https://www.reddit.com/r/automation/comments/zaclg8/driveway_durable_led_strips/,automation,"My problem is that my 2019 Chevy volt's backup camera has weak nightvision and I routinely get home after midnight. I can't see to back into the driveway, so I installed the $3 solar lights which are already underperforming. I would love to have simple strips that could be mounted on the driveway but they need to be able to endure being run over. As of right now I speculate I'll go with low voltage posts but the ability to maneuver the cars over the edge of the driveway would be a big plus, our parking is complicated. Thanks!","[""Use your mirrors and don't rely on the tech?\n\nHow did you reverse before cameras?"", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""Sounds like just a simple sensor light would do the trick? You'd be best to mount it high up with the sensor pointed mostly down, so when it's dark and you get close, your target is well-lit and now you can just park normally?\n\nThey are really common around here, typically one thumb dial to adjust how dark it needs to be before motion will start triggering it, and one dial to adjust how long the light stays on once triggered. Sensor and light can be angled independently.\n\nAlso, you could have an indoor switch to either force it off or force it on depending on the unit/your needs e.g. if you don't want pets or whatever triggering it. Or you could even get a remote one and eschew the sensor completely.""]"
I am trying to publish data from MangoAutomation with an http post request (shown in the first image) and receive this data on nodered by using the http request node to make a request to Mango. Unfortunately I get an empty response. Can anyone figure what I am doing wrong?,https://www.reddit.com/gallery/z9sque,automation,,[]
Need tips,https://www.reddit.com/r/automation/comments/z7wbk9/need_tips/,automation,Hey guys! What automation tips would you give to a newbie?,"['Study up and have a good understanding of:\n-How to use multi meter, check voltage/current continuity.\n-AC/DC circuits.\n-Differences between NO/NC (normally opened, normally closed.\n- how a relay works\n-Binary.\n-16, 32 and 64 bit registers\n-Differences between register formats signed, unsigned, floating points etc.\n\nLittle more advanced:\nModbus, canbus communication setups and topologies.\nLAN (local area Network) structures. Ipv4, macs, subnets, gateways. \nVFD/vsd programming and best practices.', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""I suggest trying out some basic automation tools before jumping into the complex stuff. That can help you get a foundational understanding of how it works, the uses of it, etc. Personally, I think that text expanders are solid tools to mess around with at first, because they are useful and they can help you understand the code that goes into automation without getting too deep into it. I recommend Text Blaze if you want to use one that's user-friendly. Ultimately, it's up to you. Just try not to get overwhelmed with all of the complicated stuff right off the bat, you got this!"", 'Dose not say munch for your automation company if you have to ask that here....']"
Hey guys i'm very new to this topic!,https://www.reddit.com/r/automation/comments/z7c03t/hey_guys_im_very_new_to_this_topic/,automation,Hey guys i'm very new to this topic can i ask someone a few questions about automation? Thanks,"['You just used up your first question. You get 2 more.', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'This is an automated response, yes you can']"
Automation Testing Market is expected to reach USD 49.9 billion by 2026,https://www.reddit.com/r/automation/comments/z6stlh/automation_testing_market_is_expected_to_reach/,automation,"To determine and forecast the global market based on components, testing types, dynamic testing, services, endpoint interfaces, organization size, verticals, and regions with respect to individual growth trends and contributions toward the overall market.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
What should people who lose their jobs due to automation do?,/r/IdeologyPolls/comments/z4mkaj/what_should_people_who_lose_their_jobs_due_to/,automation,,
VFD AutoRestart,https://www.reddit.com/r/automation/comments/z4btk9/vfd_autorestart/,automation,"Good day all!
 
I am wondering if it is common practice in industry to use the auto restart parameter on VFDs?

TIA","['Depends on how it‚Äôs used. I work in manufacturing so no you really ought to have a motor inspector/ electrician come to  line and check everything before they reset it. If you leave it up to the operators they‚Äôll trip the OLs every 15 minutes for a 12 hour shift and never give a shit. But i often use auto restart on power loss just not OL.', 'Depends on what you are doing with it', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""Ask this in r/PLC \\- you'll get more answers."", 'It depends on the process, and which faults you want to use the auto reset/restart on. I usually enable the over/undervoltage ones, and the mA input ones, as I mostly work in water and wastewater, and we want the pumps to come back after a transfer between power sources in emergencies.', ""Auto restart to stop and start based on external logic is common. Keep in mind some motors have a recommended limit on start/stop cycles, min/max speed limits. Resetting a faulted vfd is not a good idea. It is usually recommended to latch these types of shutdowns and have a tech and/or electrician look over drive or motor being controlled. Vfds usually trip for a good reason. If you're having issues, First easy check, I'd recommend checking motor plate settings.""]"
Lutron caseta and Logitech circleview,https://www.reddit.com/r/automation/comments/z3znu7/lutron_caseta_and_logitech_circleview/,automation,Has anyone tried these two in conjunction? I‚Äôm hoping for when my doorbell senses motion or is pressed my front entry lights will turn on? Can you all let me know if this is possible I‚Äôm using Apple HomeKit as a hub,"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
With what kind of probelms can neural net help in signal processing automation?,https://www.reddit.com/r/automation/comments/z3bg1e/with_what_kind_of_probelms_can_neural_net_help_in/,automation,"Hi,  
This might be a silly question so I apologize in advance.

I was trying to search on google for what kind of problems ML or DL can be useful regarding signal processing or automation but I found nothing.  
Also the problems in these topics which I have stumbled onto during classes on my uni seem not to complicate, or it seems that using such algorithm on these problems would be like reinventing the wheel.  


Do you guys have any ideas in what fields in Automation/Signal processing such algorithms might be useful?  
(I don't have a million bucks robot to teach it to walk so such farfetched ideas that are impossible for a student to conduct a study on are out)  


Thank you for your help in advance, because I couldnt thought of any topic on which I can conduct a study on.  
If you will, just give me a hint where to look, or a loose idea where such things might be useful and somewhat doable.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Working on aquaculture plc. Is a Brainbox good?,https://www.reddit.com/r/automation/comments/z3678q/working_on_aquaculture_plc_is_a_brainbox_good/,automation,"A small PLC system to control a few motors, air pumps, and lighting based on a few variables. Do you have any suggestions as to which PLC system I should employ?

I want to use Wi-Fi and have a nice interface for my computer.

Thank you in advance!","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""AutomationDirect has good low cost PLCs. For something as simple as your project, you could use a Click. As for a nice interface to your computer, a PLC generally isn't going to do that without extra software. Usually a PLC interfaces with an HMI. You can see the values of the PLC tags on the programming software, but it's not a nice way of viewing it. AutomationDirect also sells Aruino based PLCs. You might be able to find some open source software that will display the values over a GUI. You could also use a SCADA software like Ignition, but that's probably overkill for your application. Is this for yourself or for a business?"", 'The brand LaCroix sofrel has many PLCs  dedicated for water process, i recommend to check them out.', 'Check out weidmuller, it runs node red aswell. This gives you a flexible User interface for control', 'Never heard of it. Is it specific for that usage?']"
Best Dashboard Solutions for KPIs???,https://www.reddit.com/r/automation/comments/z3034c/best_dashboard_solutions_for_kpis/,automation,"Hello Everyone, 

I'm running a B2B agency and we're currently going through rounds of automation. One of the things that I'd like to implement is a dashboard that contains the following: 

\+ Financial data (MRR, growth, etc.) - coming from Quickbooks

\+ Customer success data (# of new customers, total number of clients, retention rate, etc.) - coming from Hubspot and Google Sheets. 

I was wondering if there's a service that allows to integrate all these data sources and beautifully visualize them as live dashboard that can be accessed through the phone, laptop, and maybe also displayed onto a TV. And it'd allow for user management (certain people within the company can see certain information). 

Thanks in advance","['The first two that come to mind are Power BI and Grafana.', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Download and Upload Automation - Web based,https://www.reddit.com/r/automation/comments/z2h59j/download_and_upload_automation_web_based/,automation,"I am looking for a tool that would help me download and upload assets / files from one web based application and upload on another. 

The flow would go like:

* Download N number of files from a web based application, A
* Save them to a local drive, let's say D:/
* Upload these assets to another web based application, B

Is there an out of the box tool that would help me achieve this? Thanks a ton!","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Uipath community edition', 'What about FTP?']"
windows GUI automation tool/framework,https://www.reddit.com/r/automation/comments/z0l328/windows_gui_automation_toolframework/,automation,"Hey all!

I am looking for a framework or tool, which can automate GUI software on Windows. A client of mine uses an application which poorly does not have any API. The only way of automating would be inserting directly to the DB. The vendor of the software locks th DB however and acces to it is just possible after a paid consultancy by the vendor.

So I am looking for a framework for automating GUI actions. It is just about inserting data into a basic form. Which tools should I look for?","['Check out [AutoIT](https://www.autoitscript.com/site/) that was it is specifically designed for.', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Automation for fast-growing B2B Service Agency,https://www.reddit.com/r/automation/comments/z0etl2/automation_for_fastgrowing_b2b_service_agency/,automation,"Hello Everyone, 

I'm the CEO of a fast-growing B2B service agency focused on cold email lead generation. Our internal core products include Hubspot CRM, Front, Notion, Slack, Google Drive, and Gsuite. I was wondering if anyone has ideas of how to best use automations (Zapier, App Sheets, etc.) to streamline the data exchange between these different products. We're open to coding our own integrations as well. 

Thanks and I'm looking forward to your answers.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""I'd recommend looking at tools they've built out for integration options first before going into third party like zapier"", 'Let me know if you want to circle back some ideas you may have. I‚Äôm happy to help !', 'If you‚Äôd want a constellation with my business, I‚Äôd be happy to help. Dm if you‚Äôre interested']"
Browser Automation Scheduling for Average Joe?,https://www.reddit.com/r/automation/comments/z091lj/browser_automation_scheduling_for_average_joe/,automation,"I am looking for a free or cheap software for Mac (chrome or safari) that would allow me to set up automated waiver wire pickups for fantasy football, right after waivers are run (like 3:00am lol). I know programs like Selenium exist, but I don‚Äôt know how to code, so I can‚Äôt create my own program.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Assuming your intended workflow is simple, Apple‚Äôs Automator app is built in to MacOS and is relatively easy to use. You can create automated workflows and then schedule them.']"
Discover 2 years' history of receipts&invoices in your Gmail account(s) with one click,https://www.reddit.com/r/automation/comments/z04zcv/discover_2_years_history_of_receiptsinvoices_in/,automation,"We developed a great automation service that finds all invoices and receipts in your Gmail and Outlook accounts up to 2 years back. The service is now offered at AppSumo for a $69-lifetime deal. Take a look + tell us what you think.

[https://appsumo.com/products/wellybox](https://appsumo.com/products/wellybox?utm_source=partner-link&utm_medium=referral&utm_campaign=partner-166422)","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', '$70 to use a key word search ...come on.....']"
What should this cost,https://www.reddit.com/gallery/yy4fyt,automation,,"['Somewhere between $50 and $5 million', ""If your company was to build this panel what would it roughly cost. I don't think management knows how complicated a build like this is. For reference there's 8 vfds that are used to control 9 motors in this build."", 'Best estimate is a bit broad brush as there isn‚Äôt much detail to go on, but I would budget between ¬£15,000 and ¬£25,000 in the UK. It really should be in an enclosure 3x the size it is in. There would be additional costs for engineering beyond a simple reverse engineer copy and redraw especially if you include site visits. \nInstall and testing of same would depend on site conditions. \nI‚Äôd budget between ¬£800 and ¬£1,100 a day including traveling time and + expenses for a commisioning engineer (UK). I‚Äôd expect 2-3days on site electrical commisioning as long as everything is ready to go in advance. \nAllow 6 months to source drives in the current market after design approval and a month to build once they are available. \nHope that helps.', 'Materials wise, I‚Äôd estimate between $15k-$40k depending on brands and distributor relationships. \n\nLabor is a metric that varies from company to company and is impossible to guess unless you know a company‚Äôs rate, but a skilled panel builder could build this in between 60-80 hours.', 'About tree fiddy', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""There are way too many factors to give an adequate estimate, but if I had to guess, I'd say at least $25k depending on how good your sourcing team is or relationships with suppliers.\n\nYou gotta love when management says CaN't YoU dO iT cHeApEr?!"", 'This is way too small enclosure.', ""$40-50k especially with today's prices. I also agree, cramped panel, pain to wire.""]"
Salary Question,https://www.reddit.com/r/automation/comments/ywxqij/salary_question/,automation,"I‚Äôm an electrical engineering graduate working as a controls engineer that does start up commissions and software development. I‚Äôve been doing this for about 1.5 years now. I‚Äôve done additional things for my company beyond my base responsibilities such as building a wiki that‚Äôs quickly becoming a go-to source for information sharing, and expanding the tools we have for our project development/management suite.

With annual reviews coming up I‚Äôm wondering what is a fair salary increase. I live in WA on the western side of the Cascades so cost of living is up there if that makes a difference. 

Anyways‚Ä¶  advice/comments/concerns?","[""Since each state and company can vary, my suggestion would be to look at local job postings that are similar to help gauge your expectations. Most companies have a flat percentage they boost employees' pay by and then occasionally a cost of living boost. If you can at least show a competitive salary it may help get what you'd expect."", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Have you checked Glassdoor/Indeed?']"
Forbes: How AI can improve job quality,/r/ArtificialInteligence/comments/ywsjee/forbes_how_ai_can_improve_job_quality/,automation,,
Automating Weq4u.. via Zapier or scripts or something similar?,https://www.reddit.com/r/automation/comments/ywvzbc/automating_weq4u_via_zapier_or_scripts_or/,automation," 

We are based in the UK and use a horizon phone system.

One of our departments have to often queue for hours to talk to someone in another call centre they need, it wastes a lot of time, and they are tied up when clients need them, they dont want to put the queued call on hold to talk o a client in fear of missing when its answered.

Weq4u is an excellent free service which takes the sting out of this but with a couple of caveats.

It routes your call queue request based on caller Id so you can't have more than 1. Plus all of our agents have the outbound CID set to our main office number, so that's 1 for the whole company and the return path for that number is our reception. So it can't work from this CID

When you are at the front of the queue it gives you a quick missed call for you to redial from the relevant CID to connect, it doesn't just join in you when you answer the call.

My thoughts were that we could have separate VoIP lines (with any UK provider) for the agents just for managing weq4u, so our agent makes the call out with their unique CID, they join the outbound queue and presses 9\* to end the call, so weq4u does its magic and waits for an agent.  
Then weq4u rings back to that VoIP line (2 rings missed call) to tell it that the agent is ready on the outbound call. We have an automation somehow which immediately rejects the weq4u call based on its CID, then redials it (which you have to do), dials a hunt group (external inbound) number on our horizon system and transfers the call onto that hunt group (or conferences it if that's easier).

I could name the horizon hunt groups based on which agents queue will be calling so that everyone in that department can see that Agent X's outbound call queue is ready to talk, if they are available they will grab it, if they are away or on the phone someone else will grab it and do what's needed so it's not missed.

It's only a small department, currently only 4 but looking to expand to 8 agents, they all sit together and can easily see whos busy and whos not.

It should work in theory, but I've been trawling VoIP systems and automation systems and I can't find an obvious way to make this happen.

The system would need to have unlimited minutes, include the 0333 number in the minutes, and be able to present UK CID's

I would appreciate any pointers or ideas I'm a sys admin (and I do a bit of easy dev), I'm not up on all the VoIP solutions out there.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
"Automation COE Market Growth, Opportunities Business Scenario, Share, Growth Size, Scope, Key Segments and Forecast to 2027",https://www.reddit.com/r/automation/comments/ywln5t/automation_coe_market_growth_opportunities/,automation,"To provide detailed information related to major factors (drivers, restraints, opportunities, and industry-specific challenges) influencing the market growth.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Automate content distribution to Reddit using RPA,https://www.reddit.com/r/automation/comments/yvv208/automate_content_distribution_to_reddit_using_rpa/,automation,"Hi all, I've built a flow to automate content distribution to Reddit using RPA (RoboMotion)  


Here's the vid: [https://youtu.be/CKL\_f7f-q6o](https://youtu.be/CKL_f7f-q6o)  


By the way - I have nothing to sell. Just sharing my knowledge. 

&#x200B;

https://preview.redd.it/vzq3ipx9t30a1.jpg?width=890&format=pjpg&auto=webp&v=enabled&s=78ed284c5ab666e09a0ba6e9064e71736c7cd133","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
I need to click that link first!,https://www.reddit.com/r/automation/comments/yuvelx/i_need_to_click_that_link_first/,automation,"I am someone desperately looking for a house. This realtor sends you emails, from the same sender, that host a link that you click on for a viewing of the apartment. The first \~25 people get in. I want to set it up so that when I receive an email from that sender, it automatically clicks the 2nd link or that specified link with the same button text. How would someone with no, or minimal, coding experience do this?","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Outlook on a computer with the email connected. Set up a trigger to run a file on the PC and maybe to also save the email. Run a powershell script that parses the email and executed the link in your default web browser. \n\nMaybe easier ways to do it but idk.']"
"Automation COE Market Growth, Opportunities Business Scenario, Share, Growth Size, Scope, Key Segments and Forecast to 2027",https://www.reddit.com/r/automation/comments/ys9jjo/automation_coe_market_growth_opportunities/,automation," To provide detailed information related to major factors (drivers, restraints, opportunities, and industry-specific challenges) influencing the market growth","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Join us in our E-commerce Media Automation Hackathon,/r/Automate/comments/yrwhnn/join_us_in_our_ecommerce_media_automation/,automation,,
Is there a system used in companies/business that tracks status of projects like how we track a food order/clothes online?,https://www.reddit.com/r/automation/comments/yqfesj/is_there_a_system_used_in_companiesbusiness_that/,automation,"For example jobs that are running that need process flow‚Ä¶ any names/suggestions? 
Thanks ü•∞

Explanation: 

The company I am at wants me to reduce COPQ (cost of poor quality) and improve the Company as a whole. 
The company is a service provider not manufacturing company - so it's the improving is mostly focused on providing the service itself which is on site and the steps before providing it. (work flow between employees)

For example: The company barely has SOPs, those will be written. 
Process flow maps for processes should be designed .
I also think a software where you track the process flow of each procedure such as from receiving RFQ -> doing commercial and technical offer --> submission --> Letter of PO --> Site visit, that can be documented like how we track food online after an order and know at which step we're at  till the execution of the job. 

However, I have no idea what else i should be doing? Six sigma or lean or what exactly? I'm a bit lost from what can work best in the company's case, any advice?","['Jira, Meistertask to a lesser extent', ""Yes, but it's fairly industry specific. CRM's and Issue Trackers are probably as close to universal as it gets."", 'try monday.com', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""Explanation: \n\nThe company I am at wants me to reduce COPQ (cost of poor quality) and improve the Company as a whole. \nThe company is a service provider not manufacturing company - so it's the improving is mostly focused on providing the service itself which is on site and the steps before providing it. (work flow between employees)\n\nFor example: The company barely has SOPs, those will be written. \nProcess flow maps for processes should be designed .\nI also think a software where you track the process flow of each procedure such as from receiving RFQ -> doing commercial and technical offer --> submission --> Letter of PO --> Site visit, that can be documented like how we track food online after an order and know at which step we're at  till the execution of the job. \n\nHowever, I have no idea what else i should be doing? Six sigma or lean or what exactly? I'm a bit lost from what can work best in the company's case, any advice?"", 'Guys what do you think about power automate by office 365? Any ideas? I need something that‚Äôs doesn‚Äôt need a long implementation, like between 1-3 months, and not that costly! \nThank you!']"
Automated testing basics,https://www.reddit.com/r/automation/comments/yqjg89/automated_testing_basics/,automation,"Running a large number of tests automatically on the developer's computer, server, or in the cloud to make sure everything functions as intended.

The testing phase of the software development lifecycle is crucial. By handling tedious and repetitive duties like regression tests, automation testing frees up testers to focus on other high-quality activities like conducting exploratory tests and analyzing test findings, among other things. As a result, automation testing makes it possible for you to complete more tests faster.

Manual testing may become challenging as there are more features to test or more software faults to find. Automated testing can help with this.

To keep the software development process productive and effective, automation testing investment is crucial. You may run tests in any environment you require, as frequently as you like, and with automation. As a result, security and stability are improved, time and effort are saved, and maintenance costs are decreased.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Complete Reporting Automation,https://www.reddit.com/r/automation/comments/yq1aom/complete_reporting_automation/,automation,"How do you have your reports automated completely? Share the steps/tools and tech stack used. I am looking for a solution to automatically send report to a list of people or users who are interested in receiving it. 

How did you build the report (etl, transformatin). How are you generating the report and sending to users, in which frequency and how?

Any help, ideas, processes tools and tech will be appreciated.

The idea is to design the report once and make it work every week/days etc and send automated everything. Zero human in tervention after that.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'I don‚Äôt think this is exactly what you‚Äôre after, but I don‚Äôt build ‚Äòreports‚Äô I build ‚Äòdashboards‚Äô. These don‚Äôt need to be sent to anyone. At any one time I can go to a link and view the dashboard I‚Äôm interested in which contains the information I‚Äôm after.\n\nThe main approach is to have all data from all sensors be captured in some sort of timeseries database like influxdb or timescaledb.\n\nThen you access that database via a data visualisation platform like grafana or superset. Then through that tool you setup the queries and charts you‚Äôre interested in. It‚Äôs typically best to build one dashboard for one purpose. Build as many as you want / need.\n\nThe data from your sensors should be captured into your timeseries database basically in a live fashion and you‚Äôre front end should also pull in all updated info from the database live. So at any time you go to your dashboard you get the current information. And it doesn‚Äôt need to be just about what is happening now. You‚Äôll probably want to analyse trends over time and identify anomalies. You could also setup alerts if certain variables reach certain thresholds perhaps for a certain time period etc.\n\nOnce setup it‚Äôs all very hands off so may satisfy you‚Äôre intent.', 'Hard to answer this one. Depends on how is the data generated, where it it hosted (cloud, internally, both), compliance/security, apps involved, type/structure of data, etc.\n\nWithout details, answers are a shot in the dark.', 'Have you looked into rpa solutions? And are you looking to build something yourself?']"
Which is better? Cypress VS Selenium,https://www.reddit.com/r/automation/comments/ym4sf2/which_is_better_cypress_vs_selenium/,automation,"Hello guys!
I am pretty new (almost one year) into automation testing for websites. My question and debate topic is which one is better and gives more opportunities in order to test a website? Cypress or Selenium grid?","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""When it comes to [test automation services](https://www.qasource.com/automation-testing-services) Selenium is one of the best automation tools available in the market to automate web & mobile applications.\n\nSelenium is a very popular open-source tool widely used in industry. However, there are some new tools like Cypress also, gaining popularity, so let's see the cypress vs selenium comparison.\n\nCypress is a developer-friendly JavaScript-based front-end testing tool that operates directly in the browser using a unique DOM manipulation technique.\n\nSelenium WebDriver is a library along with a language-specific framework with the flexibility to select programming languages like Ruby, Python, Java, etc. It uses JSON wire protocol for executing test cases.\n\nSelenium is a preferred choice for over a decade for test automation, as it has many advanced features when it's compared to cypress, as it supports multiple test frameworks like junit, TestNG, and Cucumber, etc, & supports safari browser, whereas cypress doesn't support safari browser, also cypress can't invoke multiple tabs.\n\nThese were only a few points but Cypress lacks on multiple fronts when it comes to 1-1 comparison. Selenium may be a bit hard to set up & use but it's worth using selenium.""]"
How To YouTube Automation With Python.. I'll be posting my own creation soon!,https://www.youtube.com/watch?v=p0M0MzFLtY0&ab_channel=Moneysmith,automation,,"['[removed]', 'j', 'Lol, [www.reddit.com/comments/**watch**](https://www.reddit.com/comments/watch) is the URL.']"
Help with Report automation,https://www.reddit.com/r/automation/comments/ym0wn7/help_with_report_automation/,automation,"I'm trying to accomplish  the goal of automating the process creating a report that pulls:

The high and low points in activity  in the last 24 hours and 30 days

The average amount of activity lost the last 24hrs and 30 days

It's able to to generate that report at certain times of the day and a click of button

Ideally the report is generated in Excel

This is all being pulled from a site that has live data graphs.


Any help would be appreciated, it's safe to say I don't have alot of programming experience. I'm struggling with this and could use any help!","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'What industry are you working for?']"
Simulation in DOPSoft 4.00.16.22,https://www.reddit.com/r/automation/comments/ym0cn4/simulation_in_dopsoft_4001622/,automation,"I‚Äôve been trying to simulate in DOPSoft but all the fonts that I use are replaced with Arial, somebody knows if it‚Äôs a version error?","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Reusability in Power Automate,https://www.reddit.com/r/automation/comments/ylj4p6/reusability_in_power_automate/,automation,I want to ask if someone has solved the reusability problem of Power Automate Desktop. How can I reuse the subflows in different Desktop flow?,"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Need help finding a tool that integrates Google Drive with Confluence Server.,https://www.reddit.com/r/automation/comments/yldkrv/need_help_finding_a_tool_that_integrates_google/,automation,"Hello!

I need to migrate tens of thousands of files of varying types from Google Drive into individual Confluence Server pages.

Can anyone recommend some good automation tools to check out?

Thanks in advance.

## Requirements

#### Must have

* Copy content from Drive to Confluence Server.
* Retain all content for each file.
* Retain most (if not all) formatting for Google Docs.
* Output a list/inventory to Google Sheets with specific details of what occurred.
* Meet corporate security requirements, including access limitations and data retention.
* Can be tested thoroughly before implementation.

#### Nice to have

* Can determine source file location on Drive side.
* Can recreate source file folder location on the Confluence side. e.g., If the source file was in /documents/taxes/ then it will create a documents page in confluence, a taxes page inside that, and put the file into that target.
* Can read Confluence labels.
* Content reformat or cleanup option. e.g., strip tags, remove markup, things like that.
* Integration with existing Confluence macros.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Anyone familiar with the DC2000 drives?,https://www.reddit.com/r/automation/comments/yl6j8j/anyone_familiar_with_the_dc2000_drives/,automation,Need help repairing some boards on a DC2000 dc drive. If anyone has any knowledge on how to repair the DCFB boards DM me.,"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Email Automation Challenge,https://www.reddit.com/r/automation/comments/yl8n8y/email_automation_challenge/,automation,"Hi there,  
Newbie to this group. I'm having trouble with an email automation challenge.  


Most mail tools allow you to ingest responses from a survey, create a contact and then send an email or sequence to a user and include merge fields based on their responses. But what if you are creating an automation where you have someone answering a form multiple times (like say a daily performance report) and you want to send them through an email sequence for each submission with the fields for each submission included with its unique merge fields? The problem I'm having in Mailchimp and other mailers is that their merge field contacts are overwritten so I can't send them a tailored sequence for EACH submission.   


Got any ideas for platforms that would help me out with this or an ideal way to set this up?","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
IoT-enabled Smart Silo/Bulk storage using LiDAR for Volume Estimation,https://www.reddit.com/r/automation/comments/yko13k/iotenabled_smart_silobulk_storage_using_lidar_for/,automation," Hi everyone, I am a student taking a Master of Science in Computer Applications. I am currently on the early journey of my graduate studies. The title that I wrote is the prospect topic I want to pursue/conduct in my thesis. Basically, the goal is, the 3D LiDAR will scan inside the Silo or Bulk Storage and depict a 3D visualization of the surface of the raw material inside and compute the estimated volume. I will create a user interface, probably window GUI or web-based GUI for remote monitoring and conducting operations.

Now the question is, how can I or where can I integrate the IoT part? (Since I am majoring in Internet of Things), and what should be my objective for this?","['Might also get some help from r/PLC\nOther than that what IoT devices do you foresee needing for this? Will you be coupling the LiDAR scan with other data from field?', 'Why not just incorporate a scale or use lasers to determine the approximate level of the material?\n\nAre you trying to be hyper-exact by creating a 3D grid from the LiDAR measurements and interpolating to create a surface?', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Automation COE Market is predicted to reach USD 1.5 billion by 2027 with CAGR of 36.9%,https://www.reddit.com/r/automation/comments/yk0ljt/automation_coe_market_is_predicted_to_reach_usd/,automation," To provide detailed information related to major factors (drivers, restraints, opportunities, and industry-specific challenges) influencing the market growth","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Tools for automation and daily tasks,http://awesome-tools,automation,"Hello, I m courios to find out more tools to use in my daily task as a infrastructure engineer. So far I use the following tools:
- dnsx (dns query)
- httpx (http requests and testing)
- mapcidr (quick calculate subnets)
- tmux .. for multiple terminals
- barrier (for remote connection to my computer through laptop)
- ansible ... Off course
- puppet/foreman
- kubernetes with helm/kind
- jq (for json parsing)
- ddosify (testing multiple paths or status code)
- mailcow-docker
- janus (for api gateway endpoints)
- docker gen (generate nginx config)
- acme-companion (generate ssl certificates)

What interesting tools do you use ü§ó??",
Benefits Of Automation Testing,https://www.reddit.com/r/automation/comments/yid2dc/benefits_of_automation_testing/,automation,"Automation testing is one of the most popular methods for software testing. It‚Äôs an extremely efficient, cost-effective solution that can be adopted at any stage of your software development lifecycle ‚Äì and it eradicates ambiguity on whether to use automation testing or stick to manual testing.

Automated testing has many benefits, such as: 

**Shift-left testing**\- It is a part of continuous testing that conveys that the testing phase should be incorporated into the SDLC (Software Development Life Cycle), right from the requirement gathering phase to find bugs at an early stage. This can save money and time, by ensuring that bugs are found early by a tester.

**Easy regression testing-** Developers may need to perform a set of similar test cases over and over again, just to ensure that the bug has been removed. To make sure all testers have access to the latest changes, they have to spend time setting up the environment on their local machines and then run tests in parallel by creating new test plans and test cases every time. This leads to unnecessary wastage of time, money and efforts.

**Reduced business costs-** Automation testing offers significant benefits. It is advantageous for organizations because it reduces business expenses and enhances the quality of work. With automation testing, organizations are able to reduce additional expenses and maximize resource utilization.

**Improve the quality of manual tests-** With the help of test automation tools, you can perform manual testing very effectively. Test automation helps testers validate testing coverage in different environments and produces the required results at a much faster pace. These benefits of test automation have won customer favors in recent years.

**Better smoke testing-** Smoke tests are considered to be a best practice as they help avoid outages. These tests are used in the early phases of a project, and can catch major issues before tests begin running regularly. Automated smoke tests are an efficient way for teams to do this.","['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Good information about automation testing. Thank you for sharing this.']"
Looking for a way/program so when I receive a text from a particular phone number it‚Äôs then immediately copied and sent to a phone number list automatically.,https://www.reddit.com/r/automation/comments/yhwv7g/looking_for_a_wayprogram_so_when_i_receive_a_text/,automation,,"['Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'You‚Äôre basically describing an SMS chat bot with custom response functionality.  Look into Amazon Lex or similar ‚Äî you can allocate a phone number that can receive a text and then kick off a Lambda that does stuff with it like relaying it to an outbound SMS.  I‚Äôve actually done a similar project for a hackathon a few years back so there might be even more user friendly tools out there now.  https://aws.amazon.com/blogs/messaging-and-targeting/create-an-sms-chatbox-with-amazon-pinpoint-and-lex/', ""All you need is tasker if you're on android."", 'Check out Shortcuts for iOS or Tasker for Android. If you want to get more aggressive you can check out Twilio and making your own paid sms bot lol']"
Career change away from production,/r/PLC/comments/yfymff/career_change_away_from_production/,automation,,
10 Key Benefits of Business Process Automation,https://www.reddit.com/r/automation/comments/yeobst/10_key_benefits_of_business_process_automation/,automation,"**What is business process automation?**

[Business process automation (BPA)](https://www.sattrixsoftware.com/what-is-business-process-automation.php) is the use of technology to automate repetitive, manual tasks in the workplace. By automating these tasks, businesses can improve efficiency, save money, and improve employee morale.

BPA can be used to automate a variety of tasks, including customer service, data entry, accounting, and human resources.

Examples of Business Process Automation

‚¶Å	 Document routing

‚¶Å	 Invoice processing

‚¶Å	 Employee onboarding

‚¶Å	 Data entry

‚¶Å	 Screening against PEPs and sanctions lists

‚¶Å	 Data deletion

‚¶Å	 Transaction monitoring

**The top 10 benefits of business process automation are listed below.**

**1. Increased efficiency and productivity:** Business process automation can help you automate repetitive and time-consuming tasks, freeing up your employees to focus on more important tasks.

**2. Improved accuracy and quality:** Automating tasks can help to reduce errors and improve the overall quality of your outputs.

**3. Increased customer satisfaction:** When your processes are more efficient and accurate, your customers will be happier with the results.

**4. Allows employees to focus on higher-value tasks:** Automating low-value tasks frees up employees' time so they can focus on tasks that are more important to the business.

**5. Increased sales and revenue:** Automating your processes can help you to increase sales and revenue by making it easier and faster for your customers to purchase your products or services.

**6. Reduces errors and improves accuracy:** Automated processes are more accurate than manual ones, which can help to reduce errors and improve the quality of your products or services.

**7. Increased market share:** By automating your processes, you can improve your competitiveness and grab a larger share of the market.

**8. Increased profitability:** Automating your processes can help you to increase your profits by reducing costs and increasing

**9. Save time and money:** By automating tasks that are time-consuming and expensive to complete manually, businesses can save a significant amount of time and money.

**10. Higher productivity:** Organizations that use technology to automate processes see an increase in productivity as well. The main reason for this is that machines can handle multiple tasks at once, which speeds up processes.","[""Surprised pikachu face?\n\nWho would've thought"", 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', 'Why do I even sub to this subreddit üôÑ', 'Automation is making things easier, faster, and more effective which is why we are seeing more and more involvement of automation in various fields. The most important aspect of automation I think is the fact that it is helping us to do things more accurately in shorter amount of time.', 'The benefits are clear - but what tools would you recommend using to see these benefits through? Recommendations? Windows environment? Linux/Mac environment?']"
extraction automation in excel,https://www.reddit.com/r/automation/comments/yepb85/extraction_automation_in_excel/,automation,"Hi Everyone, wanted to ask if we can build a macro which can extract a Excel file from a password protected pdf (which we generally open from Adobe acrobat from left attachments section) is there an alternative way or std software for this automatation?","['Python or Alteryx is your best bet', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*']"
Duplicate Tickets,https://www.reddit.com/r/automation/comments/yeecop/duplicate_tickets/,automation," 

Hi, i work as app support.

I would like to delete duplicate tickets automatically.

Can someone guide me on this.

I can do some programing (Front end , and a little bit of python). But i dont seem to have any idea on how to do it.

The rough idea now i have is to use DOM and get the duplicate tickets close. If there is a faster way,it would be better or maybe a structure i can follow. Can some1 help me on this . Thanks","['First thing id suggest is getting a udemy course on selenium if you want to use the dom. Python or Javascript (python is easier as you dont have to deal with promises / callbacks). This might be easier for you than the ideal method. \n\nIdeally i‚Äôd automate it utilizing the ticket applications API. You can use postman for this if youre not totally comfortable programming. In addition to postman look at the network tab on the developer tools in your browser to inspect the request when you GET the list of tickets and delete them. You can right click the request and copy it as a curl then import it into postman.\n\nGood luck, you‚Äôre on the right path to develop some awesome skills', 'Thank you for your post to /r/automation!\n     \nNew here? Please take a moment to read our rules, [read them here.](https://www.reddit.com/r/automation/wiki/rules)\n\nThis is an automated action so if you need anything, please [Message the Mods](https://www.reddit.com/message/compose?to=%2Fr%2Frpa) with your request for assistance.\n\nLastly, enjoy your stay!\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/automation) if you have any questions or concerns.*', ""what's your ticketing system? read up on their api docu, perhaps you can create a custom function that could read new tickets and compare them to existing ticket, then either do a merge or close the the other ticket (you might want to leave a comment/note indicating its duplicate ticket #).""]"
Running unlimited number of tests in less than 60 seconds,https://www.reddit.com/r/selenium/comments/10e0jd6/running_unlimited_number_of_tests_in_less_than_60/,selenium,"I developed an interesting tool that uses AWS lambda to basically parallelize the hell out of running test. It is a test framework specific solution and the current version works really well for pytest selenium/playwright setups. I ran a 10,000 test framework setup in under 60 seconds. Each test was designed to take 8-10 seconds to mimic typical runtimes. 

Would anyone be interested in taking this tool for a trial run in your company?

Some cool features are

1. Use your own AWS account. Support for Azure, GCP coming soon

2. Support for pytest with selenium, appium, playwright tool

3. Flaky test detection logic

4. Number of tests does not impact the overall runtimes too much because cloud scales for you

5. Way way cheap due to low cost of lambda function 

6. Integration with test case management system like TestRail and Zephyr and MicroFocus ALM. Test results are automatically uploaded to your TCM

7. No code changes needed.","['I‚Äôll post a screen recording in a few weeks so that interested folks can take it for a test drive', 'Sounds to good to be true']"
"How to click in this element using selenium which has no id and name,",https://www.reddit.com/r/selenium/comments/10e3wtv/how_to_click_in_this_element_using_selenium_which/,selenium,"<span class=""ui button"" style=""user-select: none;""><em class=""icons"">search</em><i></i></span>

&#x200B;

span = driver.find\_element(By.XPATH, ""//span\[@class='ui button'\]"")

attach=wait(driver,20).until(ec.presence\_of\_element\_located((By.XPATH,""//html//body//div//div\[4\]//span\[4\]//em\[@class='search'\]"")))

ive tried this and also tried it with class name but not working","['Your best bet is the XPath or CSS Selector.\n\nOpen up your browser to inspect the DOM (F12 or DevTools and select Elements in Chrome).  Then depress Ctrl+F to get the find in page bar.  You can test out your XPath or CSS Selector string there.  Ensure you get ""1 of 1"" in your results.\n\nThere are some plug-ins you can get to help you decipher what the best string is to identify the object.\n\nEDIT: Also, do a right-click and Copy on the element in the DOM.  You can copy the CSS Selector or various types of XPaths from their too.', 'Can‚Äôt remember the exact syntax off the top of my head but something like ‚Äú//span[@class=‚Äòui button‚Äô and text()=‚Äòsearch‚Äô]‚Äù might work', ""You could try .ui.button or .ui.button[style*='user-select']"", ""//span\\[@class='ui button'\\]//em\\[text()='search'\\]\n\n&#x200B;\n\nem @ class is icons, not search. Search is the text."", ""How to make that it doesn't click on button that has something near it(already clicked)(maybe can detect png on span class etc? And clicks on another one that doesn't have it.( Same id-s etc ).\n\n\n ( for inbox auto reply ).\n\n\nSomeone help me please"", ""You guys are probably right, but man I can rarely get XPATH to work right for me.  That's even with me copying the xpath straight from the devtools console.  I usually have to find\\_element by ID/class/etc or by partial text match.""]"
This button is physically visible but...,https://www.reddit.com/r/selenium/comments/10e2wcr/this_button_is_physically_visible_but/,selenium,"if you could find a button that doesn't have xpath, cssSelector, id, name, class, className, containsText, or tagName and doesn't have an id name in the DOM - how would you go about finding this button?  It is physically visible and clickable and I have no clue what to ask OpenAI at this point.","['Either look for the parent element (or the parent of the parent, just go up until you find something) if that has some unique property that can be used and search from there, or just use the raw xpath for example if nothing else works. I‚Äôm fairly certain that if the element exists in DOM it does have an xpath.\n\nIf you can share the DOM or the page in question it would be possible to give a more detailed answer that would be suitable for your use case.', ""If it's in the Dom why wouldn't it have an XPath."", 'How can there be no xpath? The one you copy from browser via dev tools might be not good enough, but then you would need to write your own.', 'Is it in a shadow DOM? It‚Äôs been a few years since I last looked into it. Has shadow DOM gotten easier to work with?', 'Just a button with no text on it?  I‚Äôd go with the ‚Äúfind a parent and use a relative xpath‚Äù strategy.', ""I'd say you have shitty developers and they need to go back and fix the code.\n\nAlso, EVERYTHING has an XPath."", 'or do a search against the img src and .click() it.\n\nExample:\n\n`link = driver.find_element(By.XPATH, ""//input[@src=\'images/done.gif\']"")` \n\n`link.click()`']"
Determine who shared a Facebook post,https://www.reddit.com/r/selenium/comments/10e2fu9/determine_who_shared_a_facebook_post/,selenium,"A friend of mine asked me if there was any way of programmatically getting a list of people who shared a post.  I can figure out how to get the number of shares, but haven't figured out how to get the actual list of people.  Anyone know how I can do this or where I can find some code snippets that do it?  

Thanks in advance",['Click on the number of shares. Should open the list of who shared it. Or maybe you click on the number of likes. I forget exactly and Facebook is always changing. But the info is there.']
Hard time populating the find_elements function.,https://www.reddit.com/r/selenium/comments/10dpl7k/hard_time_populating_the_find_elements_function/,selenium,"Hello all, i‚Äôm very new to Selenium and Python: Each time I attempt to use driver.find_elements none of the elements pop up. Same thing with

In fact, it looks like the functions I have are pretty limited, unless maybe I‚Äôm doing something wrong? 

I‚Äôve set up my environment like: 


from selenium import webdriver
from bs4 import BeautifulSoup
from selenium.webdriver.common.keys import Keys

Appreciate any responses!","['One automation debugging protip: use [document.querySelectorAll\\(<selector>\\)](https://developer.mozilla.org/en-US/docs/Web/API/Document/querySelectorAll) for your selector debugging directly in a browser console. This is to make sure you have a correct selector in the first place...', 'Gonna need some more information here, specifically what locator strategy are you using for finding the elements (name, id, xpath, css, etc), how are you declaring the list and what are you doing with the variable you‚Äôve declared representing the list. If you include the error text you are receiving and a screenshot of the dom representing the elements you are trying to find it‚Äôll be easier to assist you.']"
Bot detection on google?,https://www.reddit.com/r/selenium/comments/10cp1vh/bot_detection_on_google/,selenium,"So my code was working fine until a couple of days when I keep getting this error message from google: **Couldn't sign you in.** **This browser or app may not be secure.**

Here is my code:

>from selenium.webdriver import Chromefrom selenium.webdriver import ChromeOptionschrome\_options = ChromeOptions()chrome\_options.add\_argument(""--lang=en-US"")chrome\_options.add\_argument('--disable-blink-features=AutomationControlled')chrome\_options.add\_experimental\_option('prefs', {'intl.accept\_languages': 'en,en\_US'})chrome\_options.add\_experimental\_option('excludeSwitches', \['enable-logging', 'enable-automation'\])chrome\_options.add\_experimental\_option(""useAutomationExtension"", False)chrome\_options.set\_capability('dom.webdriver.enabled', False)chrome\_options.add\_argument(f'--user-data-dir={PATHS.CHROME\_SYS\_PATH}')chrome\_options.add\_argument(f'--profile-directory={sub\_dir}')chrome\_dirver = Chrome(options=chrome\_options, executable\_path=PATHS.CHROME\_DRIVER)chrome\_driver.get(r""[https://www.google.com/](https://www.google.com/)"")

Google keeps throwing the same error over and over!  Is there any way to avoid the detection on chrome?","['I love watching this question get posted here every few days.', ""You can try logging into Google via stack overflow. That used to work, I don't know about now."", ""Try using [undetected chromedriver](https://github.com/ultrafunkamsterdam/undetected-chromedriver) it should make your scraper harder to detect. If that doesn't work then you will need to use proxies.""]"
selenium/Java interview prep,https://www.reddit.com/r/selenium/comments/10cejuc/seleniumjava_interview_prep/,selenium,"Hello, I am planning to apply for some selenium based automation jobs. Anyone can give some tips on which topics in java programming and selenium should I focus on. Thanks in advance",[]
automatically detecting elements or text within the web page using Selenium?,https://www.reddit.com/r/selenium/comments/10axdse/automatically_detecting_elements_or_text_within/,selenium,Im trying to create a script that could automatically detect the content of a web page and based on that content perform some operations .. Is it possible with selenium automation?,"[""The very first line on the [Selenium website](https://www.selenium.dev/) is:  \n\n\nSelenium automates browsers. That's it!\r  \nWhat you do with that power is entirely up to you."", 'Yes. \nMap the elements that may or not appear, and check if they exist.\n\nhttps://stackoverflow.com/questions/9567069/checking-if-an-element-exists-with-python-selenium', 'What do you mean by ""automatically detect the content of a web page""?', 'Yes']"
How to automate a Google login flow using Selenium scripts?,https://www.reddit.com/r/selenium/comments/10ak09w/how_to_automate_a_google_login_flow_using/,selenium,"We are trying to automate a Google login flow in our Selenium script.

When the test runs, Google treats this as suspicious/spam-bot activity, and asks for additional verification. So we get either a Captcha screen or a OTP code login screen.

Has anyone managed to successfully automate this flow?","['No one‚Äôs solved it, that‚Äôs why it exists', 'According to [this](https://stackoverflow.com/a/62244793) answer on Stack Overflow you can use the user data dir if you have already logged in. Not sure if this still works but definitely worth a try.', 'I would suggest playing around with localstore, userdir and disabling clean sessions. From Google login POV Selenium is not different from bots, so they do everything to prevent such possibilities.', ""I've gotten past captia, reCaptia, and 2FA by using webdriver wait (until element shows) and going through the captia manually.  However this means that you'll need to do these parts manually everytime a test case is run.  The automated process resumes soon after."", 'Is this an option?\nhttps://developers.google.com/recaptcha/docs/faq#id-like-to-run-automated-tests-with-recaptcha.-what-should-i-do', ""Google specifically puts code on so that you can't do this. They don't want bots logging in for probably a multitude of reasons. We should all respect that."", 'I‚Äôve logged into gmail html5 using selenium as recently as 2020. Otherwise can you feed the auth token into local storage?']"
[python] What's the proper way to handle lazy loading of elements?,https://www.reddit.com/r/selenium/comments/10anbsq/python_whats_the_proper_way_to_handle_lazy/,selenium,"I'm currently grabbing all the elements that are loaded on page load, and iterating over them.

    elements = driver.find_elements(By.CSS_SELECTOR, 'button.group.visible')  
    for element in elements:      
        ... 

Could someone advise me on how to load the next batch and apply them to the elements? Lazy loading also pools the elements so the data changes if you scroll up and down.",[]
Avoid StaleElementReferenceException,https://www.reddit.com/r/selenium/comments/10ael88/avoid_staleelementreferenceexception/,selenium,"Hi guys,
I had this error : StaleElementReferenceException
The scenario is :  i Searched on google and visited each link in  result of google but when i returned from the first link and clicked another link i got this error ""StaleElementReferenceException""

Selenium python 
Please help me and thanks guys.","['You likely need to re-declare your element locators at the start of your for loop (guessing you are getting all the  a tags in a list, then attempting to loop through it). Problem is that when you tell selenium what to do, the dom changes after you click the first link, so after you‚Äôve returned to the list of results your original element list declaration is stale. It‚Äôs either that or your aren‚Äôt waiting long enough between trying to click the next link. Stale element means the dom changed between declaration and action.']"
Add code once automation has started,https://www.reddit.com/r/selenium/comments/10a0b36/add_code_once_automation_has_started/,selenium,"Hello,

&#x200B;

This may be a more general python question rather than specific to selenium. I am fairly new to python and selenium, but I'm typically pretty good at Google, but I can't find this answer.

&#x200B;

I use selenium to automate several admin tasks (user opens a ticket, I have selenium take that info and put it in the vendor system is one use case). What I am looking for is a way to run selenium to sign in to the sites in the morning, and I can insert and run a block of code as needed. (Same block, the only thing that changes is the ticket number)

&#x200B;

Right now I am using VScode to write in and run when I have several that are ""ready"", but that kinda defeats what I am looking for. Is there an editor that I can run that will keep Chrome open and that I can add text to as I go?

&#x200B;

Thank you!",['Could you go about implementing a Trigger method?']
Kijiji Blank Page,https://www.reddit.com/r/selenium/comments/10a4zy0/kijiji_blank_page/,selenium,"Anyone know why Kijiji blank pages after clicking ""Post ad"" manually? All i've done is open the homepage with geckobrowser. Any ideas would be greatly appreciated",[]
General advice on setting up tests,https://www.reddit.com/r/selenium/comments/109gvcx/general_advice_on_setting_up_tests/,selenium,"Hello! I am pretty new to testing and Selenium and I feel as though I'm *not getting it*. 

I'm currently building an e-commerce portfolio app with Django; right now I have my accounts app set up to register new users, log them in/out, and delete their accounts. Presumably I'd like to test all those features in a script: load my app, create a new user, log that new user in, log them out, delete the account.

I've encountered a countless number of technical difficulties even performing one of these tasks. I've found the official documentation to be contradictory and confusing (maybe it's just me); every tutorial I've found so far has used outdated syntax and only delves into the most uselessly superficial tasks (loading a URL and that's it).

So I'd like some advice on where to go to figure out what the process is for testing what I'm aiming to test. **What's the general strategy for setting up these tests**? Are there any up-to-date resources available that focus on more useful testing processes?

For a specific example of a problem I'm encountering: how does one handle loading a different page during the test? I have been able to register a new user; on clicking ""submit,"" it takes them to a login page. How do I wait for the new login page to load before continuing? Implicitly waiting doesn't seem to do anything, but `time.sleep()` does.

Even if someone has a link to a repo that includes some tests in Python (especially if it's Django!) would be wonderful to see. I learn by example pretty well. Thanks for any advice.","['This is a hard one to answer, as there aren‚Äôt any specific problems posed.  \n\nFor the redirect to the new page, you are on the right track.  As a general rule I would be using a selenium wait on the WebElement that I was looking to use on the new page.\n\nThe general strategy may vary depending on tech used.  Currently I am using Cucumber with Selenium.  So I will write my test in Gherkin.  It‚Äôs BDD, so that fails, but with an error that tells me to implement the code.  I implement it and then write the next test.  All of my tests are independent, meaning that each test logs in, completes the test and logs out.  There is no dependency between tests.\n\nSome things you may want to look at (off the top of my head) are the selenium page object model, data injection to share your web driver, maybe a web driver factory if you are testing multiple browsers.\n\nI feel you.  The documentation you find around the web can be sparse, simple, and outdated, but it is out there.  Even what I have written here may be outdated as a newer version of Selenium has simplified the process of creating/using the webdriver.  I haven‚Äôt looked at that closely yet.']"
StaleElementReferenceException,https://www.reddit.com/r/selenium/comments/10900vs/staleelementreferenceexception/,selenium,"im using python3 selenium with firefox.

how can i avoid this particular exception? it seems like everytime i try to do a loop over elements i get this exception sooner or later.

&#x200B;

    data_and_resources_ul = driver.find_element(By.CLASS_NAME,'resource-list')
    csv_or_tsv_total = data_and_resources_ul.find_elements(By.CLASS_NAME,'format-label')
    for csv_or_tsv in csv_or_tsv_total:
            csv_or_tsv.click()
            time.sleep(1)
            navbar = driver.find_element(By.CLASS_NAME,'tabs--primary')
            all_buttons = navbar.find_elements(By.TAG_NAME,'a')
            back_to_dataset = [a for a in all_buttons if a.get_attribute('href').endswith('dataset')]
            back_to_dataset[0].click()
            time.sleep(1)

this is my code csv\_or\_tsv.click() takes me to a new page so new url then i will add more code there after that i press back\_to\_dataset\[0\].click() takes me to the previous page where csv\_or\_tsv\_total exists.

so my for loop should not fail because the same elements where gathered in the first place when i was on that page initially.

the for loop crashes on second iteration with StaleElementReferenceException

how can i fix this?","[""In my experience stale element means the DOM has changed due to asynchronous loading, and/or elements being updated somehow.\n\nI don't know python at all, but try to do some sort of exception catching and then re-build your list of elements to keep it current."", ""This was asked yesterday. My solution was to catch the exception and retry infinitely. It won't be stale forever. Most Devs are understandably scared of infinite loops though."", ""What is likely happening is that because csv_or_tsv is declared outside the loop, changes to the page are causing it to become stale and it can't find it again.\n\nIt might take longer for your script to run but you might be able to refresh your page as the first step inside the loop and see if that works."", 'conditional waits can help too.   https://www.testim.io/blog/selenium-wait-until-element-is-visible/', 'I write my tests in java, I do while loop with try/catch inside and re-initialisation of the element throwing the exception.']"
Dealing with StaleElementReferenceException error,https://www.reddit.com/r/selenium/comments/1086dfo/dealing_with_staleelementreferenceexception_error/,selenium,"Hi,

I am new to Selenium and I am getting a StaleElementReferenceException error but not sure why. I have tried to debug to no avail. It would be great if someone could point me to the issue. I have posted below links to the code on Gist and the stack trace as well. I have posted the code that contains the page object, the test and the stack trace.

NB: I have tried to link to the code I have posted on  Github Gist for easier reading  but it seems that Reddit will not allow external links in posts, which is unfortunate.  

[EditCustomer.java](https://EditCustomer.java)This is the page object.  

    package com.internetBanking.pageObjects;
    
    import java.time.Duration;
    
    import org.openqa.selenium.WebDriver;
    import org.openqa.selenium.WebElement;
    import org.openqa.selenium.support.CacheLookup;
    import org.openqa.selenium.support.FindBy;
    import org.openqa.selenium.support.How;
    import org.openqa.selenium.support.PageFactory;
    
    public class EditCustomerPage {
    	WebDriver driver;
    	
    	public EditCustomerPage(WebDriver driver) {
    		this.driver = driver;
    		PageFactory.initElements(driver, this);
    	}
    	
    	@FindBy(how = How.XPATH, using = ""//a[contains(text(),'Edit Customer')]"")
    	@CacheLookup
    	WebElement lnkEditCustomer;
    	
    	public void clickEditCustomer() {
    		lnkEditCustomer.click();
    	}
    	
    	
    	@FindBy(how = How.NAME, using = ""cusid"")
    	@CacheLookup
    	WebElement txtCustomerID;
    	
    	public void setCustomerID(String customerId) {
    		txtCustomerID.sendKeys(customerId);
    	}
    	
    	
    	@FindBy(how = How.NAME, using = ""AccSubmit"")
    	@CacheLookup
    	WebElement btnSubmit;
    	
    	public void submit() {
    		btnSubmit.click();
    	}
    	
    	
    	@FindBy(how = How.NAME, using = ""city"")
    	@CacheLookup
    	WebElement txtCity;
    	
    	public void custCity(String city) {
    		txtCity.sendKeys(city);
    	}
    	
    	public String getCustCity() {
    		return txtCity.getText();
    	}
    	
    	
    	@FindBy(how = How.NAME, using = ""state"")
    	@CacheLookup
    	WebElement txtState;
    	
    	public void custState(String state) {
    		txtState.sendKeys(state);
    	}
    	
    	public String getCustState() {
    		return txtState.getText();
    	}
    	
    	
    	@FindBy(how = How.NAME, using = ""sub"")
    	@CacheLookup
    	WebElement btnSubmitForm;
    	
    	public void submitForm() {
    		btnSubmitForm.click();
    	}
    	
    	
    	
    
    }
    

TC\_EditCustomer.java  This is the test

    package com.internetBanking.testCases;
    
    import java.io.IOException;
    import java.time.Duration;
    
    import org.testng.Assert;
    import org.testng.annotations.Test;
    
    import com.internetBanking.pageObjects.EditCustomerPage;
    import com.internetBanking.pageObjects.LoginPage;
    import com.internetBanking.utilities.XLUtils;
    
    public class TC_EditCustomer_004 extends BaseClass {
    	EditCustomerPage ec;
    	LoginPage lp;
    
    	@Test
    	public void EditCustomer() throws IOException, InterruptedException {
    		driver.manage().timeouts().implicitlyWait(Duration.ofSeconds(30));
    		driver.get(baseURL);
    		ec = new EditCustomerPage(driver);
    		lp = new LoginPage(driver);
    		
    		if (lp.iframeIsExists()) {
    			if (lp.iframeIsVisible()) {
    				logger.info(""GDPR popup displayed"");
    				System.out.println(""GDPR popup displayed"");
    				lp.switchToFrame();
    				lp.clickAccept();
    				lp.switchToDefault();
    			}
    		}
    
    		lp.setUserName(username);
    		lp.setPassword(password);
    		lp.clickSubmit();
    
    		ec.clickEditCustomer();
    
    		// retrieve customer number
    		String path = System.getProperty(""user.dir"") + ""\\src\\test\\java\\com\\internetBanking\\testData\\login.xls"";
    		String customerNumber = XLUtils.getCellData(path, ""Sheet1"", 1, 2);
    
    		// fill cust id and submit
    		ec.setCustomerID(customerNumber);
    		ec.submit();
    
    		// edit customer
    		ec.custCity(""Sheffield"");
    		ec.custState(""Yorkshire"");
    		ec.submitForm();
    
    		// dismiss alert
    		driver.switchTo().alert().accept();
    
    		// fill cust id and submit
    		Thread.sleep(5000);
    		ec.clickEditCustomer();
    		System.out.println(""Clicked Edit Cistomer"");
    		ec.setCustomerID(customerNumber);
    		ec.submit();
    		
    		//Verify if successfully edited
    		if(ec.getCustCity().equalsIgnoreCase(""Sheffield"") && ec.getCustState().equalsIgnoreCase(""Yorkshire"")) {
    			Assert.assertTrue(true);
    		}
    		else {
    			Assert.assertTrue(false);
    		}
    
    	}
    
    }
    

Stack Trace

    org.openqa.selenium.StaleElementReferenceException: stale element reference: element is not attached to the page document
      (Session info: chrome=107.0.5304.107)
    For documentation on this error, please visit: https://selenium.dev/exceptions/#stale_element_reference
    Build info: version: '4.5.0', revision: 'fe167b119a'
    System info: os.name: 'Windows 10', os.arch: 'amd64', os.version: '10.0', java.version: '11.0.11'
    Driver info: org.openqa.selenium.chrome.ChromeDriver
    Command: [ec39b1f7efd2e4cc6d31633d4c66d44b, sendKeysToElement {id=3c29de5c-eb57-4512-b455-b6a4bd6d35d6, value=[Ljava.lang.CharSequence;@3313d477}]
    Capabilities {acceptInsecureCerts: false, browserName: chrome, browserVersion: 107.0.5304.107, chrome: {chromedriverVersion: 107.0.5304.62 (1eec40d3a576..., userDataDir: C:\Users\fsdam\AppData\Loca...}, goog:chromeOptions: {debuggerAddress: localhost:50466}, networkConnectionEnabled: false, pageLoadStrategy: normal, platformName: WINDOWS, proxy: Proxy(), se:cdp: ws://localhost:50466/devtoo..., se:cdpVersion: 107.0.5304.107, setWindowRect: true, strictFileInteractability: false, timeouts: {implicit: 0, pageLoad: 300000, script: 30000}, unhandledPromptBehavior: dismiss and notify, webauthn:extension:credBlob: true, webauthn:extension:largeBlob: true, webauthn:virtualAuthenticators: true}
    Element: [[ChromeDriver: chrome on WINDOWS (ec39b1f7efd2e4cc6d31633d4c66d44b)] -> name: cusid]
    Session ID: ec39b1f7efd2e4cc6d31633d4c66d44b
    	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
    	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
    	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
    	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
    	at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.createException(W3CHttpResponseCodec.java:200)
    	at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.decode(W3CHttpResponseCodec.java:133)
    	at org.openqa.selenium.remote.codec.w3c.W3CHttpResponseCodec.decode(W3CHttpResponseCodec.java:53)
    	at org.openqa.selenium.remote.HttpCommandExecutor.execute(HttpCommandExecutor.java:184)
    	at org.openqa.selenium.remote.service.DriverCommandExecutor.invokeExecute(DriverCommandExecutor.java:167)
    	at org.openqa.selenium.remote.service.DriverCommandExecutor.execute(DriverCommandExecutor.java:142)
    	at org.openqa.selenium.remote.RemoteWebDriver.execute(RemoteWebDriver.java:547)
    	at org.openqa.selenium.remote.RemoteWebElement.execute(RemoteWebElement.java:257)
    	at org.openqa.selenium.remote.RemoteWebElement.sendKeys(RemoteWebElement.java:113)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
    	at org.openqa.selenium.support.pagefactory.internal.LocatingElementHandler.invoke(LocatingElementHandler.java:52)
    	at com.sun.proxy.$Proxy24.sendKeys(Unknown Source)
    	at com.internetBanking.pageObjects.EditCustomerPage.setCustomerID(EditCustomerPage.java:34)
    	at com.internetBanking.testCases.TC_EditCustomer_004.EditCustomer(TC_EditCustomer_004.java:57)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
    	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
    	at org.testng.internal.invokers.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:139)
    	at org.testng.internal.invokers.TestInvoker.invokeMethod(TestInvoker.java:677)
    	at org.testng.internal.invokers.TestInvoker.invokeTestMethod(TestInvoker.java:221)
    	at org.testng.internal.invokers.MethodRunner.runInSequence(MethodRunner.java:50)
    	at org.testng.internal.invokers.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:962)
    	at org.testng.internal.invokers.TestInvoker.invokeTestMethods(TestInvoker.java:194)
    	at org.testng.internal.invokers.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:148)
    	at org.testng.internal.invokers.TestMethodWorker.run(TestMethodWorker.java:128)
    	at java.base/java.util.ArrayList.forEach(ArrayList.java:1541)
    	at org.testng.TestRunner.privateRun(TestRunner.java:806)
    	at org.testng.TestRunner.run(TestRunner.java:601)
    	at org.testng.SuiteRunner.runTest(SuiteRunner.java:433)
    	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:427)
    	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:387)
    	at org.testng.SuiteRunner.run(SuiteRunner.java:330)
    	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)
    	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:95)
    	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1256)
    	at org.testng.TestNG.runSuitesLocally(TestNG.java:1176)
    	at org.testng.TestNG.runSuites(TestNG.java:1099)
    	at org.testng.TestNG.run(TestNG.java:1067)
    	at org.testng.remote.AbstractRemoteTestNG.run(AbstractRemoteTestNG.java:115)
    	at org.testng.remote.RemoteTestNG.initAndRun(RemoteTestNG.java:251)
    	at org.testng.remote.RemoteTestNG.main(RemoteTestNG.java:77)

&#x200B;","['""@CacheLookup"" is used to store the WebElements once they are located so that the same instance in the DOM can always be used. Basically it intsructs the InitElement() method to cache the element so you don\'t have to search for it over and over again, which is great if this element and the DOM aren\'t going to change. \n\nWhat this means is that if that element changes in any way or the DOM changes in any way which affects that element while you are interacting with this page your cached object reference will become stale. Instead you want to just find the object directly each time you are going to use it (In this case).', 'This could help\n\nhttps://www.softwaretestingmaterial.com/stale-element-reference-exception-selenium-webdriver/', ""I just catch that exception and retry infinitely until it finds it. Feels hacky, but works. It won't be stale forever.""]"
Targeting the discord chatbox,https://www.reddit.com/r/selenium/comments/106p9pt/targeting_the_discord_chatbox/,selenium," Hello, I'm a new selenium user and I'm trying to use selenium to make a script to help me generate images with MidJourney while I'm afk. So far I've only managed to get selenium with Mocha to log me in to discord and then change the url to my conversation with MJ. But now I have problems figuring out how to actually send data into the chat. It uses a div instead of an input field, so I'm guessing it's some kind of javascript involved.

Does anyone have any experience with entering messages into the discord app chat? It would be so nice if someone could give me a heads up on this one!","['No Idea about it, but you can use Selenium ide and record the action, to see which elements does it interact with.']"
Need help on getAttribute() method,https://www.reddit.com/r/selenium/comments/104shey/need_help_on_getattribute_method/,selenium,"Hi guys, need some help on getAttribute method - tho the attribute is present, it‚Äôs returning null. What might be the problem? Thank you in advance!","['Should I spin the wheel, or do I already have enough money to buy a line of code?  \n\nThis is a really hard puzzle without any clues.', 'Post your code please. For extra credit, post a link to the page that contains the element in question.', 'Looks like you\'re trying to run before you can walk.\n\nStart in the simplest form first of all.\n\nLocate your element.\n\nelement.getAttribute(""valid attribute here"").\n\nMake sure whatever you\'re looking for actually exists. You might be trying to return value instead of text etc.\n\nCan you give us the HTML of the element you\'re using?', 'Would something like this help? (This is in C#.)\n\npublic static Dictionary<string, string> GetAttributes(this IWebElement element) { const string script = ""var items = {};"" + ""for (index = 0; index < arguments\\[0\\].attributes.length; ++index) "" + ""{"" + ""     items\\[arguments\\[0\\].attributes\\[index\\].name\\] = arguments\\[0\\].attributes\\[index\\].value"" + ""}"" + ""return items;"";\n\n    return element.ExecuteJavaScript<Dictionary<string, string>>(script, element);\n\n}\n\npublic static T ExecuteJavaScript<T>(this IWebElement element, string script, params object\\[\\] args) {  // Execute client-side JavaScript on IWebElement with return type IWebDriver driver = ((IWrapsDriver)element).WrappedDriver; IJavaScriptExecutor js = (IJavaScriptExecutor)driver; return (T)js.ExecuteScript(script, args); }\n\nUgh! I can\'t get the formatting right...']"
Selenium for Java or Python - advice sought,https://www.reddit.com/r/selenium/comments/1044cgj/selenium_for_java_or_python_advice_sought/,selenium,"Hi, I am a fairly beginner programmer with a strangely specific set of skills as a QA engineer. I have maintained test suites in a previous jobs which included adding and updating test code in Laravel and a different one using java. 

I have never set one up from scratch though and am a bit more comfortable building from the ground up with python but I wanted to get some input on which framework is better for a media focused site (think something similar to like Spotify or something).

Thanks in advance for your thoughts.","['There are 3 things here:\n\n1-Using Selenium\n2-Using Java\n3-Using Python\n\n\nFirst use Selenium only if you are working with websites. Selenium does not work on apps on Laptops or mobile apps on which most media and Spotify apps work\n\nSecond, Java is a powerful language with many libraries but not as Powerful as Python when it comes to add on libraries for AI and Machine learning or even Data Analysis algorithms\n\nThird Python can be used well with Selenium just like Java, although Java libraries for selenium seem to be older, and therefore stable builds to use with Selenium']"
Run Python-selenium bot on Gitlab,https://www.reddit.com/r/selenium/comments/103w64j/run_pythonselenium_bot_on_gitlab/,selenium,"Hi everyone

Is it possible to run a python-selenium task automator on Gitlab 

Pardon me if this is a silly question, I'm pretty new here, dunno much about gitlab CI pipeline and stuff

Thanks in advance",[]
"where i can find real examples with selenium java, i mean real in production scripts to pr√°ctica, bye level (",https://www.reddit.com/r/selenium/comments/103pnth/where_i_can_find_real_examples_with_selenium_java/,selenium,"Tryng from beginner to advance
Sorry for My bad English guys
Cya and thx",['look at examples in github.  \nhttps://github.com/nusratahmed/maven-selenium-webdriver-testng-example-project/blob/master']
Python & Selenium - help / ideas,https://www.reddit.com/r/selenium/comments/102sxzq/python_selenium_help_ideas/,selenium,"Hi All,

This probably isn't the cleanest code anyone has seen but, currently I am looking for some help or even ideas.   This code I've made is a project for fun, reason why I made this is I like to travel and yes I get there are other things like Hopper and FlightTracker but wanted to try some things on my own.

&#x200B;

**Here is what the code does:** It goes to the [AA.com](https://AA.com) site > Searches for the airport I depart from and want to arrive > Enters in the travel dates > Searches for them > AA (Tells me the dates are incorrect) I tell it to hit the submit button again  and it works > Then it takes a screen shot of the  depart flight of the first half of the page, saves it in my downloads then  clicks on the first box because it is the cheapest > Then Takes a screenshot of a return flight and saves it to my download.

(I haven't put this code on reddit but if anyone wants it I can easily give it to them.)  The next steps are I have another script run a couple minutes after > Picks up the files I saved to my downloads > Attaches it to an email and then the email sends it to me)

&#x200B;

**What i'm trying to get help with is i'm trying to get rid of the old way screenshots and putting this info into an excel document, or even put text into an email with Flight number, Price, Date, Time... ETC but i've ran into a road block and i'm not even sure if this is possible. Would love some help if anyone has experience.**

&#x200B;

`from turtle import clear`
`from selenium import webdriver`
`from selenium.webdriver.common.keys import Keys`
`from selenium.webdriver.common.by import By`
`from selenium.webdriver.support.ui import WebDriverWait`
`from selenium.webdriver.support import expected_conditions as EC`
`import timeimport os`

`if os.path.exists(""C:/Users/Test/Downloads/AA/(Filename).png""):os.remove(""C:/Users/Test/Downloads/AA/(Filename).png"")else:print(""The file does not exist"")`

`if os.path.exists(""C:/Users/Test/Downloads/AA/(Filename2).png""):os.remove(""C:/Users/Test/Downloads/AA/(Filename2).png"")else:print(""The file does not exist"")`

`chrome_options = webdriver.ChromeOptions()chrome_options.add_argument(""--incognito"")driver = webdriver.Chrome(executable_path=""C:/Users/Test/Downloads/chromedriver_win32/chromedriver.exe"",options=chrome_options)`

#Variables
`ID1 = ""slice0Flight1MainCabin""`
`NAME = ""segments[0].orgin""`
`NAME1 = ""segments[0].destination""`
`NAME2 = ""segments[0].travelDate""`
`NAME3 = ""segments[1].travelDate""`
`NAME4 = ""closeBannerButton""`
`XPATH = ""//*[@id='flightSearchSubmitBtn']""`
`XPATH2 = ""//*[@id='slice0Flight1MainCabin']""`
`LINK_TEXT = ""https://www.aa.com/booking/find-flights""`

`driver.get(LINK_TEXT)`

`print(driver.title)`

`time.sleep(10)`

`button = driver.find_element(By.NAME, NAME4)`[`button.click`](https://button.click)`()`

`search = driver.find_element(By.NAME, NAME)search.send_keys(""PHX"")`

`search = driver.find_element(By.NAME, NAME1)`

`search.send_keys(""LHR"")`

`search = driver.find_element(By.NAME, NAME2)`

`search.send_keys(""09/20/23"")`

`time.sleep(5)search = driver.find_element(By.NAME, NAME3)`

`search.send_keys(""09/27/23"")`

`time.sleep(5)button = driver.find_element(By.XPATH, XPATH)`

[`button.click`](https://button.click)`()`

`#Sleep timertime.sleep(45)`

`button = driver.find_element(By.XPATH, XPATH)`

[`button.click`](https://button.click)`()`

`#Sleep timertime.sleep(20)`

`driver.execute_script(""window.scrollTo(0,500)"")driver.get_screenshot_as_file('C:/Users/Test/Downloads/AA/(FileName).png')`

`#Sleep timer`

`time.sleep(20)`

`button = driver.find_element(By.ID, ID1)`

`driver.execute_script(""arguments[0].click();"", button)`

`time.sleep(8)`

`driver.execute_script(""window.scrollTo(0,700)"")`

`driver.get_screenshot_as_file('C:/Users/Test/Downloads/AA/(FileName2).png')`

`driver.quit()`

&#x200B;

&#x200B;

Edit1: Weird spacing in my post","[""Firstly, for the code lookin' weird, you need to add 4 spaces to the beginning of each of your code lines to make it look good:\n\n    like this\n\nSecondly, you might want to check out the [csv](https://docs.python.org/3/library/csv.html) library in Python. It's built-in, so you already have it, and it speaks Excel by default. You can write a CSV with all your data and open it in Excel!"", 'I would read the text off the page with selenium, put it into whatever format you want with python (text, csv, whatever) and mail it.', ""Is there a reason you're doing this through the front end instead of the much faster and easier api calls?"", 'Where are all the NAME1-4 VARS VALUE COMES FROM?']"
Is it possible to create a HTML button to run my Selenium script?,https://www.reddit.com/r/selenium/comments/10289jw/is_it_possible_to_create_a_html_button_to_run_my/,selenium,I've been looking for the longest time wondering if this was even possible. I've been told that the way to do it is to setup a CI like Jenkins and run it via a API trigger. Is there anyway I can do this without having to run the API?,"['You can schedule your Jenkins job to run at a particular time without having to run via an  API trigger', 'Setting up Jenkins will also give you a button to run your build, which you can set up to just run your Selenium script... so you kinda get both. :)', 'Why do you need it on the html button? What about cron job']"
java error when using selenium,https://www.reddit.com/r/selenium/comments/101q3oe/java_error_when_using_selenium/,selenium,"i have been trying to fix a problem for a while. i am using eclipse luna which is an out-of-date version, I'm doing this so I can use larva but basically, I'm having an issue with setting up selenium. can anyone help me out?

code:

	 WebDriver driver = new ChromeDriver();

System.setProperty(""webdriver.chrome.driver"", ""C://Program Files//chromedriver//chromedriver.exe"");

	 driver.get(""[www.google.com](https://www.google.com)""); 

&#x200B;

error:

Exception in thread ""main"" java.lang.IllegalStateException: The path to the chromedriver executable must be set by the webdriver.chrome.driver system property; for more information, see [http://code.google.com/p/selenium/wiki/ChromeDriver](http://code.google.com/p/selenium/wiki/ChromeDriver). The latest version can be downloaded from [http://code.google.com/p/chromedriver/downloads/list](http://code.google.com/p/chromedriver/downloads/list)","['Set the system property before you instantiate the chrome driver. Basically move your second line of code up before the first line.', 'Add the system properties in Windows, then Exit and relaunch (not just restart) your IDE so that it can read the newly added system variables.']"
"[C#] How to resolve ""Cannot access a disposed object"" error",https://www.reddit.com/r/selenium/comments/zzf828/c_how_to_resolve_cannot_access_a_disposed_object/,selenium,"Hey, folks. I've got an error that keeps coming up in a variety of tests, seemingly at random. I'm sure it's not random, but I can't identify the pattern (and subsequently the fix).

For context I have 29 tests running on windows VMs through Azure DevOps. I've got it set to 10 threads (browsers) but I can change that.

The error comes from somewhere I wouldn't expect it. Basically, I'm waiting for the invisibility of an element. Something like:

>return wait.Until(ExpectedConditions.InvisibilityOfElementLocated(By.XPath(locator)));

or

>element.Click();

This isn't a complicated line of code, and generally speaking if it fails I would expect to get an exception. But ""Cannot access a disposed object"" doesn't really tell me what the problem is or how to resolve it.

&#x200B;

It's important to note that these tests don't fail when I run them on my machine against a browser (i.e. not in a VM). I'm not sure if it has something to do with timing, with threading. Any clues are appreciated.","[""If you run only one thread, does it happen also?\n\nI am asking because I saw this explanation for the same error message in a different [situation](https://www.appsloveworld.com/csharp/100/433/cannot-access-a-disposed-object-a-common-cause-of-this-error-is-disposing-a-con):\n\n> It happens because all dependencies in the main tread are disposed when its execution finishes and you're trying to access them in another thread. To deal with this situation you need to create a scope in your background thread and resolve AuthorizedServiceService there:"", 'Never got this error, and I also have ran Selenium on C# on Azure.\n\nHow are you initializing and disposing the driver?']"
Unable to pull element for resource,https://www.reddit.com/r/selenium/comments/zwrznr/unable_to_pull_element_for_resource/,selenium,"Hey there yall! I've been trying to pull a element  from the following line of code: ```
<span tabindex=""0"" role=""link"" class=""regular-login-link clickable"">Regular Login</span>
``` and then have selenium click it. Issue is, it always says that it cant find the element. Doesn't matter if I try to use xpath, css selector, class name, nothing. `driver.find_element(By.CSS_SELECTOR, "".sso-login"").click()` Is the current line that tries to pull it, and then click it.","['Where are you getting "".sso-login""? The element in question doesn\'t have that class attribute, so it\'s not surprising Selenium can\'t find the element using that CSS selector. Try something like ""span.regular-login-link""', ""Three things come to mind:\n\n1) Have you tried using a javascript executor to click the element?\n\n2) Have you tried using some waits that return booleans (isclickable, exists, stuff like that) To make sure you've got it right?\n\n3) Is it in an iframe?""]"
Youtube Ad Detector,https://www.reddit.com/r/selenium/comments/zwarjd/youtube_ad_detector/,selenium," I‚Äôve been trying to use python selenium to watch YouTube videos for me and collect data. Getting the data is fairly easy, however, I run into problems when an ad pops up in YouTube. 

 For some reason, I can't figure out how to detect whether or not I have an ad.

  My current function is: 

def check\_ad():  try:             

WebDriverWait(driver, 20).until(         EC.presence\_of\_element\_located(driver.find\_element\_by\_xpath('//\*\[@id=""simple-ad-badge:g""\]'))             )           

print(""Ad detected"")        

 except:            

 print(""No Ad"")

Does anyone know any other way I can do this?","['Why not use Adblock instead?', 'Just do what I do and get YouTube premium family slot for a lot cheaper in Etsy or eBay. I was able to get 12 months for $50 and it‚Äôs been working perfectly fine for 4 months now.This is where I got it from  \nhttps://gameflip.com/profile/us-east-1:75bddc30-362e-4cf8-809c-286b43724d3f/john-a']"
How To Story an Instagram selenium and python,https://www.reddit.com/r/selenium/comments/ztw9h6/how_to_story_an_instagram_selenium_and_python/,selenium,"hi

please help me

I use

`mobile_emulation = {""deviceMetrics"": { ""width"": 412, ""height"": 914, ""pixelRatio"": 3.0 },""userAgent"": ""Mozilla/5.0 (Linux; Android 4.2.1; en-us; Nexus 5 Build/JOP40D) AppleWebKit/535.19 (KHTML, like Gecko) Chrome/41.0.1025.166 Mobile Safari/535.19"" }`

`chrome_options.add_experimental_option(""mobileEmulation"", mobile_emulation)`

But after sending with the message

 `rotate your device to add to your story`",['Share the full code']
"C# - Element.Click() returns error, after waiting for element to be clickable.",https://www.reddit.com/r/selenium/comments/ztqe7u/c_elementclick_returns_error_after_waiting_for/,selenium,"Hey, folks. I'm losing my mind on this one. I have this block of code:

>getWaitUtils.waitForClickabilityOfElement(GetElement(elementName));  
>  
>GetElement(elementName).Click();

The first line uses this:

>return wait.Until(ExpectedConditions.ElementToBeClickable(givenElement));

So I have an element (IWebElement, since I'm in C#). I wait for that element to be clickable. That line passes. The next line attempts to click the element (that selenium has confirmed is clickable). I get an error:

>OpenQA.Selenium.ElementClickInterceptedException: element click intercepted: Element is not clickable at point (1173, 1113)

I don't get it. What's the point of the wait if the element can't be clicked? What do?","[""There's probably other element over the element you want to click.\nCreate a try/catch and take a screenshot in the catch. See if there's any other element over it."", 'Try javascript click which overlooks some element padding', 'I can shed some light here. Until ElementToBeClickable  does basically 3 things.  It\'ll make sure the element gets found (exists), then it will check element element.isDisplayed() (is visible)   and element.isEnabled() \n\nIf all 3 are true then it passes.  enabled is pretty reliable but ""is displayed?"" what does it mean to be ""visible""? dunnow. that\'s up to the webdriver to decide. if a transparent element overlaps a button is it still visible? if an element only partially overlaps is it visible? if it\'s off screen is it visible? ¬Ø\\\\\\_(„ÉÑ)_/¬Ø\n\n\nnext I\'m going to guess this is chrome. which seems to be terrible at deciding where an element is when you call WebElement.Click().  Sometimes where on the element it decides to click doesn\'t actually line up with where it\'s rendered.  So adjacent elements seem to intercept the click even when nothing overlaps. \n\nwe use Java not C# but you can use an ""Action"" instead of just Element.click which often moves the mouse to the correct location \n\n        final Actions actions = new Actions(driver);\n        actions.moveToElement(elm).click().perform();\n\n\nwe also use a scroll script to make sure the element is on the screen. hasn\'t been a problem in a while but a while back clicks would fail because the element was out of view. \n\n    ((JavascriptExecutor) driver).executeScript(""arguments[0].scrollIntoView(true);"", elm);', ""Other have posted this but it sounds like there is something overlapping the element you want to click.  In the error does it tell you anything about the element that is intercepting the click?  It's been a minute since I had this specific error but I think I recall the full error containing some info about the element that would receive the click.\n\n&#x200B;\n\nIf that info is available check the console to see what that element is and maybe that will lead you to your answer.  Something else I've had some success with is using Ignore Exceptions during my waits so that if an interception is encountered then the wait just fails and starts the loop again.  Hope you get it solved!""]"
Flush all like buttons,https://www.reddit.com/r/selenium/comments/zrmis1/flush_all_like_buttons/,selenium,"Hello, 

I need help with iterating some like buttons on my LinkedIn feed. I was able to use the contains ""like"" descriptor to find all the buttons and scroll the page, but my current function keeps clicking the 1st like button even though it is not visible any longer. I have attempted to flush the variable, but the driver retains the original button as its main. Snippet below: 

&#x200B;

`def rerun():`  
 `print('running like function ')`  
 `all_buttons = buttons = driver.find_elements('xpath', ""//button[contains(.,'Like')]"")`  
 `like_buttons = [btn for btn in all_buttons]`  
 `while len(like_buttons) >= 1:`  
`for btn in like_buttons:`  
`driver.execute_script(""arguments[0].click();"", btn)`  
`driver.execute_script(""window.scrollBy(0,3000)"","""")`  
`time.sleep(2)`  
`del like_buttons`  
`del all_buttons`  
`print('bot is liking')`  
`rerun()`","[""Could you format your code in a single code block instead of all separate lines? Currently it's difficult to parse your code because you've lost the indentation."", 'Make it a do while statement and put your do at the very top so it finds the elements that only match the liked elements and then completes your actions.']"
"finding chromedriver, glibc version compatibility",https://www.reddit.com/r/selenium/comments/zr09jq/finding_chromedriver_glibc_version_compatibility/,selenium,"I'm trying to set up a webscraper in an amazon-linux terminal and I'm having issues with chromedriver glibc compatibility. 

&#x200B;

I'm currently using chrome and chromedriver version \~108. So I decided to try installing chrome and chromedriver 102. I still get the same error and the list of versions to try is too huge to trial and error this. 

&#x200B;

My glibc version is 2.26-62.amzn2   ...   and it seems more awkward to change that than to use older chromes. 

&#x200B;

&#x200B;

Below is the error message when chromedriver tries to open.

&#x200B;

        Traceback (most recent call last):
          File ""/home/ec2-user/.local/lib/python3.7/site-packages/selenium/webdriver/common/service.py"", line 97, in start
            path = SeleniumManager().driver_location(browser)
          File ""/home/ec2-user/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py"", line 74, in driver_location
            result = self.run((binary, flag, browser))
          File ""/home/ec2-user/.local/lib/python3.7/site-packages/selenium/webdriver/common/selenium_manager.py"", line 93, in run
            raise SeleniumManagerException(f""Selenium manager failed for: {command}. {stderr}"")
        selenium.common.exceptions.SeleniumManagerException: Message: Selenium manager failed for: /home/ec2-user/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager --browser chrome. /home/ec2-user/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager: /lib64/libc.so.6: version `GLIBC_2.29' not found (required by /home/ec2-user/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager)
        /home/ec2-user/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager: /lib64/libc.so.6: version `GLIBC_2.28' not found (required by /home/ec2-user/.local/lib/python3.7/site-packages/selenium/webdriver/common/linux/selenium-manager)
    

&#x200B;

How can I find chromedriver glibc version compatibility requirements / How can I find which version of chromedriver I need?","['This submission has been removed because it looks suspicious to automod (c). If this was done in error, please [message the moderators](https://www.reddit.com/message/compose?to=%2Fr%2Fselenium&subject=about my removed submission&message=I‚Äôm writing to you about my submission that was removed (l). %0D%0DMy issue is...).\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/selenium) if you have any questions or concerns.*', 'Do you specify path to chromedriver in `webdriver.Chrome()` of your Python script?']"
"I am trying to detect audio after playing an audio file in a page, want to check if audio is playing or not, if there anyway I can check if audio is playing ?, also in tab it shows ""tab is playing audio"" is there any way to extract that message from tab?",https://www.reddit.com/r/selenium/comments/zqthg7/i_am_trying_to_detect_audio_after_playing_an/,selenium,,"[""Untested!\n\n```\nfrom selenium import webdriver\n\ndriver = webdriver.Chrome()\ndriver.get('http://www.example.com/audio-page.html')\n\n# Find the audio element on the page\naudio_element = driver.find_element_by_css_selector('audio')\n\n# Check if the audio is playing\nif audio_element.get_attribute('paused') == 'false':\n    print('Audio is playing')\nelse:\n    print('Audio is not playing')\n\ndriver.quit()\n```""]"
Custom profiles of chrome not running in multithreading,https://www.reddit.com/r/selenium/comments/zqnu0i/custom_profiles_of_chrome_not_running_in/,selenium,"Hi Everyone,

I have an issue ongoing, I am trying to run custom chrome profiles with selenium,

The issue is that a single profile runs fine but when I use ThreadPoolExecutor, and open like three chrome profiles in parallel, one out of them works fine but the rest two do not do anything, they are just like halted. The code is concerned  is as follow:

`def browserthread(link):`  
 `i=links.index(link)`  
 `chrome_options = webdriver.ChromeOptions()`  
 `chrome_options.add_argument(""user-data-dir=C:\\Users\\LENOVO\\AppData\\Local\\Google\\Chrome\\User Data"")`  
 `chrome_options.add_argument(f""--profile-directory=Profile {str(i+1)}"")`  
 `driver = webdriver.Chrome(options=chrome_options)`  
 `drivers.append(driver)`

`with ThreadPoolExecutor(max_workers=threadnum) as pool:`  
 `response_list = list(pool.map(browserthread,links))`  
`drivers.clear()`

If multiple threads are run without profile specification, than all the chrome instances work fine, but when three profiles are opened in separate threads, only one instance works fine meanwhile other two remain halted.

Please help if you know a solution to this issue, thanks in advance.",[]
Why I can't find an element with time sleep but with webdriverwait the element appears,https://www.reddit.com/r/selenium/comments/zox3xu/why_i_cant_find_an_element_with_time_sleep_but/,selenium,"Why I can't find an element with time.sleep even with 100 seconds wait but with webdriverwait the element appears with even much less wait time, what's the mechanism behind it","[""This is an impossible question to answer given the info you've provided."", ""The way you've written it, it seems like sleep will only look once but webdriverwait looks in intervals. Am I misunderstanding?"", ""WebDriverWait typically polls the element at a specified interval so if you're waiting for 10s and polling every 500ms, you'll poll 20 times, maybe that's why. You really need to give more information and context though.\n\nThe mechanism is roughly the same to my knowledge, one sleeps the thread while the other continuously polls and can look for a specific condition. WebDriverWait is the one you should use and that's best practice. Time.sleep is generally bad practice and shouldn't really be used."", ""It's often the opposite. Are you on Java or Python? What exception do you get?""]"
XPATH returns WebElement object has no attribute aka not found,https://www.reddit.com/r/selenium/comments/zorev8/xpath_returns_webelement_object_has_no_attribute/,selenium,"I'm going nuts if I search for an xpath with $x() in the console inside the selenium browser it finds the element but when I do the same code with .find\_element in the script it keeps returning no element found (even if I do repeated searches with the Actions class).. what's going on here...

p.s. it's on Facebook website but it's a pop up that only shows on my account as it's a bug (See previous post of mine)","[""Two silly questions:\n\nIf it's in a popup are you switching scope from the main tab to the new window?\n\nAnd is it in an iframe?""]"
click on a pop up that appears on every page in Facebook,https://www.reddit.com/r/selenium/comments/zngys9/click_on_a_pop_up_that_appears_on_every_page_in/,selenium,"**Introducing cross-app messaging**

[**https://imgur.com/a/kTwj8xB**](https://imgur.com/a/kTwj8xB)

this pop up appears on every page now.. I need to get rid of it for running some scripts using selenium.. I tried get rid of it in the setting but there's nothing to remove it.. thank you","['having the same problem starting today', 'What exactly are you trying to do? What exactly have you tried? Please provide an example of what you are stuck on about handling a pop up and we will attempt to help you.', 'Add a listener when the button appears and click it.', 'Check if button exists and click it constantly, sideload an adblock extension and block the element altogether, evaluate some JS that removes it/click it whatever your choice how to handle it.', 'I found it easier using the mobile version, m.facebook.com', ""When clicking on 'Done' is it saved in a cookie or local storage? If so, just set it there so it does not appear"", ""You could maybe do a javascript injection to get rid of the window if that's what you need.""]"
Help Delaying Selenium Script,https://www.reddit.com/r/selenium/comments/zn591n/help_delaying_selenium_script/,selenium,"Hey guys, I wanted to know if anyone knew how to delay a selenium script so I can manually type something into a website and then, when I'm ready, have my selenium automation run. I use selenium in python(I've seen java versions and stuff). I already tried making an if statement with a user input as the condition but that didn't work very well.","[""What's the reason for typing something in manually instead of automating it?"", 'Maybe use thread sleep? Or what happens after you enter the text that you want? Does a success message appear or something like that? Maybe you can wait for that', 'https://selenium-python.readthedocs.io/waits.html']"
"How to handle Chrome's ""Reload site?"" window?",https://www.reddit.com/r/selenium/comments/zmp1ee/how_to_handle_chromes_reload_site_window/,selenium,"For context: I'm using Selenium 4.5.3 on Java and I've got a Mac. The browser is Chrome as the title suggests.

It happens on a JS app whenever I do some unsaved changes, then want to reload.

The exception I'm getting is:

    org.openqa.selenium.UnhandledAlertException: unexpected alert open: {Alert text : } 

However, when I use the in-built driver.window().alert() function, I'm told that there is no such alert!

It's not really counted as a window either - when I print out the output of driver.getWindowHandles(), I only see the one page.

I've tried just making a new Actions() object and clicking the Enter or Escape key to see what happens. Nothing.

I've also added --disable-notifications and --disable-popup-blocking, but nothing works.

Have you had this issue before and how did you solve it?

***Edit - Sort of solved:*** So, I still have no way of dealing with this, but what I've noticed is that you only get this sort of interaction if you use the actual browser. If you navigate using a link on the page, you get a pop-up which can be handled with the above options so that's how I'll do this going forward. Hope that helps!",[]
Custom Chrome Profile not opening in Selenium,https://www.reddit.com/r/selenium/comments/zmpvy4/custom_chrome_profile_not_opening_in_selenium/,selenium,"Hi everyone,

I am facing a problem for days with selenium in opening a custom-made profile, I am using the following line of code to open it but failing:

`chrome_options.add_argument(""user-data-dir=C:\\Users\\LENOVO\\AppData\\Local\\Google\\Chrome\\User Data\\Profile 1"")`

In order to open the default profile it just needs to remove the last part of the path, like this:

`chrome_options.add_argument(""user-data-dir=C:\\Users\\LENOVO\\AppData\\Local\\Google\\Chrome\\User Data"")`

It opens the default profile successfully but whenever I try to open a custom-made profile it opens the chrome with native selenium setting,

How can this issue be resolved?

Thanks in advance.","['I believe selenium by default still looks for the default profile there, so the trick is to delete profile 1 and rename the desired profile to profile 1.']"
Different ways to get xpath elements and CSS selectors,https://www.reddit.com/r/selenium/comments/zmdhwr/different_ways_to_get_xpath_elements_and_css/,selenium,"I would like to expand my knowledge on this because sometimes I'm struggling with myself due to the website I'm trying to automate, always changes every time I refresh it.

And in your opinion what's the best option to use, CSS selector or XPATH","[""It's contentious.\n\npersonally, I do everything with xpath. For a few reasons. Firstly, I've never found an element I couldn't get with xpath. Secondly, xpath allows me to navigate a DOM's hierarchy at will. And lastly, since xpath satisfies the first two, I don't feel the need to remember any extra syntax.\n\nI have heard it said it's slower. If so, it's measured in milliseconds and the several hundred thread.sleeps left over in the framework from the devs before me are of much greater concern than me using xpath."", ""I personally do everything with CSS because you can do the same things you can do with xpath, but it looks cleaner.\n\nAll you need is a cheatsheet like this: [https://htmlcheatsheet.com/css/](https://htmlcheatsheet.com/css/)\n\nThen go to a random website, open the developer console and try to find things in there. The find within the Developer Console matches CSS selectors, so it's a quick and easy way to learn how to use them. I imagine the same works for XPath, but again, my personal preference is CSS."", ""CSS selectors, the DOM can change just like you mentioned. An ID, Name, or Class is less likely to change. The goal of automation is to be quick, dependable, and have low maintenance. If you're using those properties in XPath then you're adding additional time, even if it appears negligible."", ""When using xpath you can select based in relative elements, maybe inside exactly three divs and a ul, or maybe the div has always a aria prop that only your data posses \n\nThat's where xpath shines"", 'What if the text on the page remains the same but the xpath changes?']"
"ElementNotInteractableException: Message: Element <span class=""selection""> could not be scrolled into view",https://www.reddit.com/r/selenium/comments/zmk7hr/elementnotinteractableexception_message_element/,selenium,"    select_span = driver.find_element(By.CLASS_NAME,'selection')
    select_span.text
    select_span.click()

i found the element i want and select\_span.text give me the text inside `<span class=""select2-selection__rendered"" id=""select2-indicatorDropdown-container"" role=""textbox"" aria-readonly=""true"" title=""Experienced violence since COVID-19"">Experienced violence since COVID-19</span>`

which is 'Experienced violence since COVID-19' but if i do select\_span.click() to click on this span and open the selection i get :

    ElementNotInteractableException: Message: Element <span class=""selection""> could not be scrolled into view

i keep getting this error almost daily and i never understand why..

there is no shadowroot here or iframe or anything since i got the element anyway, but when i try to click it i get this error why?? it happens to almost everything i try to click.

PS: i use python selenium and firefox browser","['In Java you need to scroll to that element then thread.sleep or wait.until so it can be clickable or whatever you neeed to do with element. So I guees you have something like that in Python', 'Instead of `select_span.click()` try \n\n    driver.execute_script(""arguments[0].click();"", select_span)\n\n\nA bit of javascript passed to the browser I think. Looks odd but it\'s been handy for me.', ""Hi as per [test automation services](https://www.qasource.com/automation-testing-services), the possible solutions for this one are:  \na) You need to check whether the locator you are using is correct or not.  \nb) If the locator is correct, scroll to the element where you want to perform the click operation. In javascript, you can scroll to a certain block by defining the block where you want to scroll {center, end or start block).   \nc) Once you have scrolled to the element put some wait there you can use implicit wait if that doesn't work try the pause method for some seconds and see if that works or not and perform the click operation.\n\nHope You find it useful!""]"
"Python-Selenium, what how can i detect this string?",https://www.reddit.com/r/selenium/comments/zlqxdb/pythonselenium_what_how_can_i_detect_this_string/,selenium,"Hi, I have an element that looks like this:

    <label class=""ui-selectchekboxmenu-label ui-corner-all"">Foobar</label>

How is Foobar detectable with something like this:

    expected_conditions.element_to_be_clickable((By.XPATH, ""Foobar"")))

Of course, not literally that, since the xpath is not only ""Foobar"" but I am trying to make the code work even if the element number changes or something like that due to a software update in the future.","[""//label[contains(text(), 'Foobar')]"", 'Just took a look at your previous comment - you need to surround the locator string with quotes, as it\'s a string argument.\n\n`\'//label[contains(text(), ""Foobar"")]\'`', 'Its just nice to sometime read about someone helping someone on py selenium stuff. Hiks', 'Everyone here suggested querying with text, I would also propose to query the element using ancestor and sibling tags that you think would always be there around the this Foobar element, in addition to using text of course, to make your selector more robust and resistant to changes.']"
How do I wait for css selector to click?,https://www.reddit.com/r/selenium/comments/zlorlo/how_do_i_wait_for_css_selector_to_click/,selenium,"Hi, I have a monitoring script in Python + Selenium. Right now I use a lot of xpath and id to click and it is annoying because the frameworks used sometimes changes the id and xpath, so I would like to look for something that will stay the same for a longer time.

I figured CSS selector content could be nice, they seem to be named after what they really do in the application I monitor.

I tried to google it but I found no examples I understood how I could convert.

Right now my function looks like this, how can I modify that to use css selector?:

    def wait_for_xpath_click(params, element_xpath):
    	temp_element = WebDriverWait(browser, 60).until(
    		expected_conditions.presence_of_element_located((By.XPATH, element_xpath))
    		)
    	time.sleep(5)
    	temp_element.click()

Edit: I got it now:
It needs to look like this:

    expected_conditions.element_to_be_clickable((By.CSS_SELECTOR, selector)))","['Nice for figuring it out can you give me an actual example of a real code please', ""You need to change the third line from By.Xpath to By.css, then enter the css right after. That's really all there is to it! Xpath, class, css, id can be used interchangeably, you just need to change the By.XXX function to match it, e.g. By.class, By.tag, By.id, By.css, etc.""]"
Simple class wont work,https://www.reddit.com/r/selenium/comments/zk5tw2/simple_class_wont_work/,selenium,"Can someone tell me, what have i done wrong here? 

Im very new to python and selenium FYI.

&#x200B;

    from selenium import webdriver
    from selenium.webdriver.chrome.service import Service
    
    class Open (webdriver.Chrome):
        def __init__(self, path=Service(""C:\Selenium\chromedriver.exe"")):
            self.path = webdriver.Chrome(service=path)
            super(Open,self).__init__()
    
        def landFP(self):
            self.get(""https://www.facebook.com/"")
    
    page = Open()
    page.landFP
    

The outcome is not facebook page. im loss. help","[""What's the outcome? Please describe the error"", 'You aren‚Äôt calling your landFP method, add () to the end of page.landFP']"
Help me with selenium,https://www.reddit.com/r/selenium/comments/zjljgg/help_me_with_selenium/,selenium,Hello! I have a technical research paper about selenium that i need to go through and i don't have knowledge of selenium. Could someone help me with it? It's nothing in depth. It's just about an experiment to replace sleep threads in selenium with something else. Thank you,"['Funnily enough I just started a new job where their test suite has about 800 thread.sleep\'s i need to remove. DM me and I\'ll see if I can help.\n\nSide note: The ""something else"" is explicit waits. (wait.until(expectedcondition...))', ""Adding to what was already discussed above: It is better to write a wrapper for every inbuilt selenium methods such as click, enterText etc which internally calls wait.untill(elements is displayed) so that you don't have a dependency on sleep. Further optimisation would be adding polling every nth second (user defined) in is element displayed method.""]"
Scrapping of a trading website.,https://www.reddit.com/r/selenium/comments/zh2ad9/scrapping_of_a_trading_website/,selenium,So I was on [gocharting.com](https://gocharting.com).. trying to scrap some data... but I cannot find the elements of the chart in html file. There are divs but I cannot find the numbers & I'm not sure how to handle that. If anybody has any idea please let me know.,"['Picture what u want to scrape exactly would help', 'Try Selenium IDE to map the elements.']"
Selenium Modules,https://www.reddit.com/r/selenium/comments/zfjdxw/selenium_modules/,selenium,"Hi fellow automation geeks.

If im making any sense, can you guys point me to a website or any reference that i can check for:

All the Selenium's modules, for example we all know webdriver module.

Like for example when we want to user the webdriver module we write

 

    from selenium import webdriver
    
    driver = webdriver.Chrome(""your path"")

and when you want to find elements you will use 

    from selenium.webdriver.common.by import By
    
    driver.find_element(By.XPATH, '//button[text()=""Some text""]')

i want to know where can i read about all the modules. like webdriver modules, and BY modules(if its a module) and common modules(if its a module).

Thnks again",['I will point you to the official docs selenium.dev']
Getting a NoSuchElementException when trying to dismiss popup,https://www.reddit.com/r/selenium/comments/zeziub/getting_a_nosuchelementexception_when_trying_to/,selenium,"I am testing a demo website for practice and I am receiving an error when trying to dismiss a cookie permissions popup (not really a popup but an iframe). The popup only appears once in an open browser session and will only appear if you close the browser and reopen website. I am testing logins using test data from an xls, so when the  webpage is opened, it dismisses the cookie popup logs in and then logs out and then attempts the next login in the xls. It tries to look for the cookie popup which will not appear as we have not closed the browser. I have written an 'if' statement that checks for the popup, to dismiss popup if it appears or continue as normal if it doesn't. But it does not continue and then fails the test.  I would like some help on what is causing this.

Here is the error message:

**org.openqa.selenium.NoSuchElementException: no such element: Unable to locate element: {""method"":""css selector"",""selector"":""#gdpr\\-consent\\-notice""}**

Here is a link to the code for the test. The If statement is on line 23.

[https://gist.github.com/fdama/5a73c1f95319f09266120dd658b425cc](https://gist.github.com/fdama/5a73c1f95319f09266120dd658b425cc)

Thanks in advance.","[""Well, the error is on the function iframeIsVisible, but the code you linked there's no description of this function.\n\nWe need to see the function to see if we can notice anything wrong.""]"
Java selenium Textarea/iFrame help,https://www.reddit.com/r/selenium/comments/ze4n7p/java_selenium_textareaiframe_help/,selenium,"I have problem of locating and entering any text into ""Content"" field on some blog using java selenium webdriver. It seems like textarea but when inspected, textarea is hidden and iFrame document is what I need to somehow locate and sendKeys there. So basicaly I need somehow to click on <p> under <body> of that document under iFrame which I dont know how. Everything I tried bring me Exceptions NoSuchElement or NotClickable. I would appreciate any suggestion based on exeperience, thanks.","['To interact on an element inside on an iframe, you need to switch to the iframe prior to the interaction.\n\nCode:\n\ndriver.switchTo().frame(0)\n\n--Switch to the first iframe of the page\n\ndriver.switchTo().frame(‚Äúid of the element‚Äù)\n--Switch to the frame that has that id.\n\nhttps://www.guru99.com/handling-iframes-selenium.html', ""Welcome to the nightmare that is frames. Wait until you work with a website that utilizes 10+ nested frames, it's soul crushing.""]"
How do I bulk add a bunch of commands to Selenium?,https://www.reddit.com/r/selenium/comments/ze7l5j/how_do_i_bulk_add_a_bunch_of_commands_to_selenium/,selenium,"I was using Excel & iMacros to do this before.  Basically, I have a list of employee ID #s that need to be clicked, by their Link ID (not by their name).  So for example, in iMacros I'd send the command:
TAG POS=1 TYPE=A ATTR=ID:Link_123456

In that example, the employee's ID # was 123456.

I'd have a whole list of IDs, so I'd just use excel to merge the ""123456"" with ""TAG POS=1 TYPE=A ATTR=ID:Link_"" to make ""TAG POS=1 TYPE=A ATTR=ID:Link_123456""

iMacros doesn't work anymore and has been discontinued.

In Selenium IDE, it would be:
Command ""click""
Targer ""id=Link_123456

That's what I'd need it to do.

Now, how do I bulk add a bunch of IDs for each one to be clicked?  Can I do it in excel and then import those commands to Selenium?  I know how to manually add them one by one in Selenium, but I've got hundreds that need clicked.  Plus it's different everyday, so I'll have a new list of IDs that need to be clicked each day.

How do I bulk add new commands each time?","['I would look at data driving your tests, either using Excel or JSON and create map of KVPs and iterate that way.']"
Beginner's guide to web automation,https://www.reddit.com/r/selenium/comments/zd7zgd/beginners_guide_to_web_automation/,selenium,"Hi everyone, this is my first time in reddit, as well in this subreddit.

Basically I'm confused, I don't know where to start with web automation. I've been searching the web but I still have a hard time understanding where does ""Selenium"" fit in the whole picture. I don't have a whole picture btw. I have experience on scripting in Linux, and with networking. But the web is still an unexplored territory and I need to be able to write basic scripts that can access links, fill login details and retrieve data.  

Any definition, any book, any resources are useful for me right now, either to understand what selenium is, or to get an idea about the whole concept of web automation.","['Google is your best friend. Lots of stuff on YouTube or Udemy', ""Not entirely sure what you're looking for here, but I'll give it a shot:\n\nIf you're familiar with linux scripting, then selenium isn't much different.  Basically with selenium you can do anything on a website that a user can do.  So it's used for automation and also for user testing (many companies use it to run regression testing on their apps/websites when doing updates or feature changes).\n\nThe selenium documentation is good, but your best bet is to try making a test script to do something simple (log in to website, click some stuff, submit a form, logout).  Then iterate your code while you learn until you get it to do what you want.  Then come back here with your code and let people tell you how it could be done differently / simpler / more-compact.  Iterate on your code again and then you'll have a decent grasp.""]"
'sendKeys' but in Javascript,https://www.reddit.com/r/selenium/comments/zckj6g/sendkeys_but_in_javascript/,selenium, Is there a Javascript version of Selenium's 'sendKeys' method? Setting value won't work as the website doesn't think you've inputted data in the field in order for the sign in button to be enabled.,"['Maybe the input field is in iframe', 'Set the value to the correct element and then you may need to trigger an event\n\nLook at dispatchEvent that may be the issue']"
"some problems with find_element(By.NAME,""value"")",https://www.reddit.com/r/selenium/comments/zcduid/some_problems_with_find_elementbynamevalue/,selenium,"I'm working on a script using selenium that can login automatically login my college's imformation system.

Here's the code:
```python
from selenium import webdriver
from selenium.webdriver.common.by import By

from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager

# from selenium.webdriver.edge.service import Service as EdgeService
# from webdriver_manager.microsoft import EdgeChromiumDriverManager

driver = webdriver.Chrome(service = ChromeService(executable_path = ChromeDriverManager().install()))

# driver = webdriver.Edge(EdgeChromiumDriverManager().install())

driver.get(""http://stucis.ttu.edu.tw/stucis.htm"")

ID = ""studentid""
PASS = ""password""

ID_input = driver.find_element(By.NAME,""ID"")
PWD_input = driver.find_element(By.NAME,""PWD"")

ID_input.send_keys(ID)
PWD_input.send_keys(PWD)

driver.close()
```
and it comes with erros
```
Traceback (most recent call last):
  File ""C:\Users\USER\Desktop\Crawler\login_stucis.py"", line 19, in <module>
    ID_input = driver.find_element(By.NAME,""ID"")
  File ""C:\Users\USER\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\selenium\webdriver\remote\webdriver.py"", line 861, in find_element
    return self.execute(Command.FIND_ELEMENT, {""using"": by, ""value"": value})[""value""]
  File ""C:\Users\USER\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\selenium\webdriver\remote\webdriver.py"", line 444, in execute
    self.error_handler.check_response(response)
  File ""C:\Users\USER\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\selenium\webdriver\remote\errorhandler.py"", line 249, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {""method"":""css selector"",""selector"":""[name=""ID""]""}
  (Session info: chrome=108.0.5359.95)
Stacktrace:
Backtrace:
        (No symbol) [0x00CBF243]
        (No symbol) [0x00C47FD1]
        (No symbol) [0x00B3D04D]
        (No symbol) [0x00B6C0B0]
        (No symbol) [0x00B6C22B]
        (No symbol) [0x00B9E612]
        (No symbol) [0x00B885D4]
        (No symbol) [0x00B9C9EB]
        (No symbol) [0x00B88386]
        (No symbol) [0x00B6163C]
        (No symbol) [0x00B6269D]
        GetHandleVerifier [0x00F59A22+2655074]
        GetHandleVerifier [0x00F4CA24+2601828]
        GetHandleVerifier [0x00D68C0A+619850]
        GetHandleVerifier [0x00D67830+614768]
        (No symbol) [0x00C505FC]
        (No symbol) [0x00C55968]
        (No symbol) [0x00C55A55]
        (No symbol) [0x00C6051B]
        BaseThreadInitThunk [0x761A6939+25]
        RtlGetFullPathName_UEx [0x77B08FD2+1218]
        RtlGetFullPathName_UEx [0x77B08F9D+1165]
```
Some fourms says it is becaust the driver's version is different.
I also tried:
```python
ID_input = driver.find_element(""name"",""ID"")
PWD_input = driver.find_element(""name"",""PWD"")
```
but can't works.","[""You're sending in a variable as a literal String. Get rid of the quotes if you are going to assign the ID and PWD variables."", 'Is the Name of the First Element really ""ID"" ? Does the page contain an iFrame? Can you share some HTML as well?\n\nEdit: the stuff you are looking for is in an iframe. You need to switch to it first.']"
Where do u learn,https://www.reddit.com/r/selenium/comments/zc5ptu/where_do_u_learn/,selenium,"Hi guys,

Where do u guys learn selenium. Any tutorials/blog/website/videos u can suggest. 

Im planning to learn it for free. Not planning to pay for it. 

I have a background of python and web dev. 

Thanks","['YouTube selenium tutorials\nBadabing badaboom', ""starting learning selenium with virtually no background in python. Tech with tim has some decent tutorials, i typically just have documentation pulled up. Almost everything i've needed is in doc's."", 'I would recommend the following YouTube channel. Look through the playlists for the Selenium tutorials. He has a few. \n\nhttps://www.youtube.com/@sdetpavan/playlists', ""Hey man, if you are 100% new, don't go Selenium. Learn Playwright. It's basically the same thing, but better."", ""I just started with it and so far I've been reading the docs (there's missing doc there) and YouTube tutorials with blogs"", 'Lots of resources online. If you just google the topic you want to learn. Usually redirects you to some YouTube link. Then it‚Äôs just a matter of looking at the reviews of the YouTuber and finding if you like their teaching skills. Good Luck.']"
how can i run selenium on replit? I always get driver path errors,https://www.reddit.com/r/selenium/comments/zc9h0n/how_can_i_run_selenium_on_replit_i_always_get/,selenium,"I did try solutions from this post comments
https://replit.com/talk/ask/Can-I-use-selenium/11566
But still doesn't work","[""To get help with something custom like this you will need to post more information than a link to 4 year old question. What exactly did you try from that page? What exactly is the error you're facing? Do you have any code that demonstrates your issue? When you follow the steps in this question above what is the outcome?""]"
Selenium ChromeDriver eating up HD space?,https://www.reddit.com/r/selenium/comments/zar4e3/selenium_chromedriver_eating_up_hd_space/,selenium,"Hi there, I'm to see if anyone is having this issue or if it is just me.

Prior to running my Selenium script, I have about 13GB of Hard Drive space.

After running the script for about 5-6 hours, I'm down to 3GB of space.

Here's my python code:

\# Keep the Browser open, even after execution  
chrome\_options = Options()  
chrome\_options.add\_experimental\_option(""detach"", True)  
\# this parameter tells Chrome that  
\# it should be run without UI (Headless)  
chrome\_options.headless = True  
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options = chrome\_options)  
....

driver.quit()

Is anyone else experience the same issue, if so, is there a way around it beside having restart my server or laptop after so many runs?

Thanks in Advance.","[""You could check what's consuming that much space. It's logs, temporary internet files, etc?"", 'Check the temp files generated by ChromeDriver...', ""I'm gonna guess that the issue is in the \\``....`\\` part of your program. Presumably that's the part that's taking 5-6 hours lol? The code you shared is just basic scaffolding.""]"
Element not interactable,https://www.reddit.com/r/selenium/comments/z9uyn2/element_not_interactable/,selenium,"Hi Reddit, I m working on a script that uses selenium to click on all of the jobs on indeed. I have found that without fail it always returns an ""element not interactable"" error on the 11th LI element. I have tried to implement an implicit wait to wait until the element was clickable and it just resulted in a timeout error. This is the code that I have so far

    from selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.wait import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.webdriver import ActionChains
    import time
    import pandas as pd
    
    intialLink = 'https://www.indeed.com/jobs?q=software+engineer&l=Connecticut&vjk=d2a438c96f6e9c7e&from=gnav-util-jobsearch--indeedmobile'
    driver = webdriver.Chrome(executable_path='C:<path ommited for privacy reasons>\\chromedriver.exe')
    driver.get(intialLink)
    jobPannels = driver.find_elements(By.CSS_SELECTOR,"".jobsearch-ResultsList > li"")
    
    #it starts at the 9th li element
    for i in range(9, len(jobPannels)):
        print(jobPannels[i].tag_name)
        ActionChains(driver).move_to_element(jobPannels[i]).perform()
        #wait = WebDriverWait(driver, 15)
        #wait.until(EC.element_to_be_clickable(jobPannels[i]))
        time.sleep(1)
        jobPannels[i].click()

I've tried to look this up and all I can find are people saying to use the wait for it to work and like I said before I didn't get that to work. I suspect that this is something to do with the underlying HTML of the site.

Solution: I found out that it was the 12 li that was giving me trouble, not the 11th. The reason for this was that the 12 li only contained an empty div.","['Gotta slap some grease on the wheels. Aka, put the faulty line of code within a try/except block. Then never think about it again.', 'maybe format the code snippet so its not on 1 line its unreadable atm']"
Scroll to element using python selenium,https://www.reddit.com/r/selenium/comments/z9nlsl/scroll_to_element_using_python_selenium/,selenium,"    element.location_once_scrolled_into_view

and ive used this too:

    driver.execute_script(""return arguments[0].scrollIntoView(true);"", element)

and everytime i run any of these lines i get anxiety because its always by chance if they work or not.

now im trying to run any of these im not getting any errors but the page doesnt scroll to the element, and the first one gives me this without scrolling anywhere:

    {'x': 0, 'y': 0}

eventho the element is not on coordinates x = 0 and y = 0

what can i do?

i just get this error if i try to scroll to the element or click()

    ElementNotInteractableException: Message: Element <button class=""btn btn-outline-light btn-icons"" type=""button""> could not be scrolled into view

&#x200B;","['Is it possible to link to the page in question? \n\nAnd if not, could you give some more context about it? IE why is it important to first scroll the elements into view before clicking on them? Does the page lazyload?', ""Maybe it's in iframe?""]"
Can't find an element which is visible on the windk,https://www.reddit.com/r/selenium/comments/z8vlmg/cant_find_an_element_which_is_visible_on_the_windk/,selenium,"I want to scrape the website: https://www.theguardian.com/world/coronavirus-outbreak
for newslinks.
Once the page is opened it asks to if or not accept cookies. There is a button to accept it which is visible in the screen which I want to click.
I tried to find it using xpath, class etc but no element is found.
I tried using wait to find the elements still it doesn't work. 
Can anyone help me solve this issue?",['the button seems to be in iframe.Try switching into frame and then click on the button.I was able to find the element.']
Issue with Selenium tests on AWS,https://www.reddit.com/r/selenium/comments/z7r7lx/issue_with_selenium_tests_on_aws/,selenium,"Hi all...

I've written a simple browser test with Python/Selenium that runs fine locally from my Mac, as well as from AWS Linux and Ubuntu Docker containers on my Mac. However, if I run the containers on an EC2 instance (with Docker installed, obvs), the test fails, always on the same step (which is loading a login page). I've tried an Ubuntu AWS EC2 instance and just installed all the component manually to run it natively from there, but that also fails in the same place.

So it seems that the issue is something to do with AWS, but I cannot for the life of me figure out what it may be so wondered if any of you glorious people might?","['Does it fail to load the page or fail the login steps? If it fails to log in, you may have to whitelist the EC2 IP.  They are usually within a certain range, but are dynamic.', 'Is your program headless?', 'Try taking a screenshot and grabbing a screenshot. First guesses are either firewall or DNS. Does your application load? Is it on the same host? I also seem to recall you can use VNC with the debug containers to watch playback and manually launch a browser.']"
Get 5GB of clean Residential Proxies for free,https://www.reddit.com/r/selenium/comments/z7tgeg/get_5gb_of_clean_residential_proxies_for_free/,selenium,"Hey all!

I'm looking for a few developers who are doing web scraping to make interviews about the proxy setup experience. The interview usually does not take more than 30-40 minutes. As a reward, I can offer 5GB of Residential Proxies.

Thanks in advance and don‚Äôt hesitate to DM me or at [product@soax.com](mailto:product@soax.com) to schedule a call.","['Finally I will be able to pay my rent with those 5GB of Residential Proxies', '[removed]']"
ticket-booking algorithm,https://www.reddit.com/r/selenium/comments/z72cfy/ticketbooking_algorithm/,selenium,"I implement automatic ticket-booking using selenium and python, including auto-login, auto-redirection, and auto-booking features. If you are interested in learning selenium and want to start with a project. Or if you have any comments or issues related with the task, feel free to check it online. the link towards to github repo is: [https://github.com/JJerryJi/ticket-booking](https://github.com/JJerryJi/ticket-booking)",[]
How to disable geckodriver.log file i dont want it to be created anywhere,https://www.reddit.com/r/selenium/comments/z6ygq8/how_to_disable_geckodriverlog_file_i_dont_want_it/,selenium,"straight forward question i dont want any logs from geckodriver,

i am using python selenium with firefox and everytime i run the driver a geckodriver.log file gets created. how can i disable that i dont want this file to be created.",['Apparently you just pipe it to dev null (or whatever the windows version of that is) as described here: https://stackoverflow.com/questions/41696695/how-to-turn-off-the-marionette-gecko-driver-logs-in-selenium-3']
#shadow-root (open) selenium python trying to access button inside shadow-root (open),https://www.reddit.com/r/selenium/comments/z4bwjc/shadowroot_open_selenium_python_trying_to_access/,selenium,"im trying to access a download button inside 4 shadow-root (open) what do i have to do?

the inspect element looks like this:

    <div class=""dataset-download-card"" data-test=""dataset-download-card"">
    	<hub-download-card dataset-id=""04c64cb5553843b8a644af6429b6633c_0"" spatial-ref-id=""4326"" data-element=""download-card"" hydrated="""">
    	 #shadow-root (open)
    	  <calcite-card dir=""ltr"" hydrated="""">
    	   #shadow-root (open)
    			<h3 slot=""title"">CSV</h3>
    			<dl slot=""subtitle"">
    				<dt class=""ltr"">File created</dt>
    				<dd>May 24, 2022, 01:58</dd>
    				<dt class=""ltr"">File size</dt>
    				<dd>28.9 KB</dd>
    			</dl>
    			<div slot=""footer-leading"">
    				<hub-download-notice file-status=""ready"" hydrated=""""/>
    				<calcite-button icon-position=""start"" alignment=""center"" appearance=""outline"" color=""blue"" scale=""m"" width=""full"" hydrated="""">
    				 #shadow-root (open)
    				  <button aria-label="""" class=""content--slotted icon-start-empty icon-end-empty"" type=""button"">
    						<span class=""content"">
    							<slot>
    								<#text>
    							</slot>
    						</span>
    					</button>
    					Download
    				</calcite-button>
    			</div>
    		</calcite-card>
    	</hub-download-card>
    </div>

so this is a chunk of the html code from inspect element. i am trying to access the Download button and click it.

how do i do that?

i tried using 

    driver.execute_script(""return document.querySelector('hub-download-card').shadowRoot.querySelector('calcite-card').shadowRoot.querySelector('calcite-button').shadowRoot.querySelector('button.content--slotted icon-start-empty icon-end-empty')"").click()

im getting error:

    JavascriptException: Message: TypeError: document.querySelector(...).shadowRoot.querySelector(...).shadowRoot.querySelector(...) is null",['[removed]']
how to change browser.download.dir as much as i want even after initializing the driver,https://www.reddit.com/r/selenium/comments/z49fi1/how_to_change_browserdownloaddir_as_much_as_i/,selenium,"    options = Options()
options.set_preference(""browser.download.dir"", 'downloads')

driver = webdriver.Firefox(service=service,
                                options=options)

so after i initialize the driver this driver downloads will go into downloads variable which has the path i specified for my downloads.

what if i want to change this download var later on in my script without reinitializing the driver how can i do that?

i want to change the download location many times in my script. i am using python selenium with firefox","[""Don't have an answer to your question but, cant you just grab the file and move it to the desired location? Don't understand the use case."", 'This stack overflow answer has some great insight\n\nhttps://stackoverflow.com/a/25744385/4999246', 'Use remote driver to take the session again and change those options  \n\n\nhttps://www.selenium.dev/documentation/webdriver/drivers/remote\\_webdriver/']"
Error Selenium Python,https://www.reddit.com/r/selenium/comments/z42y36/error_selenium_python/,selenium,"Hola a Todos 

Estoy automatizando con selenium y python con un webdriver de chrome, y ejecutando mis pruebas derrepente me aparecio este problema

23420:23136:1125/003102.494:ERROR:device\_event\_log\_impl.cc(215)\] \[00:31:02.494\] USB: usb\_device\_handle\_win.cc:1048 Failed to read descriptor from node connection: Uno de los dispositivos conectados al sistema no funciona. (0x1F)

estoy intentando de todo pero no me funciona, si alguien sabe pliiiz!","['–ù—è–º–∞–º –ø—Ä–µ–¥—Å—Ç–∞–≤–∞ –∫–∞–∫–≤–æ –ø–∏—à–µ—à, –º–æ–∂–µ –±–∏ —Ç—Ä—è–±–≤–∞ –¥–∞ –æ–ø–∏—Ç–∞—à –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏, –∞–∫–æ –∏—Å–∫–∞—à –Ω—è–∫–æ–π –¥–∞ –≥–æ –ø—Ä–æ—á–µ—Ç–µ.']"
xpath breaking,https://www.reddit.com/r/selenium/comments/z3a4am/xpath_breaking/,selenium,"So, I have a python script that at some point needs to get information from a website.
Everything is fine when I try to get ellement a, but element b breaks. This element lies deeper in the html code. Nothing would work.
I did figure out that after passing the 4th div or so that was when the xpath broke. When playing around with the website it seems that is roughly where the html changes when you press certain buttons.
 I figure the website makes use of something akin to tabs, but nothing seems to reflect this in the html. (And the ""default"" tab is the one I need anyways)
I can't really share the html and in python I've tried practicaly any way to access it that might exist (with the exception of going through sibling elements, as any element that is somewhat close to it is also unreachable)
Does anyone have an idea how I could fix this?","[""Without seeing the DOM it's hard to give any specific assistance here, but I think the general rule of avoiding XPath and only using it when nothing else works holds true here. If you can, try to find the element through some other means like class name, id (though I reckon you would've done that already if that was an option), text, and so on. If you can get the parent element of the element you want more easily with something like id, class name, text, etc. try to get that and then use some other means to search for the element you want within that element.\n\nFor example I had once a button that had no unique identifier to go on. The text of the button was the same as many other buttons in the DOM, it had no id, and the class names also were identical to many other buttons. I tried using XPath at first, but since the button appeared on a form that was generated when a certain event happened, the XPath wasn't always the same. However I noticed that the form actually had some unique identifiers, so when I first searched for that element with the unique locator I was then able to just look for the button element from within that form element. Even though the locators were identical to other elements on the page, they was unique within the context of the parent element.\n\nHope any of this helps!"", 'I can understand that you cannot share html code here. But at least you could mention if there are any tags or attributes available for that element.\n\nMaybe someone with similar issues will help.', 'Trying searching around for ""shadow dom""', 'Does it work with Selenium IDE recording and running? If it does, using the element it generates may solve your problem.']"
What else stops finding elements besides iframes,https://www.reddit.com/r/selenium/comments/z2psxn/what_else_stops_finding_elements_besides_iframes/,selenium,"I have a web page I'm trying to automate and it works perfectly until I get to a certain point, but then python stops finding anything on the last page.

I was using find element by link and by partial link but I also tried some different things with xpath, id, and css selector but still no dice.

After some googling, I also tried switching to the 2 iframes in the page (I did so by index) and back to the main content, but still not a die to be found. 

I noted that the links in question come in the same wrapper as a Javascript noop. Could that have something to do with it? What should I google/try next?

I'm not sure what to paste in here to ask for help. I've tried so many things that didn't work. Thanks for your time, those who read this far; whether you can help me or not, I appreciate you.","['Is the site public? Can you link it?\n\nYou can try Selenium IDE, does it interact with it?', ""Where you running headless and didn't realise there was another window?"", ""Any chance the people who keep downvoting this can explain why? I keep hitting 5 votes and then it's back down to 1 or 2. If there's a faux pas I've committed, please let me know.""]"
Rasberry Pi recs (or hosting alternatives) to run webdriver python script?,https://www.reddit.com/r/selenium/comments/z2nwqh/rasberry_pi_recs_or_hosting_alternatives_to_run/,selenium,Hi just wondering if anyone would be so kind to recommend a cost efficient setup for deploying a  crawler package that I plan to run continuously.  I was recommended raspberry pi for additional devices but there are a lot of options and not sure what is required to smoothly run webdriver (ChromeDriverManager)?  Just one instance of the script.  Also open to hosting but I don't know that is feasible... thank you!,['If it supports the software a pi is good for running something 24/7.  There‚Äôs also free tiers at the various cloud providers.']
Trying to understand .perform() keyword,https://www.reddit.com/r/selenium/comments/z2g9p7/trying_to_understand_perform_keyword/,selenium,anyone can eli5 the purpose behind this perform keyword thanks,[]
Select only buttons with aria-pressed,https://www.reddit.com/r/selenium/comments/z1rgdn/select_only_buttons_with_ariapressed/,selenium,"Hello, 

&#x200B;

Im working on improving my like bot. I can get all the like buttons, but the bot is very indiscriminate about what it likes as I'm using 

&#x200B;

`driver.find_elements('xpath', ""//button[contains(.,'Like')]"")`

I need to find a way to only click on items that are `aria-pressed=""false'` 

&#x200B;

I have tried adding the condition after the statement as follows:

`river.find_elements('xpath', ""//button[contains(.,'Like')]"" and aria-pressed=""false')`  

&#x200B;

&#x200B;

Any suggestions are highly appreciated.",['Your syntax is wrong see the example here \n\nhttps://stackoverflow.com/questions/18547410/xpath-with-multiple-contains-on-different-elements']
"Cannot find Chrome Binary , MS Visual Studio 2022",https://www.reddit.com/r/selenium/comments/z1p8ww/cannot_find_chrome_binary_ms_visual_studio_2022/,selenium,"Hello, I have been googling this error for 2 days, and i've tried to give the explicit path to the chromedriver.exe outside or the project and inside the project, it still pops up with the same error, tried it on different computers, reinstalled VS, tried also the headless start, and yes reinstalled few times.
Selenium.Support
Selenium.WebDriver
Selenium.WebDriver.ChromeDriver

nothing seems to be working. It's a very stupid question but i ran out of ideas or maybe my googling abilities suck.","[""For better help it would be a good idea to post your full error code.\nAt this point i can only guess from my humble point of view. A common issue exists when you copy the PATH of chromedriver. Change the separators from ' \\ ' to ' / '. Maybe it'll work."", 'Try this:\n\nhttps://www.reddit.com/r/selenium/comments/qw1jms/how_to_automatically_update_your_chromedriver_in_c/', 'Is it a version mismatch between the Chrome driver and Chrome Browser?  \nDoes your Chrome Driver version first 2 digits match   \nwith your Chrome Browser version first 2 digits?', 'Sorry for late reply I was hoping to receive notification from reddit, anyway, here is the code  \n\n\nBasically i am running the code from the official selenium web site, nothing unusual that would leave room for error, in the end i\'ve copy pasted everything, funny thing today i have tried to run it again, i receive a different error. Maybe some browser automatically updated and solved my error but created a new one :)\n\n&#x200B;\n\n    OpenQuestionnaire\r\n\r\n  \u2009Source:\u2009UnitTest1.cs\u2009line\u200917\r\n\r\n  \u2009Duration:\u20091 min\r\n\r\n \r\n\r\n  Message:\u2009\r\n\r\nTest method TestingQuestionnaire.UnitTest1.OpenQuestionnaire threw exception:\r\n\r\nOpenQA.Selenium.WebDriverException: The HTTP request to the remote WebDriver server for URL http://localhost:xxxxx/session timed out after 60 seconds. ---> System.Threading.Tasks.TaskCanceledException: A task was canceled.\r\n\r\n \r\n\r\n  Stack Trace:\u2009\r\n\r\nTaskAwaiter.ThrowForNonSuccess(Task task)\r\n\r\nTaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n\r\nTaskAwaiter`1.GetResult()\r\n\r\n<MakeHttpRequest>d__35.MoveNext()\r\n\r\n--- End of stack trace from previous location where exception was thrown ---\r\n\r\nExceptionDispatchInfo.Throw()\r\n\r\nTaskAwaiter.ThrowForNonSuccess(Task task)\r\n\r\nTaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task)\r\n\r\nTaskAwaiter`1.GetResult()\r\n\r\nHttpCommandExecutor.Execute(Command commandToExecute)\r\n\r\n--- End of inner exception stack trace ---\r\n\r\nHttpCommandExecutor.Execute(Command commandToExecute)\r\n\r\nDriverServiceCommandExecutor.Execute(Command commandToExecute)\r\n\r\nWebDriver.Execute(String driverCommandToExecute, Dictionary`2 parameters)\r\n\r\nWebDriver.StartSession(ICapabilities desiredCapabilities)\r\n\r\nWebDriver.ctor(ICommandExecutor executor, ICapabilities capabilities)\r\n\r\nChromiumDriver.ctor(ChromiumDriverService service, ChromiumOptions options, TimeSpan commandTimeout)\r\n\r\nEdgeDriver.ctor(EdgeDriverService service, EdgeOptions options, TimeSpan commandTimeout)\r\n\r\nEdgeDriver.ctor(EdgeDriverService service, EdgeOptions options)\r\n\r\nEdgeDriver.ctor(EdgeOptions options)\r\n\r\nEdgeDriver.ctor()\r\n\r\nUnitTest1.OpenQuestionnaire()\u2009line\u200919\n\n&#x200B;\n\n    \n    using System;\r\nusing Microsoft.VisualStudio.TestTools.UnitTesting;\r\nusing OpenQA.Selenium;\r\nusing OpenQA.Selenium.Chrome;\r\n\r\nnamespace SeleniumDocs.GettingStarted\r\n{\r\n    [TestClass]\r\n    public class FirstScriptTest\r\n    {\r\n\r\n        [TestMethod]\r\n        public void ChromeSession()\r\n        {\r\n           var driver = new EdgeDriver();\n               //var options - new EdgeOptions();\r\n\r\n            \n            driver.Navigate().GoToUrl(""https://www.google.com"");\r\n           \r\n            \r\n            //driver.Quit();\r\n        }\r\n    }\r\n}']"
How do you deal with 'difficult' elements?,https://www.reddit.com/r/selenium/comments/yy4y8l/how_do_you_deal_with_difficult_elements/,selenium,"Bit of a selenium noob so apologies upfront. 

I often come across elements that are very clear and seem easy to interact with, just by looking at the page. However, when I try to click on said element it comes up saying it's not clickable. Do you have a checkbox list of things you work through to click on difficult elements like these? In my mind I'm picturing a flowchart sort of like, if element not clickable, is it a popup- do X, is it an input box - do Y. If that makes sense","['Usually I just ask myself three questions:\n\n* Am I actually trying to find and click the correct element or do I need to click the parent or child of that element instead?\n* If it\'s an XPath or something else, is it actually unique or are there multiple elements found?\n* Is there a slight delay of a few ms between the element becoming clickable (e.g. a page load or something) and me trying to click it and do I need to wait for the element or the page to finish loading first?\n\nAll of these are simple enough to verify in the browser\'s console with little effort (except maybe the delay thing, that\'s usually just checked by me throwing a Thread.Sleep or something somewhere in the code and checking if that helps) and usually it\'s one of these three. They\'re like my ""have you tried turning it off and on again"" -routine.\n\nSometimes it gets a bit trickier, but in the end as long as something is on a webpage and it can be clicked with a mouse, it\'s usually clickable so it\'s just a matter of finding what particular portion of that element you need to actually click to get things rolling.', ""When I don't know what to do, I use Selenium IDE and export the code."", ""Use xpath plugins like chropath. If it doesn't give you what you need it'll get close to it"", 'JavaScript click', 'By using javascript. If you use C# you can write an extension for WebElements to add a ClickJs() method to the class. It can come in handy.', 'I look to download documents but sometimes the element is behind iframes and widgets. I can find my way around them for the most part but how how do you account for those techniques']"
Whats the best site for hosting a selenium bot?,https://www.reddit.com/r/selenium/comments/yxr43l/whats_the_best_site_for_hosting_a_selenium_bot/,selenium,I have a bot i want to host online so i would like to know which is best for selenium.,"[""I don't think that's possible. You'll have to run it on your computer or stand up your own Selenium Grid server."", 'Railway.app']"
Selenium Find button containing text,https://www.reddit.com/r/selenium/comments/yxptrt/selenium_find_button_containing_text/,selenium,"Hello,

&#x200B;

Im working on building a small linkedin bot that clicks on likes for my company's posts. The issue at the moment is that all like buttons are dynamic and therefore,  I cannot select via the regular text options. I have been trying to see if I could get something like the following working, but I'm getting an error::

`like = driver.find_element('xpath', ""//button[contains(text(),'Like')]"")`

`print(like)`

&#x200B;

Any help is greatly appreciated.","[""What's the element look like (in the Web Dev Tool, F12)?"", 'What error are you getting?', 'Answer for those wondering: `driver.find_elements(\'xpath\', ""//button[contains(.,\'Like\')]"")`']"
Help with uploading file on Python Selenium using remote driver,https://www.reddit.com/r/selenium/comments/yx49ls/help_with_uploading_file_on_python_selenium_using/,selenium,"I am using python 3.9 and selenium 4.6.0 on Chrome. I have a script that needs to upload a file to an input, this works fine on local but fails when run on RemoteDriver. The code I am using is

    driver.find_element(By.XPATH, ""//input[@accept]"").send_keys('path to file')

When run on RemoteDriver the error returned is

    selenium.common.exceptions.WebDriverException: Message: unknown command: unknown command: session/cddd71e067d7717481fb8a635103c643/se/file

I've think it is due to this line in the remote\_connection.py file in selenium

    Command.UPLOAD_FILE: ('POST', ""/session/$sessionId/se/file"")

From the research I've done the 'se' in this case is a 'vendor\_prefix' for selenium but I cannot figure out how to either configure the remote driver to use a vendor prefix or remove that from POST path that is being passed (short of pulling my own version of the code and maintaining that).

For other functional reasons I can't revert to selenium 3x (which is an option I've seen to correct this), nor can I set w3c to False. Does anyone know how to work around this particular issue; either by getting send\_keys to operate as expected in this situation or using another method to upload the file? Thanks.",[]
trying to download a file by opening the download link with urllib,https://www.reddit.com/r/selenium/comments/ywo4nf/trying_to_download_a_file_by_opening_the_download/,selenium,"    import urllib
    urllib.request.urlretrieve(csv_url, os.path.join(downloading_dir,'Data.csv'))

i have a var a downloading\_dir which specifies the path i want my download to go and Data.csv is the filename that i want once the download is finished.

im getting this error:  **URLError**: <urlopen error unknown url type: blob> 

the url has a weird format that urlopen is not processing well.

this is an ex of one of the links: blob:null/3a9be3c2-02d9-4943-b136-0d064a6bb6bb

if you open this link with selenium driver.get('blob:null/3a9be3c2-02d9-4943-b136-0d064a6bb6bb')

it works with an error but it works and the files gets downloaded with a random name and a location i do not want.

thats why im trying to access the download link in a way i can specify the download location and name.",[]
Trying to soup a page to get to an element because selenium is not finding it,https://www.reddit.com/r/selenium/comments/yvuqq9/trying_to_soup_a_page_to_get_to_an_element/,selenium,"[https://www.who.int/data/gho/data/indicators/indicator-details/GHO/proportion-of-population-below-the-international-poverty-line-of-us$1-90-per-day-(-)](https://www.who.int/data/gho/data/indicators/indicator-details/GHO/proportion-of-population-below-the-international-poverty-line-of-us$1-90-per-day-(-))

Open this url and go to Data tab, inside data tab we have the unclickable link on the right side with inner text: EXPORT DATA in CSV format: Right-click here & Save link

in order to get the data i need to right click and save link as then save in order to get the data i need.

im trying to reach this element by using beautifulsoup but no matter what i do i can't see to find this <a> tag nor its href attribute.

i tried using selenium to get driver.source\_page then use that source\_page in beautifulsoup it still didnt get me the element.

and i tried using selenium itself find\_element i also couldn't reach that <a> i need.

what can i do?","[""The link you posted directs to a page that's 404ing. Would love to take a look if you can fix the link!"", '[`https://www.who.int/data/gho/data/indicators/indicator-details/GHO/proportion-of-population-below-the-international-poverty-line-of-us$1-90-per-day-(-)`](https://www.who.int/data/gho/data/indicators/indicator-details/GHO/proportion-of-population-below-the-international-poverty-line-of-us$1-90-per-day-(-))\n\n&#x200B;\n\nthis is the link if anyone is trying to access it']"
Right click save link as in python,https://www.reddit.com/r/selenium/comments/yvqpwu/right_click_save_link_as_in_python/,selenium,"hello guys i want to right click save link as then save on the save pop up that windows shows.

this is an example:

[https://www.who.int/data/gho/data/indicators/indicator-details/GHO/proportion-of-population-below-the-international-poverty-line-of-us$1-90-per-day-(-)](https://www.who.int/data/gho/data/indicators/indicator-details/GHO/proportion-of-population-below-the-international-poverty-line-of-us$1-90-per-day-(-))

go on this page in the data tab u can see EXPORT DATA in CSV format:Right-click here & Save link

so if u right click and save link as it will let u save the data as csv.

i want to automate that can it be done using selenium if so how?","['I would go with another approach. Find the identifier of the SVG html tag and take a screenshot of that element\nhttps://stackoverflow.com/questions/15018372/how-to-take-partial-screenshot-with-selenium-webdriver-in-python', 'just do context click with selenium and then use pyautogui to click/navigate through the context menu']"
Selenium Side Runner does not create Result Files,https://www.reddit.com/r/selenium/comments/yu2n4x/selenium_side_runner_does_not_create_result_files/,selenium,"Hey Folks, I plan to test a website automatically on a headless server and I'm considering using Selenium for that since I know it from previous web scraping projects. I used Selenium IDE to record a little demo _.side_ file (opens a website and clicks a button) to test my setup. Then, I executed it using the Selenium side runner tool but it did not output anything although the output directory was set. Although my case is as simple as it can be I'm struggling so much already, partly because of poor documentation (ended up digging options/flags from source code) and the tool not doing what one is expecting, i.e. outputting results in a machine readable format. 

Here's what I've done:

**sides.yaml**

```yaml
capabilities:
  browserName: ""firefox""
timeout: 25000
```

**command**

```
selenium-side-runner --config-file=""config/side.yaml""  --output-directory=""results"" --debug tests/demo.side
```

**output**

```
Configuration: {
  baseUrl: '',
  capabilities: { browserName: 'firefox' },
  debug: true,
  filter: '.*',
  force: undefined,
  maxWorkers: 16,
  params: {},
  projects: [ '/home/user/workspace/test-website/tests/demo.side' ],
  proxyOptions: {},
  runId: '5d7ee74cc411318e92cb196738a08653',
  path: '/usr/local/lib/node_modules/',
  server: '',
  timeout: 25000
}
info: Running test demo
debug: Playing state changed prep
info: Building driver for firefox
info: Driver has been built for firefox
debug: Playing state changed playing
debug: executing open|/
debug: passed open|/
debug: executing click|linkText=Antworten!
debug: passed click|linkText=Antworten!
debug: executing click|name=q
debug: passed click|name=q
debug: executing type|name=q|blockchain
debug: passed type|name=q|blockchain
debug: executing click|css=input:nth-child(2)
debug: passed click|css=input:nth-child(2)
debug: Playing state changed finished
info: Finished test demo Success
 PASS  ../../../../../usr/local/lib/node_modules/selenium-side-runner/dist/main.test.js (6.686 s)
  Running project demo
    Running suite Default Suite
      ‚úì Running test demo (6260 ms)

Test Suites: 1 passed, 1 total
Tests:       1 passed, 1 total
Snapshots:   0 total
Time:        6.728 s
Ran all test suites within paths ""/usr/local/lib/node_modules/selenium-side-runner/dist/main.test.js"".
Jest did not exit one second after the test run has completed.

This usually means that there are asynchronous operations that weren't stopped in your tests. Consider running Jest with `--detectOpenHandles` to troubleshoot this issue.
```

Also, when passing the `--output-format` flag, I get the following error:

```
error: unknown option '--output-format=jest'
```

I followed the instructions at https://www.seleniumhq.org/selenium-ide/docs/en/introduction/command-line-runner/ with command line runner version 4.0.0-alpha.16.

**EDIT:** I just noticed that I'm on a alpha version of a presumably new major release and thus there may be breaking changes and not yet complete documentation. All fine but why the hell is this shipped to users that don't request it explicitly? Shouldn't there be separate release channels for unstable versions?

**EDIT:** Downgraded to the last _3.x_ release from 3 years ago(!) and now it outputs results properly. However, it has >20 security vulnerabilities listed in its dependencies which is a red flag for me. Also, the `--output-format` flag is not recognized either which is okay for me but still does not match the docs.",[]
How to find out where script is being run from?,https://www.reddit.com/r/selenium/comments/yty2cu/how_to_find_out_where_script_is_being_run_from/,selenium,"This is quite basic and perhaps not Selenium specific but I've got a Selenium script that's being called through celery, from my webpage built with Django. I thought I knew the file my script was running from but I just commented almost all the code from that file out and the script it still running! How do I find out where it's running from?",['what does the script do? just found for example the locator on which script is clicking across whole project']
VBA Firefox browser Selenium,https://www.reddit.com/r/selenium/comments/yt0gox/vba_firefox_browser_selenium/,selenium,"Hi guys, I just downloaded and learnt Selenium and Selenium Wrapper today for a VBA project. I just want to auto fill a form on web since it‚Äôs repetitive and time consuming but don‚Äôt want to keep opening and quitting Firefox browser all the time. Do you have any suggestions on how to write a function that only auto fill the form with values in specified cells? 
Thank you!!","[""There's no one size fits all formula. It depends on the html syntax of the website. You're asking a very broad question with not enough information provided for someone to give a more detailed answer. You also need to learn the browser API in order to interact with it to automate. Sounds like you need to learn more of the mechanics on how to do this, and come back w/ a more specific question if you get what I mean. It's a lot more complicated than just one function solving something that is very dynamic.""]"
ScreenPy Playwright v0.0.1 is released (and a humble request for help)!,https://www.reddit.com/r/selenium/comments/ysivip/screenpy_playwright_v001_is_released_and_a_humble/,selenium,"Hey friends, we released the [ScreenPy](https://screenpy-docs.readthedocs.io/en/latest/) extension [ScreenPy Playwright](https://screenpy-playwright-docs.readthedocs.io/en/latest/), and we need some help. With Selenium, i personally had a large, professional project to develop the extension with, so i feel that the [ScreenPy Selenium](https://screenpy-selenium-docs.readthedocs.io/en/latest/) extension is getting mature. But i don't have a similar project for Playwright.

If any of you have some time and interest, can you give some suggestions for Actions you would want to see in ScreenPy Playwright for it to cover your use cases? So far, there are only enough to be able to automate [this example test for SwagLabs.](https://github.com/ScreenPyHQ/screenpy_examples/blob/trunk/screenpy_playwright/swaglabs/features/test_cart.py#L15) 

We'd love to get your input! Also, is there a Playwright-specific subreddit? The only one i can find is for script-writing, you know, for theaters.",[]
How to achieve @FindBy in Playwright?,https://www.reddit.com/r/selenium/comments/ys5f1m/how_to_achieve_findby_in_playwright/,selenium,"Hi,  


I am thinking of migrating the 'core' of my framework and try to use Playwright.  
The framework is built on page object model and using the  @ FindBy annotations   
(using Java)  


So the page objects look like the following :  


public class HomePage(){  


@ FindBy(id='Username')  
public WebElement username\_field;

&#x200B;

public HomePage clickOnUsername(){  
username\_field.click();

return this();

}  
}  


I would like to keep the same format also using PlayWright, but it has no annotations of this kind.  
Any ideas how to achieve that?  


Thanks !","[""You can't use that annotation, but you can still use the POM. I'm in the midst of doing this process as well, it's tedious, but well worth it.""]"
How can I automate tests for a whiteboard? The Chrome extension IDE recorder seems to record coordinates.,https://www.reddit.com/r/selenium/comments/yrkbl2/how_can_i_automate_tests_for_a_whiteboard_the/,selenium,"I will soon need to automate some tests for a WebGL whiteboard (to draw and move objects), and I've been trying to practice on some sites that have examples of this (where you can move shapes around), and I noticed that the Selenium IDE Chrome extension recorder appears to track the coordinates. However, when I replay the recording (even after tinkering with what appear to be the coordinates), it fails to work.


Does anyone have experience with this who can share some advice on how to proceed?","['https://o8wi0.csb.app - this is the sample website I was tinkering with, trying to move the shapes around the board.', 'In general selenium IDE is terrible. Try selenium Webdriver.']"
"Hey, scraping developers, I need your help!",https://www.reddit.com/r/selenium/comments/yrg70d/hey_scraping_developers_i_need_your_help/,selenium,"Hey all, 

Are there any experienced scraping API‚Äôs tech-users (the tools like ScraperAPI, ScrapingBee, ScrapingBot, Zenrows, etc.)? Or just web scraping enthusiasts? I really need your help! 

My name is Alex, I am a scraping developer with a mission to build the best Proxy API tool out there (humble is not my way.)  So here is my project - [ScrapeIN‚Äô](https://scrapein.app/)  where I am trying to combine and automate the best practices for bypassing site protection and create all-in-one scraping infrastructure for any data engineer. 

I released the first MVP version of my Proxy API and want to make sure that it works as planned, so it would be awesome if you could help me out and test it for any issues and bugs. 

So to test my ScrapeIn you need to

1. Go [here](https://dashboard.scrapein.app/)
2. Register - it will allow you to use scraper for 14 days with 1000 credits. I can extend access on request if needed, just ping me here or in dms or by email. I don‚Äôt request credit card upon registration or anything, so don‚Äôt worry about the payment that supposedly should follow the trialüòÖ
3. Look through our [API docs](https://dashboard.scrapein.app/docs) 
4. [Use ](https://dashboard.scrapein.app/)the API key given to you for scraping any public data from the web.  
5. [Use](https://dashboard.scrapein.app/query-builder) visual CSS selectors mode in order to extract the necessary data from a site accurately. 
6. Take and submit a short questionnaire Google [form](https://forms.gle/vbEaerevcoDjFNNc6).  
7. Enjoy increased ScrapeIN‚Äô account balance by 1000 free credits! 

I really appreciate any of your feedback and thoughts about ScrapeIN‚Äô. Don‚Äôt hesitate to share with me any of your feedback in DMs or at support@scrapein.app.",['Bypassing site protections is the exact opposite of best practices.']
"Trying to Scroll inside a div with selenium, scroller function only scrolls up to a certain amount and then just stops",https://www.reddit.com/r/selenium/comments/yr3zpj/trying_to_scroll_inside_a_div_with_selenium/,selenium,"I want to get a list of all the list items which are present inside a div with a scroller. They are not loaded at once upon loading the page, rather the items are loaded dynamically as the user scrolls down (until there are no elements left). So, this is the scroller script which I tried to implement:

    def scroller():
        userList = None
        prev = 0    
    
        while True:
            time.sleep(5)
            userList = WebDriverWait(browser, 50).until(
                EC.presence_of_all_elements_located(( By.CLASS_NAME, '<class of list item>' ))
            )
            n = len(userList)
            if n == prev:
                break
            prev = n
            #getting the last element in the list in the view
            userList[-1].location_once_scrolled_into_view

This function scrolls the list upto a certain length, but doesn't go to the full length of the elements (not even half). Can someone please suggest a better way to do this?

Thank you","[""What's the purpose of prev =n"", ""You should *get* the list of visible items and look for the desired element there.  \nIf it's not present you save the last item and scroll to it.  \nOnce again check the list and save the last item.  \nTill the last item doesn't change after scrolling.""]"
Closing a tab in Selenium IDE,https://www.reddit.com/r/selenium/comments/yppzkt/closing_a_tab_in_selenium_ide/,selenium,"Hi! 
I have the steps: clicking on the URL that is external and it opens in a new tab. I then have to go back to the original tab to keep doing something there with Selenium IDE. How can I close that new tab with external link? Or how can I go back to the original tab? Please help","[""Stackoverflow, as usual, has the answer to this question:\n\n[https://stackoverflow.com/questions/12729265/switch-tabs-using-selenium-webdriver-with-java](https://stackoverflow.com/questions/12729265/switch-tabs-using-selenium-webdriver-with-java)\n\nSireesha Middela's answer looks right:\n\n`ArrayList<String> tabs2 = new ArrayList<String> (driver.getWindowHandles());`  \n`driver.switchTo().window(tabs2.get(1));`  \n`driver.close();`  \n`driver.switchTo().window(tabs2.get(0));`"", 'driver.close() : closes the current tab and transfers the driver control to the previous tab.', 'Have you tried the [select window](https://www.selenium.dev/selenium-ide/docs/en/api/commands#select-window) function?', 'Utilize window handles, store the handle of the window prior to opening up the new tab and then you can use switchTo for toggling.']"
Pressing spacebar in selenium (python) to scroll down in a table element,https://www.reddit.com/r/selenium/comments/yovwce/pressing_spacebar_in_selenium_python_to_scroll/,selenium,"What I need to do is, I need a list of all the elements which are basically list-items, but the list doesn't load at once, instead it loads part by part, so the following code doesn't get the list of all the list elements:

    userList = WebDriverWait(browser, 5000).until(
     EC.presence_of_all_elements_located(( By.CLASS_NAME, 'c-virtual_list__item' ))
    )

So, in order to get the list of all the elements present in the list/table, I need to scroll all the way down in the table. I am trying to do that by trying to replicate the following process:

1. Select the element with a scroller by clicking on it
2. Press space to scroll down

I wrote the following piece of code to try and accomplish that:

    scroller = WebDriverWait(browser, 5000).until(
        #this is a div element which contains a scroller
        EC.presence_of_element_located(( By.CLASS_NAME, 'c-table_view_keyboard_navigable_container' ))
    )
    
    prev = 0
    userList = None
    
    #scrolling until I read the end of the list
    while True:
        scroller.send_keys(Keys.SPACE)
        time.sleep(2)
        userList = WebDriverWait(browser, 5000).until(
            EC.presence_of_all_elements_located(( By.CLASS_NAME, 'c-virtual_list__item' ))
        )
        cur = len(userList)
        if cur == prev: break

But this line:  `scroller.send_keys(`[`Keys.SPACE`](https://Keys.SPACE)`)` throws an error:

>selenium.common.exceptions.ElementNotInteractableException: Message: element not interactable

I have seen some code snippets on stackoverflow where people select the body element:

`find_element(By.TagName, ""body"")`

and scroll down the webpage in a similar manner to what I have tried:

`element.send_keys(`[`Keys.SPACE`](https://Keys.SPACE)`)`

However, it doesn't work for me and throws the given error.

Can someone please help me make this work!?

&#x200B;

Thank you for your time :)","[""This isn't working because Selenium expects an element to which it is sending keys to be some form of text field. The element you're selecting isn't able to receive the text input, so Selenium considers that element not interactable.\n\nTaking a step back, ss there a reason you are trying to scroll by pressing the spacebar? Typically scrolling in Selenium is done via executing javascript."", 'Have you tried using Actions chain?', 'Not sure if this would help you but you could use the PyAutoGUI package to actually simulate space bar presses at the appropriate point in your code.  You could also simulate down arrow or page down presses too.  Good Luck!', 'I think [this](https://www.tutorialspoint.com/how-to-scroll-a-specific-div-using-selenium-webdriver-with-java) is what you want.']"
Can i find_element or find_elements that contain a class but this class only?,https://www.reddit.com/r/selenium/comments/yoh99r/can_i_find_element_or_find_elements_that_contain/,selenium,"lets say i have an elements like this:

    <div class=""full-width flex-buttons-container push""></div>
    <div class=""full-width push""></div>
    <div class=""full-width""></div>
    <div class=""full-width""></div>
    <div class=""full-width""></div>

if i use the following:

    ¬†driver.find_elements(By.CLASS_NAME,'full-width')

i will get all 5 divs but what i want is the elements that have full-width class and full-width class only.

so i want the last two divs only can i achieve something like that?","[""You can do this with css selector by excluding the ones you don't need, for example: div.full-width:not(.push)\n\nEdit: or, of course also using css selector: div[class='full-width']\n\nThat will look for a div with a class attribute that matches the String 'full-width' exactly.""]"
Selenium IDE,https://www.reddit.com/r/selenium/comments/yoj5gl/selenium_ide/,selenium,"Selenium IDE is a free, easy-to-use browser automation tool that makes web application testing simple. It is an open source test automation tool that allows you to capture and replay online activity, which then translates into tests that can be rerun at any time. 

In order to construct Selenium test cases as a component of the Selenium suite, the Selenium IDE record & replay tool was released in 2006.

Install the extension (or add-on) for the relevant browser before beginning Selenium automation testing using Selenium IDE. Additionally, the IDE offers a GUI for documenting website interactions. 

Selenium IDE may now be used to test on Chrome browsers in addition to Firefox, which it was previously only accessible to test on. Cross-browser support and Selenium parallel testing are now supported by the IDE.",['Thanks?']
how to target html nested elements ?,https://www.reddit.com/r/selenium/comments/ymqeo9/how_to_target_html_nested_elements/,selenium,"I'm trying to target a div that is deeply nested and has no specific id. Is it possible to get the parent element (that has an id), then to target the child div using find_element by xpath from there ?","['Xpath axes   driver.findElements()', 'You can also use class names in your xpath to simplify the locator. If the element in question has a super class(more than one class) you can use the contains method in your xpath so something like\n\n‚Äú//div[contains(@class, ‚Äòclass name‚Äô)]‚Äù', 'Can you link to the page, or if not then post an example of the HTML in question?']"
Using Driver in Functions and returning that Driver ?,https://www.reddit.com/r/selenium/comments/ym4anm/using_driver_in_functions_and_returning_that/,selenium,"I was wondering if it's a bad practice using functions with webdriver as an argument and return that webdriver in order to use it.
For example :
```python
def search(driver):
   # do something with the driver

    return driver
```

well it works, but i was wondering if good practice or i should avoid that ?","[""I don't return the driver in functions, because I never needed to, but I use it as argument all the time, and I don't see why it would be a bad practice."", 'That sounds like you‚Äôre lacking some abstraction layer between tests and driver itself.\nIdeally your tests should not be aware of drivers existence.', 'You could create a DriverManager Class and use TheadLocal. Then you could set it during start up and use a getter without having to pass the driver as a parameter.']"
How to generate Extent Reports in Selenium?,https://www.reddit.com/r/selenium/comments/ylromm/how_to_generate_extent_reports_in_selenium/,selenium," 

1. Import the JAR file: degreereports-java-2.1.2.jar. After downloading the ZIP file, extract its contents to a folder.
2. Add the JAR file to the build path of the project using the Build Path -> Set Build Path option.
3. Create a new JAVA class for Scope Report with the following code.

&#8203;

    package com.browserstack.demo;
    import org.junit.AfterClass;
    import org.junit.BeforeClass;
    import org.junit.Test;
    import org.openqa.selenium.WebDriver;
    import org.openqa.selenium.chrome.ChromeDriver;
    import com.relevantcodes.extentreports.ExtentReports;
    import com.relevantcodes.extentreports.ExtentTest;
    import com.relevantcodes.extentreports.LogStatus;
    public class ExtentDemo {
    static ExtentTest test;
    static ExtentReports report;
    @BeforeClass
    public static void startTest()
    {
    report = new ExtentReports(System.getProperty(""user.dir"")+""ExtentReportResults.html"");
    test = report.startTest(""ExtentDemo"");
    }
    @Test
    public void extentReportsDemo()
    {
    System.setProperty(""webdriver.chrome.driver"", ""D:SubmittalExchange_TFSQAAutomation3rdpartychromechromedriver.exe"");
    WebDriver driver = new ChromeDriver();
    driver.get(""https://www.google.co.in"");
    if(driver.getTitle().equals(""Google""))
    {
    test.log(LogStatus.PASS, ""Navigated to the specified URL"");
    }
    else
    {
    test.log(LogStatus.FAIL, ""Test Failed"");
    }
    }
    @AfterClass
    public static void endTest()
    {
    report.endTest(test);
    report.flush();
    }
    }

### How to generate Extent Reports in Selenium using NUnit?

    [SetUpFixture]
    public abstract class Base
    {
    protected ExtentReports _extent;
    protected ExtentTest _test;
    
    [OneTimeSetUp]
    protected void Setup()
    {
    var dir = TestContext.CurrentContext.TestDirectory + ""\\"";
    var fileName = this.GetType().ToString() + "".html"";
    var htmlReporter = new ExtentHtmlReporter(dir + fileName);
    
    _extent = new ExtentReports();
    _extent.AttachReporter(htmlReporter);
    }
    
    [OneTimeTearDown]
    protected void TearDown()
    {
    _extent.Flush();
    }
    
    [TestFixture]
    public class TestInitializeWithNullValues : Base
    {
    [Test]
    public void TestNameNull()
    {
    Assert.Throws(() => testNameNull());
    }
    }
    
    [SetUp]
    public void BeforeTest()
    {
    _test = _extent.CreateTest(TestContext.CurrentContext.Test.Name);
    }
    
    [TearDown]
    public void AfterTest()
    {
    var status = TestContext.CurrentContext.Result.Outcome.Status;
    var stacktrace = string.IsNullOrEmpty(TestContext.CurrentContext.Result.StackTrace)
    ? """"
    : string.Format(""{0}"", TestContext.CurrentContext.Result.StackTrace);
    Status logstatus;
    
    switch (status)
    {
    case TestStatus.Failed:
    logstatus = Status.Fail;
    break;
    case TestStatus.Inconclusive:
    logstatus = Status.Warning;
    break;
    case TestStatus.Skipped:
    logstatus = Status.Skip;
    break;
    default:
    logstatus = Status.Pass;
    break;
    }
    
    _test.Log(logstatus, ""Test ended with "" + logstatus + stacktrace);
    _extent.Flush();
    }
    }

**Source:** [Guide to generate Extent reports in selenium](https://qacraft.com/guide-to-generate-extent-reports-in-selenium-webdriver/)",[]
Selenium python wait for download to finish before driver.close(),https://www.reddit.com/r/selenium/comments/yl35k7/selenium_python_wait_for_download_to_finish/,selenium,"im trying to download files and my internet is volatile i can't predict the download time of every file and use time.sleep() for it.

im using firefox what i did is this loop

    while recheck:
        for file in os.listdir():
            if file.endswith('.part'):
                print('Downloading at index: '+ str(y))
                time.sleep(1)
            else:
                recheck = False
    time.sleep(1)

in firefox when u download something if the donwload isn't finished it has the extention '.part' in it

but this is not ideal and im still getting stuck sometimes because the driver tries to close the window before the download finishes and i get the popup that says if i want to close the browser when i have a download in progress.

what can i do? i can't find a useful answer on stackoverflow either.","[""Does it need to be on firefox?\n\nIf not, there's seem to have a solution:\n\nhttps://stackoverflow.com/questions/48263317/selenium-python-waiting-for-a-download-process-to-complete-using-chrome-web"", 'You can create a loop that keeps checking the file size every 5 to 10 seconds. Once the file size becomes constant for 4-5 iterations, you can assume the file is downloaded therefore ending the loop and then quitting the driver.\nHope this helps.', ""Why doesn't your method work though?\n\nAlso where is the variable y u're using is coming from""]"
11 Best Selenium Alternatives You Should Know,https://www.reddit.com/r/selenium/comments/ykteoh/11_best_selenium_alternatives_you_should_know/,selenium,"Below is the list of selenium alternatives:  


1. Robot Framework
2. Cypress
3. Katalon Studio
4. Screenster
5. CasperJS
6. Watir
7. Cucumber
8. Ghost Inspector
9. Lemonce Editor
10. TestCraft
11. Protractor","['Playwright', ""Cucumber is not even meant for being used like Selenium, it's just a framework for gherkin syntax"", '11 Selenium ‚Äòalternatives‚Äô you ‚Äòshouldn‚Äôt‚Äô use', 'Playwright and WebDriverIO', 'How is cucumber an alternative for Selenium? Does cucumber has option to control web browsers?', 'Cypress, Playwright and Puppeteer are definitely alternatives to Selenium but I think unless something has changed a lot of the other things you mentioned use Selenium underneath.\n\nA good way to think about it is if any of those product support a way to connect to a Selenium grid then they are just using Selenium and providing a different API on top of it.', 'Could you do a sort of rating for them? Have you used them? \n\nI‚Äôve used selenium and heard of Cucumber but the rest I haven‚Äôt.', ""The most common tools I've been seeing lately are\n\n- Cypress\n- Playwright\n- Puppeteer\n- WebDriverIO\n- Robot Framework"", ""Protractor is a wrapper on Selenium to deal with Angular. That's the joke, kids."", 'I‚Äôd have to throw Testcafe in there. Has many similarities to playwright/puppeteer.']"
what's the coolest project you've engaged in with Selenium?,https://www.reddit.com/r/selenium/comments/ykfn8f/whats_the_coolest_project_youve_engaged_in_with/,selenium,"What's the most interesting project you've engaged in that's required Selenium to serve as the primary tool?


It can be business/work or personal, any answer is welcome!","[""Inlaws wanted to take the wife and kid camping for a week but couldn't register any campsite at the one and only park they wanted to go to because all the spaces got swept up each morning. If they didn't get a campsite, I wouldn't get my week alone. Within 2 days of the python/selenium script running at 7am, they had a campsite booked and I had my week alone at home. It was fabulous."", 'For work, I wrote a script that takes a list of IP addresses, opens a headless browser that scrapes a MAC address from the end device and logs it into an excel sheet. Ran through 2500 IP addresses in about 4 hours. It would have taken me weeks to do it manually.', 'Wrote boating license test scripts to go through training and take long exam to get state certificatio. Normally training and exam takes 10+ hours to complete but test script can takes within two minutes.']"
Select an element with pointer-events:none,https://www.reddit.com/r/selenium/comments/yjz3v7/select_an_element_with_pointereventsnone/,selenium,"Hello, I am trying to find an element that is hidden behind the ""pointer-events:none"" property. 

I need to find a href value of the footer on that site, but the table in the body has this property to prevent clicking and every element inherits that.

Is there any way to disable this or is there any other way to find that href value?

Thanks for your answers!

&#x200B;

Here is the link for that site:

 https://mirror.ownpage.fr/clients/21d281cc37e84c52/preview/the\_briefing.html",[]
Chrome driver error,https://www.reddit.com/r/selenium/comments/yjzws9/chrome_driver_error/,selenium,https://stackoverflow.com/q/74237502/13284999,"['Use webdrivermanager', 'Share your code', 'Did you updated the chrome driver file? Remember to use the most stable version']"
Trying to get if site is safe,https://www.reddit.com/r/selenium/comments/yjxyoy/trying_to_get_if_site_is_safe/,selenium,"Hi, i was wondering if you can get via selenium information if site is safe eg: i have 2 sites one was flagged by google becouse it has phising content, and other site no. Yet selenium sees that both of the sites are safe. Any ideas?",[]
LogMeIn,https://www.reddit.com/r/selenium/comments/yjduij/logmein/,selenium,Does anyone here use LogMeIn?,"['What is that?', 'I use RemotePC for remote access and data transfer across computers..\n\nVery useful and reliable.']"
Wierd pagination,https://www.reddit.com/r/selenium/comments/yiyqvk/wierd_pagination/,selenium,"Using Python, how do I paginate through this site ? [https://community.tableau.com/s/ideas](https://community.tableau.com/s/ideas)

I can get the links for the first page, I can scrape the information for each item, but I can't figure out how to go to the next page.","['You can locate the ""next"" button with the CSS locator\n\n    lightning-button:nth-child(3) button.slds-button\n\nJust be sure to wait for the element to be clickable before clicking it, because it looks like it takes each page quite a while to load before the page is interactable', 'Normal selector:  \ndriver.FindElement(By.CssSelector(""svg\\[class=\'slds-button\\_\\_icon slds-button\\_\\_icon\\_right\'\\]"")).Click();\n\nWait:  \nnew WebDriverWait(driver, TimeSpan.FromSeconds(5)).Until(ExpectedConditions.ElementToBeClickable(By.CssSelector(""svg\\[class=\'slds-button\\_\\_icon slds-button\\_\\_icon\\_right\'\\]""))).Click();\n\n&#x200B;\n\nIf you\'re planning on doing his for every page you might want to grab the value of the final page number and create a for-loop.\n\nPs the above code is for C#', 'As per my knowledge of Javascript in [qa services company](https://www.qasource.com/) , You need to wait for the page to load properly and then scroll to the element and after that perform the click operation on the element which in your case is the next button:\n\n**Use the following code:**\n\nbrowser.geturl([community.tableau.com/s/ideas](https://community.tableau.com/s/ideas));\n\n//wait for the page to load fullybrowser.sleep(10000) //time in ms\n\n//Scroll to the next button$(\'//button\\[text()=""Next""\\]).scrollIntoView({behavior: ""smooth"", block: ""center"");\n\n// Click on next button$(\'//button\\[text()=""Next""\\]).click();\n\n//wait for the page to load fullybrowser.sleep(10000) //time in ms\n\nHope you find it helpful!']"
Is it possible to perform google authentication on a website without having to enter the password? Selenium always starts with a fresh session with not log ins or password saves,https://www.reddit.com/r/selenium/comments/yidyvd/is_it_possible_to_perform_google_authentication/,selenium,"I am writing an automation script for slack and currently I am using my email address and password to login. But for deploying this script (on a docker container), this is obviously not safe. The problem is that selenium starts with a completely fresh session every time the script is run. So, if I make the script click the google login button, I have to enter the google email address and password in order to log in. Is there some way to do this without password? Some google api or sdk probably?

&#x200B;

Pardon for the vague question. But I just haven't used anything like this before and am stuck on google authentication.

&#x200B;

Thank you in advance :)","['There is an option from selenium that allows using profile data and auto-complete, first of all, try to identify the which profile you use in case you have over 2 profiles, otherwise you can use the default profile. I\'m on my mobile phone, however this is the code.\n\n```from selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom webdriver_manager.chrome import ChromeDriverManager\nfrom selenium.webdriver.chrome.service import Service\n\nclass Driver(object):\n    def __init__(self) -> None:\n          service = Service(ChromeDriverManager().install())\n          options = Options()\n          directory_profile = ""C:\\\\User\\\\yourUserOfYourPc\\\\AppData\\\\Local\\\\\\Google\\\\Chrome\\\\User Data\\\\Default"" #if you have only one profile, you can use this setting, however it\'s not, type it until ""User Data""\n\n          # You manage 2 or more profiles, you necessarily must put this line of code\n          profile_to_use = ""Profile 3"" # pretend that you\'d want to use 3rd profile, use this\n          options.add_argument(""--user-data-dir=%s"", % directory_profile)\n          options.add_argument(""--profile-directory=%s"", % profile_to_use)\n```']"
Problems with new Instagram layout: Unable to locate element,https://www.reddit.com/r/selenium/comments/yim5t8/problems_with_new_instagram_layout_unable_to/,selenium,"I need a nudge in the right direction: Instagram has changed the interface. Since then, my testing script for posts no longer works. The until recently this section was enough to initiate a new post:

driver.find\_element\_by\_xpath('//div\[@class=""\_abm0""\]/\*\[name()=""svg""\]\[@aria-label=""New post""\]').click()

The new interface has been changed only slightly and the element in question looks like this:

<svg aria-label=""New post"" class=""\_ab6-"" color=""#262626"" fill=""#262626"" height=""24"" role=""img"" ... </svg>

Which led me to the following adjustment:

driver.find\_element\_by\_xpath('//div\[@class=""\_ab6-""\]/\*\[name()=""svg""\]\[@aria-label=""New post""\]').click()

But it will not work like this anyway. The error message is:

selenium.common.exceptions.NoSuchElementException: Message: no such element:: {""method"":""xpath"",""selector"":""//div\[@class=""\_ab6-""\]/\*\[name()=""svg""\]\[@aria-label=""New post""\]""}  (Session info: chrome=106.0.5249.121)

Do any of you ""pros"" have any idea what I'm doing wrong?

Thanks!",[]
"Chromium how to disable ""Save and autofill address""",https://www.reddit.com/r/selenium/comments/yicwf0/chromium_how_to_disable_save_and_autofill_address/,selenium,"Hello, recently I started having issues with my selenium autotests due to a chrome popup that appears when address form is being filled. From the options it can be manually disabled via Settings > Autofill > Addresses and more. My question is what is the chrome option name that can be used to disable this in my automation runs ?","['I eventually found the solution to my problem. To anyone that will encounter this in future: the chrome option is called ""autofill.profile\\_enabled"".\n\n    prefs = {\n            \'autofill.profile_enabled\': False\n        }\n    options.add_experimental_option(\'prefs\', prefs)', ""I've been looking for the answer to this question for days now. Thank you! I had to modify a bit so here's what worked for me. Hopefully this helps someone:\n\n`const webdriver = require('selenium-webdriver')`  \n`const chrome = require('selenium-webdriver/chrome')`  \n`const chromeOptions = new chrome.Options()`\n\n`prefs = {`  \n`'autofill.profile_enabled': false`  \n`}`  \n`chromeOptions.setUserPreferences(prefs)`""]"
Packaging msedgedriver.exe with my app,https://www.reddit.com/r/selenium/comments/yie13l/packaging_msedgedriverexe_with_my_app/,selenium,"I have a small .Net app for automating a repetitive task I am required to do every day. After building and publishing the app in Visual Studio 2022, it leaves me with 2 files.

MyAutomation.exe
msedgedriver.exe

The msedgedriver.exe file has to be in the same directory as MyAutomation.exe, otherwise the Edge browser will not open. 

I'm using Edge since I know it will always be installed on a machine I'm using, not sure if this issue would be any different using Chrome.

Is there a reason this is not being packaged with MyAutomation into one executable file?",['You could skip specifying the driver since it will need to be updated routinely and just add WebDriverManager to your dependencies.']
Need help with locating a button,https://www.reddit.com/r/selenium/comments/yi03yi/need_help_with_locating_a_button/,selenium,"Hello, I am attempting to click the coupon button on  [https://coupons.safeway.com/weeklyad](https://coupons.safeway.com/weeklyad). I have tried the following code  to locate various coupons but it doesn't seem to be able to find the element. The error I get is  ""InvalidSelectorError"".  Does anyone have any tips? 

&#x200B;

    WebElement coupon1 = driver.findElement(By.xpath(""/html/body/flipp-router/flipp-publication-page/div/flipp-sfml-component/sfml-storefront/div/sfml-linear-layout/sfml-flyer-image[1]/div/button[1]""));
    

&#x200B;

    WebElement coupon1 = driver.findElement(By.cssSelector(""//button[@aria-label='Large Fuji Apples or Navel Oranges, , $1.28 lb Member Price . Select for details.']""));","['the xpath you used is absolute xpath, can you try with relative one.\n\nand in the second line of code you have given xpath in By.cssSelector()']"
Element not Interactable exception,https://www.reddit.com/r/selenium/comments/yglfwr/element_not_interactable_exception/,selenium,"Hi, I am trying to login to a website - [https://myaccount.play-cricket.com/idp-signin?state=bDdCdExYWXNzNVlTSTBPRUxiMjhzWU9KZW02SGhINTM0NWEySnNncE01VWZmcUZibjNMU2dYdjBuSXlhanltcg&client\_id=qqaXhehov6cu0sd7AEfd&redirect\_uri=https%3A%2F%2Flogin.ecb.co.uk%2Foauth2%2Fv1%2Fauthorize%2Fcallback&response\_type=code&scope=email+openid+profile](https://myaccount.play-cricket.com/idp-signin?state=bDdCdExYWXNzNVlTSTBPRUxiMjhzWU9KZW02SGhINTM0NWEySnNncE01VWZmcUZibjNMU2dYdjBuSXlhanltcg&client_id=qqaXhehov6cu0sd7AEfd&redirect_uri=https%3A%2F%2Flogin.ecb.co.uk%2Foauth2%2Fv1%2Fauthorize%2Fcallback&response_type=code&scope=email+openid+profile) using selenium. When I attempt to enter something into the password field I get the element not interactable exception. This is my code:  driver.find\_element([By.NAME](https://By.NAME), 'password').send\_keys(password) .

Any help would be appreciated",['Did you wait until the page fully loaded?']
Process unexpectedly closed with status 11,https://www.reddit.com/r/selenium/comments/yftdr9/process_unexpectedly_closed_with_status_11/,selenium,"Hello, I'm trying to run selenium but i get this error.

This is the program in python:

    ""First selenium script""
    from selenium import webdriver
    from selenium.webdriver.firefox.service import Service as FirefoxService
    from webdriver_manager.firefox import GeckoDriverManager
    
    
    driver = webdriver.Firefox(
        service=FirefoxService(executable_path=GeckoDriverManager().install()))
    
    driver.get(""https://www.google.com"")

This is the console output:

    alex@nobara ~/selenium$ python main.py
    Traceback (most recent call last):
      File ""/home/alex/selenium/main.py"", line 7, in <module>
        driver = webdriver.Firefox(
      File ""/home/alex/.local/lib/python3.10/site-packages/selenium/webdriver/firefox/webdriver.py"", line 177, in __init__
        super().__init__(
      File ""/home/alex/.local/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py"", line 272, in __init__
        self.start_session(capabilities, browser_profile)
      File ""/home/alex/.local/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py"", line 364, in start_session
        response = self.execute(Command.NEW_SESSION, parameters)
      File ""/home/alex/.local/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py"", line 429, in execute
        self.error_handler.check_response(response)
      File ""/home/alex/.local/lib/python3.10/site-packages/selenium/webdriver/remote/errorhandler.py"", line 243, in check_response
        raise exception_class(message, screen, stacktrace)
    selenium.common.exceptions.WebDriverException: Message: Process unexpectedly closed with status 11
    

This is the content of geckodriver.log:

    1666974769008	geckodriver	INFO	Listening on 127.0.0.1:58881
    1666974769634	mozrunner::runner	INFO	Running command: ""/usr/bin/firefox"" ""--marionette"" ""--remote-debugging-port"" ""56809"" ""--remote-allow-hosts"" ""localhost"" ""-no-remote"" ""-profile"" ""/tmp/rust_mozprofile6UjIeC""
    ExceptionHandler::GenerateDump cloned child 6111
    ExceptionHandler::WaitForContinueSignal waiting for continue signal...
    ExceptionHandler::SendContinueSignalToChild sent continue signal to child

I don't know what to do.

I'm on Linux fedora 36.",['Is your OS only terminal based? It may be because the driver isn‚Äôt running headless but there‚Äôs no way to bring up the browser.']
GoLogin and using websocket for devTools,https://www.reddit.com/r/selenium/comments/yfpbkt/gologin_and_using_websocket_for_devtools/,selenium,"I'm trying to use GoLogin api with python/selenium to run the browser in the cloud. But Chrome driver expects ip:port for debuggerAddress instead of websocket. The GoLogin api returns a websocket address. 

Here is the code: 


debugger_status = gl.startRemote()
debugger_address = debugger_status[""wsUrl""]
print(debugger_address)

chrome_options = ChromeOptions()
chrome_options.add_experimental_option(""debuggerAddress"", debugger_address)
service = ChromeService(executable_path=chrome_driver_path)
driver = webdriver.Chrome(service=service, options=chrome_options)
driver.get(""http://www.python.org"")
assert ""Python"" in driver.title
time.sleep(3)
driver.close()
gl.stop()


When I run this code, I get this exception:

selenium.common.exceptions.InvalidArgumentException: Message: invalid argument: cannot parse capability: goog:chromeOptions
from invalid argument: cannot parse debuggerAddress
from invalid argument: must be 'host:port'


The debugger address looks like this: 

wss://635afEab6124ee712e5f2572.orbita.gologin.com/devtools/browser/4e3f8eda-cd49-45D7-9d51-acb76356fb77

How can I change the address of Chrome devTools to use a websocket instead of ip:port ? Or is there another way to do this?",[]
"Need help with making a generic Xpath within the Action (Helper location), that I can reuse on the web-application form page",https://www.reddit.com/r/selenium/comments/yfjv88/need_help_with_making_a_generic_xpath_within_the/,selenium,"Hi All,

&#x200B;

I‚Äôm new to automated testing with Selenium and have some questions regarding the following that I want to accomplish.

\-	I want to define a generic Xpath within the Action (Helper location), that I can reuse for several fields on the web-application form page.

\-	Basically I want to find the class element that I have written down in Step 2 and fill the k-textbox with a value by using the generic Xpath from Step 1.

&#x200B;

The below example is not working for me and I guess I have messed it up, would be nice If someone could provide me with an example. Thanks!

&#x200B;

Step1:

My current generic Xpath within the Action (Helper location), that I want use for several fields on the webpage form.

&#x200B;

Example what I got.

&#x200B;

public void SelectAndTypeEditFieldByLabelGeneric(string label, string searchtext)

{

TypeByXpath(""//\*\[contains(@class,'form-col') or contains(@class, 'form-input')\]//\*\[text()='"" + label + ""'\]/parent::div//input"", searchtext);

}

&#x200B;

Step 2:

From my steps location I fil in the input values with the reference toward the generic Xpath from step 1.

&#x200B;

Example what I got.

&#x200B;

\[When(@""I Fill In The Account Details"")\]

public void WhenIFillInTheAccountDetails(string label, string searchtext)

{

Action.SelectAndTypeEditFieldByLabelGeneric(""Bedrijfsnaam"", ""Test Company"");

Action.SelectAndTypeEditFieldByLabelGeneric(""Straat"", ""Test Street"");

Action.SelectAndTypeEditFieldByLabelGeneric(""Huisnummer"", ""999"");

    }  

Furthermore the When condition here has a relation with the SpecFlowFeature for the scenario.

&#x200B;

Scenario: Add A New Account

    When I Fill In The Account Detail

EDIT: I found the issue and solved the problem.

I changed: 

public void SelectAndTypeEditFieldByLabelGeneric(string label, string searchtext) With -> 'public void WhenIFillInTheAccountDetailsTest() .  

And within Action I changed the string searchtext with string value

public void SelectAndTypeEditFieldByLabelGeneric(string label, string searchtext)

{

TypeByXpath(""//\*\[contains(@class,'form-col') or contains(@class, 'form-input')\]//\*\[text()='"" + label + ""'\]/parent::div//input"", searchtext);

} ",[]
Website Blocking Selenium Input,https://www.reddit.com/r/selenium/comments/yf9790/website_blocking_selenium_input/,selenium,"Some background: I have been working on a project for a while now that scrapes fares off Amtrak's site so a calendar view of fares can be seen at once. Initially, Amtrak would throw an error anytime I tried to make a search on the site, but adding the code below as an argument to options fixed that.

    ""--disable-blink-features=AutomationControlled""

Now, I am struggling with a much more challenging kind of error. Using the above code, I can access the site and perform searches. However, after making many consecutive searches (the number varies but around 5+), the site stops loading searches again for 10-20 minutes. What is particularly strange about this error is that Amtrak is not blocking my browser, if I manually enter the same information Selenium does through the webdriver browser the site loads fine. I have tried using the undetected\_chromedriver extension and altered my input to appear more human-like by entering phrases character by character, adding random delays between every action, and hovering over elements before clicking. Somehow, Amtrak is able to differentiate my human input from Selenium, and I have no idea how. I'd really appreciate any ideas for how to change my code to make the form input undetectable.","[""Can you share your code so far so we can try tinkle with it to find a solution, I've a few ideas in my mind already""]"
"How to make a list by ""Label for"" elements",https://www.reddit.com/r/selenium/comments/yeo6dq/how_to_make_a_list_by_label_for_elements/,selenium,"Hello,

I have these elements:

 <label for=""categories\\\_36"">  


 <label for=""categories\\\_38"">  


 <label for=""categories\\\_6"">  


.....

I want to create a list with all of these elements and after that to click on every of them.

Maybe something like that:   all\_categories = driver.find\_elements(By.CSS\_SELECTOR,'label\[for=')

pp I am using Python and Selenium in  Jupyter Notebook.

Thanks in advance!","[""Find elements by xpath  \n    //label[contains(@for,'categories')]"", 'Driver.find_elements(By.xpath(‚Äú//label[contains(.,‚Äòcategories‚Äô)])']"
SeleniumIDE store values on a big table to txt,https://www.reddit.com/r/selenium/comments/yeb8ym/seleniumide_store_values_on_a_big_table_to_txt/,selenium,"hello i wanted to save the values of a big html table into a text file im currently working with selenium ide & selenium side runner  
any help would be good","[""If you're using selenium side runner may I recommend a few additional steps forward with robot framework.  Quite a many things you can do with it along with selenium.  I used it just this week to scrape 8k urls and store their element text values into a PostgreSQL database...""]"
Noobie needs help,https://www.reddit.com/r/selenium/comments/ye0sfm/noobie_needs_help/,selenium,"Hello there,

&#x200B;

at the moment i try to programm a small bot for myself, but know i run into following error and im not able to solve it by myself.

 **AttributeError**: 'WebDriver' object has no attribute 'execute\_scipt' 

&#x200B;

The Script is pretty simple:

    from selenium import webdriver
    from selenium.webdriver.common.keys import Keys
    from webdriver_manager.chrome import ChromeDriverManager
    
    driver = webdriver.Chrome(ChromeDriverManager().install())
    driver.implicitly_wait(10)
    
    driver.get(""fantastic-website"")
    driver.execute_scipt('document.getElementsByName(""btn-add-to-cart"")[0].click()')

I alredy tested the JavaScript in the DevTools Console and the Script is working.

Can someone give me a hint?

&#x200B;

Kind regards","['You have a typo; you\'re missing the ""r"" in ""execute_script"" so your code currently says ""execute_scipt"" . \n\nIt sounds like you\'re probably not using an IDE, or it would have highlighted the error for you. I recommend doing your development within an IDE like Pycharm.\n\nHope this helps!', 'So this is simply a typo, but a good lesson for a new person since the error tells you exactly what\'s wrong. \n\nThis line:\n\n    driver = webdriver.Chrome(ChromeDriverManager().install())\n\nAssigns the name \'driver\' to an instance of the webdriver module. \n\nThis line:\n\n    driver.execute_scipt(\'document.getElementsByName(""btn-add-to-cart"")[0].click()\')\n\nThen tries to utilize an attribute of the webdriver module ... but there\'s a problem there. There is no such attribute, according to the error. So what\'s the problem? Well there\'s no \'execute\\_scipt\' attribute, right? So ... fix the typo! The error tells you where the typo is, so it\'s easy once you get used to reading such things.  \n\n\n^((if that\'s too obtuse, just change \'execute\\_scipt\' to \'execute\\_script\'))', 'Where you got this code from']"
Is it possible to automate clicking a browser extension?,https://www.reddit.com/r/selenium/comments/yda3k6/is_it_possible_to_automate_clicking_a_browser/,selenium,"Hi.

I'm using Firefox on both my mobile phone and my PC and I have a tendency to open a lot of Facebook, 9gag, etc. tabs that contain videos on my mobile phone and then send the list of tabs to my PC where I open each link manually, click the VideoDownloadHelper addon on upper right, choose quality of video to download then swap over to next tab.

Is it possible to automate this with Selenium? The whole process would look like this:

1) Click VideoDownloadHelper
2) Click ""HLS streaming"" option in drowndown menu from VideoDownloadHelper with highest resolution
3) Ctrl+Tab to next tab
4) repeat until out of tabs


Is something like this possible with Selenium?","['Hi,\n\nYes, i think its possible. how do you send the list of these Tabs to your browser PC? is it via bookmarks? anyway, i was just thinking aloud bcoz u can automate the opeing of these Tabs too.\n\nLet me know if you  need help.', 'You could use a tool called AutoIt to accomplish this, but you can\'t use Selenium directly to do this. With AutoIt you should be able to automate the clicking sequence required to perform the tasks you want.   \n\n\nBut I have to ask if all you\'re doing is ""picking up where you left off"" on your PC after being on your mobile, why not use firefox\'s built in sync which is designed to do exactly this? All you have to do is create a profile so that you can keep track of these tabs on whatever device you\'re on then switch devices and boom! Bob\'s your Uncle.   \n\n\nIf that\'s sounds like exactly what you were looking for then click [here](https://www.mozilla.org/en-US/firefox/sync/) for more info, and have a great day!', 'Puppeteer can automate browser extensions']"
firefox/geckdriver slow to load [python/pytest],https://www.reddit.com/r/selenium/comments/ydazum/firefoxgeckdriver_slow_to_load_pythonpytest/,selenium,"Firefox can take over 30 seconds to load the first page.  Once the browser loads I have no issue with speed.   chromedriver loads almost instantly.

Any issues with my config?

    fp = webdriver.FirefoxProfile('C:\\Users\\user\\AppData\\Roaming\\Mozilla\\Firefox\\Profiles\\7ot81hip.my--dev')
    driver = webdriver.Firefox(fp)

&#x200B;","[""I created a new profile to use and its way faster.  Not sure if that's all I did but it seems to have made a huge difference.""]"
Dealing with div number changes,https://www.reddit.com/r/selenium/comments/ycoqtv/dealing_with_div_number_changes/,selenium,"I am currently working in a automation of a kind of web form, but the it seems that the dibs numbers of the elements changes if I tried to retest my code (which means open the browser logging in, query the form and so on...). Here is an example of the  full xpath change:

1. 

/html/body/div[38]/div[2]/div/div[2]/div/div/div[1]/div[1]/div/table/thead/tr[2]/th[1]/span/span/span/input

2. 

/html/body/div[29]/div[2]/div/div[2]/div/div/div[1]/div[1]/div/table/thead/tr[2]/th[1]/span/span/span/input

If I try to use shorter version of xpath a get a ""grid number"" Id. 

Already tried to use contains and Starts with, but I got Not interactible element error.

Any thoughts?","['The full xpath path will change 99% if it is a modern site, since new things will be added to the site and the site could update as well, making your full xpath path invalid.\n\nDon\'t use full xpath path and learn to write your own xpath. It is not hard to learn and helps you with much shorter paths, which can be calculated much faster by selenium as well. So it should be in your best interest to learn to write xpath paths.\n\nEdit: For example if the input box has a text in it just use ""//input[text ()=\'the text in the box\']""', 'Hey,  dont use XPath  unless you now what you are doing. Use element locators. you will be frustrated especially if you are new to Selenium']"
https://www.techsravi.com/automation-testing-resume-for-4-years-in-experience/,https://www.reddit.com/r/selenium/comments/ycycnu/httpswwwtechsravicomautomationtestingresumefor4yea/,selenium,,[]
How do I click on Youtube cookies 'Accept all' correctly?,https://www.reddit.com/r/selenium/comments/ycfwjn/how_do_i_click_on_youtube_cookies_accept_all/,selenium,"[https://i.ibb.co/cy796c7/index.png](https://i.ibb.co/cy796c7/index.png)

Here's the code I currently use, but it doesn't work all the time. Sometimes it just errors out. Any ideas?

    el_xpath = '//*[@id=""content""]/div[2]/div[6]/div[1]/ytd-button-renderer[2]/a'
    WebDriverWait(self.driver, 20).until(EC.presence_of_element_located((By.XPATH, el_xpath)))
    self.driver.find_element(""xpath"", el_xpath).click()

Error:

      File ""/home/admin/DEV/Python/bbot/scrap/__init__.py"", line 51, in click_accept_all
        WebDriverWait(self.driver, 20).until(EC.presence_of_element_located((By.XPATH, el_xpath)))
      File ""/home/admin/DEV/Python/bbot/venv/lib/python3.10/site-packages/selenium/webdriver/support/wait.py"", line 90, in until
        raise TimeoutException(message, screen, stacktrace)
    selenium.common.exceptions.TimeoutException: Message: 
    Stacktrace:","['You could try locating the element by text ?', 'Use text() xpath', 'tried like this too, also not working from time to time...\n```\nWebDriverWait(self.driver, 10).until(EC.presence_of_element_located((By.XPATH, ""//span[contains(text(), \'Accept all\')]"")))\nself.driver.find_element(""xpath"", ""//span[contains(text(), \'Accept all\')]"").click()\n```']"
